# Day 56: Á´∂Âêà„Ç≥„É≥„Ç∑„É•„Éº„Éû„Éº„Éë„Çø„Éº„É≥

## üéØ Êú¨Êó•„ÅÆÁõÆÊ®ô (Today's Goal)

Á´∂Âêà„Ç≥„É≥„Ç∑„É•„Éº„Éû„Éº„Éë„Çø„Éº„É≥„ÇíÂÆüË£Ö„Åó„ÄÅË§áÊï∞„ÅÆ„Ç≥„É≥„Ç∑„É•„Éº„Éû„Éº„ÅåÂêå‰∏Ä„Ç≠„É•„Éº„Åã„Çâ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂÆâÂÖ®„Å´ÂèñÂæó„ÉªÂá¶ÁêÜ„Åô„Çã‰ªïÁµÑ„Åø„ÇíÊßãÁØâ„Åô„Çã„ÄÇË≤†Ëç∑ÂàÜÊï£„ÄÅ„Éï„Çß„Ç§„É´„Ç™„Éº„Éê„Éº„ÄÅ„Çπ„Ç±„Éº„É©„Éì„É™„ÉÜ„Ç£„ÇíÂÆüÁèæ„Åô„ÇãÂåÖÊã¨ÁöÑ„Å™„Ç∑„Çπ„ÉÜ„É†„ÇíÁøíÂæó„Åô„Çã„ÄÇ

## üìñ Ëß£Ë™¨ (Explanation)

### Á´∂Âêà„Ç≥„É≥„Ç∑„É•„Éº„Éû„Éº„Éë„Çø„Éº„É≥„Å®„ÅØ

Á´∂Âêà„Ç≥„É≥„Ç∑„É•„Éº„Éû„Éº„Éë„Çø„Éº„É≥ÔºàCompeting Consumer PatternÔºâ„ÅØ„ÄÅË§áÊï∞„ÅÆ„Ç≥„É≥„Ç∑„É•„Éº„Éû„Éº„Ç§„É≥„Çπ„Çø„É≥„Çπ„ÅåÂêå‰∏Ä„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„Ç≠„É•„Éº„Åã„ÇâÁ´∂ÂêàÁöÑ„Å´„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂèñÂæó„ÅóÂá¶ÁêÜ„Åô„Çã„Éë„Çø„Éº„É≥„Åß„Åô„ÄÇ„Åì„ÅÆ„Éë„Çø„Éº„É≥„Å´„Çà„Çä„ÄÅ„Çπ„É´„Éº„Éó„ÉÉ„Éà„ÅÆÂêë‰∏ä„Å®ÂèØÁî®ÊÄß„ÅÆÁ¢∫‰øù„ÇíÂÆüÁèæ„Åß„Åç„Åæ„Åô„ÄÇ

### ‰∏ªË¶Å„Å™Âà©ÁÇπ

1. **„Çπ„Ç±„Éº„É©„Éì„É™„ÉÜ„Ç£**: „Ç≥„É≥„Ç∑„É•„Éº„Éû„ÉºÊï∞„ÇíÂãïÁöÑ„Å´Ë™øÊï¥ÂèØËÉΩ
2. **Ë≤†Ëç∑ÂàÜÊï£**: Âá¶ÁêÜË≤†Ëç∑„ÇíË§áÊï∞„Ç§„É≥„Çπ„Çø„É≥„Çπ„Å´ÂàÜÊï£
3. **È´òÂèØÁî®ÊÄß**: ‰∏ÄÈÉ®„ÅÆ„Ç≥„É≥„Ç∑„É•„Éº„Éû„Éº„ÅåÂÅúÊ≠¢„Åó„Å¶„ÇÇÂá¶ÁêÜÁ∂ôÁ∂ö
4. **„Éï„Ç©„É´„Éà„Éà„É¨„É©„É≥„Éà**: ÈöúÂÆ≥„Åã„Çâ„ÅÆËá™ÂãïÂæ©Êóß

### Âü∫Êú¨„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£

```go
type CompetingConsumerSystem struct {
    messageQueue    MessageQueue
    consumers       map[string]*Consumer
    coordinator     *ConsumerCoordinator
    loadBalancer    LoadBalancer
    healthChecker   *HealthChecker
    metrics         *SystemMetrics
}

type Consumer struct {
    ID              string
    Status          ConsumerStatus
    ProcessingChan  chan *Message
    ErrorChan       chan error
    HeartbeatTicker *time.Ticker
    Processor       MessageProcessor
}

type ConsumerStatus string

const (
    StatusIdle       ConsumerStatus = "idle"
    StatusProcessing ConsumerStatus = "processing"
    StatusFailed     ConsumerStatus = "failed"
    StatusStopped    ConsumerStatus = "stopped"
)
```

### „É°„ÉÉ„Çª„Éº„Ç∏„Ç≠„É•„Éº„ÅÆÂÆüË£Ö

```go
type SafeMessageQueue struct {
    messages        []*Message
    inFlight        map[string]*InFlightMessage
    mu              sync.RWMutex
    notifyConsumers chan struct{}
    maxRetries      int
    visibilityTimeout time.Duration
}

type InFlightMessage struct {
    Message       *Message
    ConsumerID    string
    StartTime     time.Time
    RetryCount    int
    Timeout       time.Time
}

func (smq *SafeMessageQueue) Dequeue(consumerID string) (*Message, error) {
    smq.mu.Lock()
    defer smq.mu.Unlock()
    
    if len(smq.messages) == 0 {
        return nil, ErrNoMessages
    }
    
    // FIFO„Åß„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂèñÂæó
    message := smq.messages[0]
    smq.messages = smq.messages[1:]
    
    // „Ç§„É≥„Éï„É©„Ç§„Éà„É°„ÉÉ„Çª„Éº„Ç∏„Å®„Åó„Å¶ËøΩÂä†
    inFlight := &InFlightMessage{
        Message:    message,
        ConsumerID: consumerID,
        StartTime:  time.Now(),
        Timeout:    time.Now().Add(smq.visibilityTimeout),
    }
    smq.inFlight[message.ID] = inFlight
    
    return message, nil
}

func (smq *SafeMessageQueue) Acknowledge(messageID, consumerID string) error {
    smq.mu.Lock()
    defer smq.mu.Unlock()
    
    inFlight, exists := smq.inFlight[messageID]
    if !exists {
        return ErrMessageNotFound
    }
    
    if inFlight.ConsumerID != consumerID {
        return ErrUnauthorizedAck
    }
    
    delete(smq.inFlight, messageID)
    return nil
}

func (smq *SafeMessageQueue) Nack(messageID, consumerID string) error {
    smq.mu.Lock()
    defer smq.mu.Unlock()
    
    inFlight, exists := smq.inFlight[messageID]
    if !exists {
        return ErrMessageNotFound
    }
    
    if inFlight.ConsumerID != consumerID {
        return ErrUnauthorizedNack
    }
    
    // ÂÜçË©¶Ë°åÂõûÊï∞„Çí„ÉÅ„Çß„ÉÉ„ÇØ
    if inFlight.RetryCount >= smq.maxRetries {
        // DLQ„Å´ÈÄÅ‰ø°
        return smq.sendToDeadLetterQueue(inFlight.Message)
    }
    
    // „É°„ÉÉ„Çª„Éº„Ç∏„Çí„Ç≠„É•„Éº„Å´Êàª„Åô
    inFlight.RetryCount++
    smq.messages = append(smq.messages, inFlight.Message)
    delete(smq.inFlight, messageID)
    
    // ‰ªñ„ÅÆ„Ç≥„É≥„Ç∑„É•„Éº„Éû„Éº„Å´ÈÄöÁü•
    select {
    case smq.notifyConsumers <- struct{}{}:
    default:
    }
    
    return nil
}
```

### Ë≤†Ëç∑ÂàÜÊï£Êà¶Áï•

```go
type LoadBalancer interface {
    SelectConsumer(consumers []*Consumer) *Consumer
}

type RoundRobinLoadBalancer struct {
    current int
    mu      sync.Mutex
}

func (rr *RoundRobinLoadBalancer) SelectConsumer(consumers []*Consumer) *Consumer {
    rr.mu.Lock()
    defer rr.mu.Unlock()
    
    availableConsumers := make([]*Consumer, 0)
    for _, consumer := range consumers {
        if consumer.Status == StatusIdle {
            availableConsumers = append(availableConsumers, consumer)
        }
    }
    
    if len(availableConsumers) == 0 {
        return nil
    }
    
    selected := availableConsumers[rr.current%len(availableConsumers)]
    rr.current++
    return selected
}

type WeightedLoadBalancer struct {
    weights map[string]int
    mu      sync.RWMutex
}

func (wlb *WeightedLoadBalancer) SelectConsumer(consumers []*Consumer) *Consumer {
    wlb.mu.RLock()
    defer wlb.mu.RUnlock()
    
    totalWeight := 0
    for _, consumer := range consumers {
        if consumer.Status == StatusIdle {
            totalWeight += wlb.weights[consumer.ID]
        }
    }
    
    if totalWeight == 0 {
        return nil
    }
    
    rand.Seed(time.Now().UnixNano())
    target := rand.Intn(totalWeight)
    
    current := 0
    for _, consumer := range consumers {
        if consumer.Status == StatusIdle {
            current += wlb.weights[consumer.ID]
            if current > target {
                return consumer
            }
        }
    }
    
    return nil
}

type LeastConnectionsLoadBalancer struct {
    connections map[string]int
    mu          sync.RWMutex
}

func (lcb *LeastConnectionsLoadBalancer) SelectConsumer(consumers []*Consumer) *Consumer {
    lcb.mu.RLock()
    defer lcb.mu.RUnlock()
    
    var selected *Consumer
    minConnections := int(^uint(0) >> 1) // max int
    
    for _, consumer := range consumers {
        if consumer.Status == StatusIdle {
            connections := lcb.connections[consumer.ID]
            if connections < minConnections {
                minConnections = connections
                selected = consumer
            }
        }
    }
    
    return selected
}
```

### „Éò„É´„Çπ„ÉÅ„Çß„ÉÉ„ÇØ„Å®„Éï„Çß„Ç§„É´„Ç™„Éº„Éê„Éº

```go
type HealthChecker struct {
    consumers       map[string]*Consumer
    checkInterval   time.Duration
    healthTimeout   time.Duration
    failureThreshold int
    failures        map[string]int
    mu              sync.RWMutex
}

func (hc *HealthChecker) StartMonitoring(ctx context.Context) {
    ticker := time.NewTicker(hc.checkInterval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            hc.performHealthChecks()
        case <-ctx.Done():
            return
        }
    }
}

func (hc *HealthChecker) performHealthChecks() {
    hc.mu.Lock()
    defer hc.mu.Unlock()
    
    for consumerID, consumer := range hc.consumers {
        if err := hc.checkConsumerHealth(consumer); err != nil {
            hc.failures[consumerID]++
            
            if hc.failures[consumerID] >= hc.failureThreshold {
                consumer.Status = StatusFailed
                hc.triggerFailover(consumer)
            }
        } else {
            hc.failures[consumerID] = 0
            if consumer.Status == StatusFailed {
                consumer.Status = StatusIdle
            }
        }
    }
}

func (hc *HealthChecker) checkConsumerHealth(consumer *Consumer) error {
    // „Éè„Éº„Éà„Éì„Éº„Éà„ÉÅ„Çß„ÉÉ„ÇØ
    if time.Since(consumer.LastHeartbeat) > hc.healthTimeout {
        return errors.New("heartbeat timeout")
    }
    
    // „É¨„Çπ„Éù„É≥„Ç∑„Éñ„Éç„Çπ„ÉÅ„Çß„ÉÉ„ÇØ
    healthCheck := make(chan error, 1)
    go func() {
        healthCheck <- consumer.Ping()
    }()
    
    select {
    case err := <-healthCheck:
        return err
    case <-time.After(hc.healthTimeout):
        return errors.New("health check timeout")
    }
}

func (hc *HealthChecker) triggerFailover(failedConsumer *Consumer) {
    // „Éï„Çß„Ç§„É´„Ç™„Éº„Éê„Éº„É≠„Ç∏„ÉÉ„ÇØ
    // 1. Âá¶ÁêÜ‰∏≠„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„Çí‰ªñ„ÅÆ„Ç≥„É≥„Ç∑„É•„Éº„Éû„Éº„Å´ÂÜçÈÖçÂ∏É
    // 2. Êñ∞„Åó„ÅÑ„Ç≥„É≥„Ç∑„É•„Éº„Éû„Éº„Ç§„É≥„Çπ„Çø„É≥„Çπ„ÅÆËµ∑Âãï
    // 3. „Ç¢„É©„Éº„ÉàÈÄÅ‰ø°
}
```

### ÂãïÁöÑ„Çπ„Ç±„Éº„É™„É≥„Ç∞

```go
type AutoScaler struct {
    minConsumers    int
    maxConsumers    int
    scaleUpThreshold   float64
    scaleDownThreshold float64
    cooldownPeriod     time.Duration
    lastScaleAction    time.Time
    metrics           *SystemMetrics
    consumerFactory   ConsumerFactory
    mu               sync.RWMutex
}

func (as *AutoScaler) MonitorAndScale(ctx context.Context, system *CompetingConsumerSystem) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            as.evaluateScaling(system)
        case <-ctx.Done():
            return
        }
    }
}

func (as *AutoScaler) evaluateScaling(system *CompetingConsumerSystem) {
    as.mu.Lock()
    defer as.mu.Unlock()
    
    // „ÇØ„Éº„É´„ÉÄ„Ç¶„É≥ÊúüÈñì‰∏≠„ÅØ„Çπ„Ç±„Éº„É™„É≥„Ç∞„Åó„Å™„ÅÑ
    if time.Since(as.lastScaleAction) < as.cooldownPeriod {
        return
    }
    
    currentConsumers := len(system.consumers)
    queueDepth := system.messageQueue.GetDepth()
    avgProcessingTime := as.metrics.GetAverageProcessingTime()
    
    // „Çπ„Ç±„Éº„É´„Ç¢„ÉÉ„Éó„ÅÆÂà§ÂÆö
    if queueDepth > 0 && avgProcessingTime > 0 {
        estimatedThroughput := float64(currentConsumers) / avgProcessingTime.Seconds()
        queueGrowthRate := float64(queueDepth) / estimatedThroughput
        
        if queueGrowthRate > as.scaleUpThreshold && currentConsumers < as.maxConsumers {
            as.scaleUp(system)
            return
        }
    }
    
    // „Çπ„Ç±„Éº„É´„ÉÄ„Ç¶„É≥„ÅÆÂà§ÂÆö
    if queueDepth == 0 && currentConsumers > as.minConsumers {
        idleConsumers := 0
        for _, consumer := range system.consumers {
            if consumer.Status == StatusIdle {
                idleConsumers++
            }
        }
        
        idleRatio := float64(idleConsumers) / float64(currentConsumers)
        if idleRatio > as.scaleDownThreshold {
            as.scaleDown(system)
        }
    }
}

func (as *AutoScaler) scaleUp(system *CompetingConsumerSystem) {
    newConsumer := as.consumerFactory.CreateConsumer()
    system.AddConsumer(newConsumer)
    as.lastScaleAction = time.Now()
    
    log.Printf("Scaled up: added consumer %s", newConsumer.ID)
}

func (as *AutoScaler) scaleDown(system *CompetingConsumerSystem) {
    // ÊúÄ„ÇÇ„Ç¢„Ç§„Éâ„É´ÊôÇÈñì„ÅÆÈï∑„ÅÑ„Ç≥„É≥„Ç∑„É•„Éº„Éû„Éº„ÇíÂÅúÊ≠¢
    var longestIdle *Consumer
    var maxIdleTime time.Duration
    
    for _, consumer := range system.consumers {
        if consumer.Status == StatusIdle {
            idleTime := time.Since(consumer.LastActivity)
            if idleTime > maxIdleTime {
                maxIdleTime = idleTime
                longestIdle = consumer
            }
        }
    }
    
    if longestIdle != nil {
        system.RemoveConsumer(longestIdle.ID)
        as.lastScaleAction = time.Now()
        
        log.Printf("Scaled down: removed consumer %s", longestIdle.ID)
    }
}
```

### „É°„ÉÉ„Çª„Éº„Ç∏Âá¶ÁêÜ„ÅÆÂÆüË£Ö

```go
type MessageProcessor interface {
    Process(ctx context.Context, message *Message) error
}

type AsyncMessageProcessor struct {
    workerPool  *WorkerPool
    timeout     time.Duration
    retryPolicy RetryPolicy
}

func (amp *AsyncMessageProcessor) Process(ctx context.Context, message *Message) error {
    processCtx, cancel := context.WithTimeout(ctx, amp.timeout)
    defer cancel()
    
    return amp.workerPool.Submit(processCtx, func(ctx context.Context) error {
        return amp.processWithRetry(ctx, message)
    })
}

func (amp *AsyncMessageProcessor) processWithRetry(ctx context.Context, message *Message) error {
    var lastErr error
    
    for attempt := 0; attempt < amp.retryPolicy.MaxAttempts; attempt++ {
        if attempt > 0 {
            delay := amp.retryPolicy.CalculateDelay(attempt)
            select {
            case <-time.After(delay):
            case <-ctx.Done():
                return ctx.Err()
            }
        }
        
        if err := amp.processMessage(ctx, message); err != nil {
            lastErr = err
            if !amp.retryPolicy.ShouldRetry(err) {
                break
            }
            continue
        }
        
        return nil
    }
    
    return lastErr
}
```

## üìù Ë™≤È°å (The Problem)

‰ª•‰∏ã„ÅÆÊ©üËÉΩ„ÇíÊåÅ„Å§ÂåÖÊã¨ÁöÑ„Å™Á´∂Âêà„Ç≥„É≥„Ç∑„É•„Éº„Éû„Éº„Ç∑„Çπ„ÉÜ„É†„ÇíÂÆüË£Ö„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºö

### 1. Âü∫Êú¨Ê©üËÉΩ
- ÂÆâÂÖ®„Å™„É°„ÉÉ„Çª„Éº„Ç∏„Ç≠„É•„Éº
- Ë§áÊï∞„Ç≥„É≥„Ç∑„É•„Éº„Éû„Éº„ÅÆÁÆ°ÁêÜ
- „É°„ÉÉ„Çª„Éº„Ç∏„ÅÆÂèØË¶ñÊÄßÂà∂Âæ°

### 2. Ë≤†Ëç∑ÂàÜÊï£
- „É©„Ç¶„É≥„Éâ„É≠„Éì„É≥ÊñπÂºè
- Èáç„Åø‰ªò„ÅçÂàÜÊï£
- ÊúÄÂ∞èÊé•Á∂öÊï∞ÊñπÂºè

### 3. ÈöúÂÆ≥Âá¶ÁêÜ
- „Éò„É´„Çπ„ÉÅ„Çß„ÉÉ„ÇØ
- Ëá™Âãï„Éï„Çß„Ç§„É´„Ç™„Éº„Éê„Éº
- „É°„ÉÉ„Çª„Éº„Ç∏„ÅÆÂÜçÂá¶ÁêÜ

### 4. „Çπ„Ç±„Éº„É©„Éì„É™„ÉÜ„Ç£
- ÂãïÁöÑ„Çπ„Ç±„Éº„É™„É≥„Ç∞
- „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÁõ£Ë¶ñ
- Ë≤†Ëç∑‰∫àÊ∏¨

### 5. ÈÅãÁî®Ê©üËÉΩ
- „É°„Éà„É™„ÇØ„ÇπÂèéÈõÜ
- „É≠„Ç∞Ë®òÈå≤
- „Ç¢„É©„Éº„ÉàÊ©üËÉΩ

## ‚úÖ ÊúüÂæÖ„Åï„Çå„ÇãÊåôÂãï (Expected Behavior)

ÂÆüË£Ö„ÅåÊ≠£„Åó„ÅèÂÆå‰∫Ü„Åô„Çã„Å®„ÄÅ‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å™„ÉÜ„Çπ„ÉàÁµêÊûú„ÅåÂæó„Çâ„Çå„Åæ„ÅôÔºö

```bash
$ go test -v
=== RUN   TestCompetingConsumer_BasicOperation
    main_test.go:45: Multiple consumers processing messages correctly
--- PASS: TestCompetingConsumer_BasicOperation (0.02s)

=== RUN   TestCompetingConsumer_LoadBalancing
    main_test.go:65: Load balancing distributing work evenly
--- PASS: TestCompetingConsumer_LoadBalancing (0.03s)

=== RUN   TestCompetingConsumer_Failover
    main_test.go:85: Failover handling working correctly
--- PASS: TestCompetingConsumer_Failover (0.04s)

PASS
ok      day56-competing-consumer   0.156s
```

## üí° „Éí„É≥„Éà (Hints)

ÂÆüË£Ö„Å´Ë©∞„Åæ„Å£„ÅüÂ†¥Âêà„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ„Éí„É≥„Éà„ÇíÂèÇËÄÉ„Å´„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºö

### Âü∫Êú¨ÁöÑ„Å™„Ç≥„É≥„Ç∑„É•„Éº„Éû„ÉºÂÆüË£Ö

```go
func (c *Consumer) Start(ctx context.Context, queue MessageQueue) {
    go func() {
        for {
            select {
            case <-ctx.Done():
                return
            default:
                message, err := queue.Dequeue(c.ID)
                if err != nil {
                    time.Sleep(100 * time.Millisecond)
                    continue
                }
                
                c.processMessage(ctx, message, queue)
            }
        }
    }()
}
```

### „É°„ÉÉ„Çª„Éº„Ç∏ÂèØË¶ñÊÄßÂà∂Âæ°

```go
func (smq *SafeMessageQueue) startVisibilityTimeoutChecker() {
    go func() {
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            smq.checkTimeouts()
        }
    }()
}

func (smq *SafeMessageQueue) checkTimeouts() {
    smq.mu.Lock()
    defer smq.mu.Unlock()
    
    now := time.Now()
    for messageID, inFlight := range smq.inFlight {
        if now.After(inFlight.Timeout) {
            // „Çø„Ç§„É†„Ç¢„Ç¶„Éà„Åó„Åü„É°„ÉÉ„Çª„Éº„Ç∏„Çí„Ç≠„É•„Éº„Å´Êàª„Åô
            smq.messages = append(smq.messages, inFlight.Message)
            delete(smq.inFlight, messageID)
        }
    }
}
```

## üöÄ Áô∫Â±ïË™≤È°å (Advanced Challenges)

Âü∫Êú¨ÂÆüË£Ö„ÅåÂÆå‰∫Ü„Åó„Åü„Çâ„ÄÅ‰ª•‰∏ã„ÅÆÁô∫Â±ïÁöÑ„Å™Ê©üËÉΩ„Å´„ÇÇ„ÉÅ„É£„É¨„É≥„Ç∏„Åó„Å¶„Åø„Å¶„Åè„Å†„Åï„ÅÑÔºö

1. **ÂÑ™ÂÖàÂ∫¶„Ç≠„É•„Éº**: „É°„ÉÉ„Çª„Éº„Ç∏ÂÑ™ÂÖàÂ∫¶„Å´Âü∫„Å•„ÅèÂá¶ÁêÜ
2. **„Éê„ÉÉ„ÉÅÂá¶ÁêÜ**: Ë§áÊï∞„É°„ÉÉ„Çª„Éº„Ç∏„ÅÆ‰∏ÄÊã¨Âá¶ÁêÜ
3. **ÂàÜÊï£„Ç≥„Éº„Éá„Ç£„Éç„Éº„Ç∑„Éß„É≥**: Ë§áÊï∞„Éé„Éº„ÉâÈñì„Åß„ÅÆË™øÊï¥
4. **Ê©üÊ¢∞Â≠¶Áøí‰∫àÊ∏¨**: Ë≤†Ëç∑„Éë„Çø„Éº„É≥„ÅÆÂ≠¶Áøí„Å®‰∫àÊ∏¨
5. **„Çº„É≠„ÉÄ„Ç¶„É≥„Çø„Ç§„É†Êõ¥Êñ∞**: ÁÑ°ÂÅúÊ≠¢„Åß„ÅÆ„Ç≥„É≥„Ç∑„É•„Éº„Éû„ÉºÊõ¥Êñ∞

Á´∂Âêà„Ç≥„É≥„Ç∑„É•„Éº„Éû„Éº„Éë„Çø„Éº„É≥„ÅÆÂÆüË£Ö„ÇíÈÄö„Åò„Å¶„ÄÅ„Çπ„Ç±„Éº„É©„Éñ„É´„ÅßÂ†ÖÁâ¢„Å™ÂàÜÊï£„Ç∑„Çπ„ÉÜ„É†„ÅÆÊßãÁØâÊâãÊ≥ï„ÇíÁøíÂæó„Åó„Åæ„Åó„Çá„ÅÜÔºÅ