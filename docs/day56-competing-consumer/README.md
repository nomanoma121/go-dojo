# Day 56: ç«¶åˆã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³

## ğŸ¯ æœ¬æ—¥ã®ç›®æ¨™ (Today's Goal)

ç«¶åˆã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè£…ã—ã€è¤‡æ•°ã®ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ãŒåŒä¸€ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å®‰å…¨ã«å–å¾—ãƒ»å‡¦ç†ã™ã‚‹ä»•çµ„ã¿ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚è² è·åˆ†æ•£ã€ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’å®Ÿç¾ã™ã‚‹åŒ…æ‹¬çš„ãªã‚·ã‚¹ãƒ†ãƒ ã‚’ç¿’å¾—ã™ã‚‹ã€‚

## ğŸ“– è§£èª¬ (Explanation)

### ç«¶åˆã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã¯

ç«¶åˆã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCompeting Consumer Patternï¼‰ã¯ã€è¤‡æ•°ã®ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒåŒä¸€ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ç«¶åˆçš„ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—ã—å‡¦ç†ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚ã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚Šã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®å‘ä¸Šã¨å¯ç”¨æ€§ã®ç¢ºä¿ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚

```go
// ã€ç«¶åˆã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ã®é‡è¦æ€§ã€‘é«˜å¯ç”¨æ€§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ³ã‚°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
// âŒ å•é¡Œä¾‹ï¼šå˜ä¸€ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ã«ã‚ˆã‚‹å‡¦ç†ãƒœãƒˆãƒ«ãƒãƒƒã‚¯
func catastrophicSingleConsumerProcessing() {
    // ğŸš¨ ç½å®³ä¾‹ï¼šå˜ä¸€ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ãŒå…¨å‡¦ç†ã‚’æ‹…å½“
    
    messageQueue := make(chan Message, 10000)
    
    // ã€è‡´å‘½çš„å•é¡Œã€‘å˜ä¸€ã®ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ãŒå…¨è²¬ä»»ã‚’è² ã†
    for {
        message := <-messageQueue
        
        // ã€ç½å®³ã‚·ãƒŠãƒªã‚ªã€‘ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ãŒé‡ã„å ´åˆ
        if err := processHeavyMessage(message); err != nil {
            log.Printf("âŒ Processing failed: %v", err)
            // çµæœï¼š1ã¤ã®å‡¦ç†å¤±æ•—ã§å…¨ã‚·ã‚¹ãƒ†ãƒ ãŒåœæ­¢
            //
            // ã€å®Ÿéš›ã®è¢«å®³ä¾‹ã€‘ï¼š
            // ãƒ–ãƒ©ãƒƒã‚¯ãƒ•ãƒ©ã‚¤ãƒ‡ãƒ¼ï¼šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æµå…¥é‡ãŒæ€¥å¢—
            // â†’ å˜ä¸€ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ãŒå‡¦ç†ã—ãã‚Œãªã„
            // â†’ ã‚­ãƒ¥ãƒ¼ãŒæº€æ¯ã«ãªã‚Šæ–°è¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒç ´æ£„
            // â†’ æ³¨æ–‡å‡¦ç†ãŒå®Œå…¨åœæ­¢ï¼ˆ1æ™‚é–“ã§5å„„å††ã®å£²ä¸Šæå¤±ï¼‰
            // â†’ é¡§å®¢ã‹ã‚‰ã®ã‚¯ãƒ¬ãƒ¼ãƒ æ®ºåˆ°
            // â†’ ã‚·ã‚¹ãƒ†ãƒ å¾©æ—§ã¾ã§8æ™‚é–“ï¼ˆæ‰‹å‹•ã§ã®ç·Šæ€¥å¯¾å¿œï¼‰
            // â†’ ç«¶åˆä»–ç¤¾ã¸ã®é¡§å®¢æµå‡º
            //
            // ã€å…·ä½“çš„ãªéšœå®³ã€‘ï¼š
            // - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†é€Ÿåº¦: 100ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸/ç§’
            // - ãƒ”ãƒ¼ã‚¯æ™‚æµå…¥é‡: 5000ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸/ç§’  
            // - è“„ç©ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: 1æ™‚é–“ã§20ä¸‡ä»¶
            // - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: 32GB -> ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ãƒƒã‚·ãƒ¥
            // - å¾©æ—§æ™‚é–“: æ‰‹å‹•ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã§8æ™‚é–“
            continue
        }
        
        log.Printf("Message %s processed", message.ID)
    }
}

// âœ… æ­£è§£ï¼šã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç´šç«¶åˆã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ã‚·ã‚¹ãƒ†ãƒ 
type EnterpriseCompetingConsumerSystem struct {
    // ã€åŸºæœ¬ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ç®¡ç†ã€‘
    consumerPool        *ConsumerPool           // ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ãƒ—ãƒ¼ãƒ«
    messageQueue        *ScalableMessageQueue   // ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã‚­ãƒ¥ãƒ¼
    loadBalancer        *SmartLoadBalancer      // é«˜åº¦è² è·åˆ†æ•£
    healthMonitor       *ConsumerHealthMonitor  // ãƒ˜ãƒ«ã‚¹ç›£è¦–
    
    // ã€é«˜åº¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ©Ÿèƒ½ã€‘
    autoScaler          *AdaptiveAutoScaler     // é©å¿œçš„è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    resourceMonitor     *ResourceMonitor        // ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
    performancePredictor *PerformancePredictor  // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
    capacityPlanner     *CapacityPlanner        // å®¹é‡è¨ˆç”»
    
    // ã€éšœå®³å¯¾å¿œãƒ»å›å¾©åŠ›ã€‘
    failoverManager     *FailoverManager        // ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ç®¡ç†
    circuitBreaker      *CircuitBreaker         // ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼
    retryHandler        *RetryHandler          // ãƒªãƒˆãƒ©ã‚¤åˆ¶å¾¡
    deadLetterQueue     *DeadLetterQueue       // Dead Letter Queue
    
    // ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†æœ€é©åŒ–ã€‘
    batchProcessor      *BatchProcessor        // ãƒãƒƒãƒå‡¦ç†
    priorityQueue       *PriorityQueue         // å„ªå…ˆåº¦ã‚­ãƒ¥ãƒ¼
    messageDeduplicator *MessageDeduplicator   // é‡è¤‡æ’é™¤
    rateLimiter         *RateLimiter          // ãƒ¬ãƒ¼ãƒˆåˆ¶é™
    
    // ã€ç›£è¦–ãƒ»é‹ç”¨ã€‘
    metricsCollector    *MetricsCollector     // ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
    alertManager        *AlertManager         // ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†
    performanceDashboard *PerformanceDashboard // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
    operationalLogger   *OperationalLogger    // é‹ç”¨ãƒ­ã‚°
}

// ã€åŒ…æ‹¬çš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ã€‘ä¼æ¥­ãƒ¬ãƒ™ãƒ«ã®ç«¶åˆã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼å‡¦ç†
func (ccs *EnterpriseCompetingConsumerSystem) ProcessMessagesConcurrently(ctx context.Context) error {
    log.Printf("ğŸš€ Starting Enterprise Competing Consumer System")
    
    // ã€STEP 1ã€‘ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã¨å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
    if err := ccs.performSystemHealthCheck(); err != nil {
        return fmt.Errorf("system health check failed: %w", err)
    }
    
    // ã€STEP 2ã€‘åˆæœŸã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ãƒ—ãƒ¼ãƒ«ä½œæˆ
    initialConsumerCount := ccs.capacityPlanner.CalculateInitialCapacity()
    for i := 0; i < initialConsumerCount; i++ {
        consumer := ccs.createOptimizedConsumer(fmt.Sprintf("consumer-%d", i))
        ccs.consumerPool.AddConsumer(consumer)
    }
    
    // ã€STEP 3ã€‘å„ç¨®ç›£è¦–ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®ã‚´ãƒ«ãƒ¼ãƒãƒ³èµ·å‹•
    go ccs.startHealthMonitoring(ctx)
    go ccs.startAutoScaling(ctx)
    go ccs.startPerformanceMonitoring(ctx)
    go ccs.startFailoverManager(ctx)
    
    // ã€STEP 4ã€‘ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ãƒ«ãƒ¼ãƒ—
    for {
        select {
        case <-ctx.Done():
            return ccs.gracefulShutdown()
            
        default:
            // ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å–å¾—ã€‘
            if ccs.messageQueue.IsEmpty() {
                time.Sleep(10 * time.Millisecond)
                continue
            }
            
            // ã€è² è·åˆ†æ•£ã«ã‚ˆã‚‹ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼é¸æŠã€‘
            availableConsumer := ccs.loadBalancer.SelectOptimalConsumer(ccs.consumerPool.GetHealthyConsumers())
            if availableConsumer == nil {
                // ã€ç·Šæ€¥ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã€‘åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ãŒãªã„å ´åˆ
                if ccs.autoScaler.CanScaleUp() {
                    newConsumer := ccs.createOptimizedConsumer(fmt.Sprintf("emergency-consumer-%d", time.Now().Unix()))
                    ccs.consumerPool.AddConsumer(newConsumer)
                    availableConsumer = newConsumer
                    
                    ccs.alertManager.SendAlert(&ScalingAlert{
                        Type:    "emergency_scale_up",
                        Reason:  "no_available_consumers",
                        Time:    time.Now(),
                        Details: "Created emergency consumer due to high load",
                    })
                } else {
                    // ã€ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼é©ç”¨ã€‘ã‚·ã‚¹ãƒ†ãƒ ä¿è­·
                    time.Sleep(100 * time.Millisecond)
                    continue
                }
            }
            
            // ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å–å¾—ã¨å‡¦ç†å§”è­²ã€‘
            message, err := ccs.messageQueue.DequeueWithTimeout(5 * time.Second)
            if err != nil {
                log.Printf("âš ï¸ Message dequeue failed: %v", err)
                continue
            }
            
            // ã€éåŒæœŸå‡¦ç†é–‹å§‹ã€‘
            go ccs.processMessageSafely(availableConsumer, message)
        }
    }
}

// ã€å®‰å…¨ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ã€‘åŒ…æ‹¬çš„ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ã
func (ccs *EnterpriseCompetingConsumerSystem) processMessageSafely(consumer *Consumer, message *Message) {
    startTime := time.Now()
    processingID := generateProcessingID()
    
    // ã€å‡¦ç†çŠ¶æ…‹è¿½è·¡ã€‘
    ccs.metricsCollector.RecordMessageProcessingStart(consumer.ID, message.Type)
    
    defer func() {
        processingDuration := time.Since(startTime)
        ccs.metricsCollector.RecordMessageProcessingEnd(consumer.ID, message.Type, processingDuration)
        
        if r := recover(); r != nil {
            // ã€ãƒ‘ãƒ‹ãƒƒã‚¯å›å¾©ã€‘ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ä¿è­·
            ccs.handleConsumerPanic(consumer, message, fmt.Errorf("panic: %v", r))
        }
    }()
    
    // ã€STEP 1ã€‘ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‰å‡¦ç†
    if err := ccs.preprocessMessage(message); err != nil {
        ccs.handlePreprocessingError(consumer, message, err)
        return
    }
    
    // ã€STEP 2ã€‘é‡è¤‡ãƒã‚§ãƒƒã‚¯
    if ccs.messageDeduplicator.IsDuplicate(message.ID) {
        log.Printf("ğŸ”„ Duplicate message detected: %s", message.ID)
        ccs.metricsCollector.RecordDuplicateMessage(message.Type)
        return
    }
    
    // ã€STEP 3ã€‘ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
    if !ccs.rateLimiter.Allow(consumer.ID) {
        // ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Šå‡¦ç†ã‚’é…å»¶
        delay := ccs.rateLimiter.GetBackoffDelay(consumer.ID)
        time.Sleep(delay)
    }
    
    // ã€STEP 4ã€‘ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ãƒã‚§ãƒƒã‚¯
    if ccs.circuitBreaker.IsOpen(message.Type) {
        ccs.sendToDeadLetterQueue(message, "circuit_breaker_open")
        return
    }
    
    // ã€STEP 5ã€‘å®Ÿéš›ã®ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè¡Œ
    processCtx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()
    
    result, err := ccs.executeBusinessLogicWithRetry(processCtx, consumer, message)
    
    if err != nil {
        // ã€ã‚¨ãƒ©ãƒ¼å‡¦ç†ã€‘
        ccs.handleProcessingError(consumer, message, err)
        return
    }
    
    // ã€STEP 6ã€‘å¾Œå‡¦ç†
    if err := ccs.postprocessMessage(message, result); err != nil {
        log.Printf("âš ï¸ Post-processing failed for message %s: %v", message.ID, err)
    }
    
    // ã€STEP 7ã€‘æˆåŠŸãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ã€‘
    ccs.metricsCollector.RecordSuccessfulProcessing(consumer.ID, message.Type)
    consumer.UpdateLastActivity()
    
    log.Printf("âœ… Message %s processed successfully by consumer %s", message.ID, consumer.ID)
}

### ä¸»è¦ãªåˆ©ç‚¹

1. **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼æ•°ã‚’å‹•çš„ã«èª¿æ•´å¯èƒ½
2. **è² è·åˆ†æ•£**: å‡¦ç†è² è·ã‚’è¤‡æ•°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«åˆ†æ•£
3. **é«˜å¯ç”¨æ€§**: ä¸€éƒ¨ã®ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ãŒåœæ­¢ã—ã¦ã‚‚å‡¦ç†ç¶™ç¶š
4. **ãƒ•ã‚©ãƒ«ãƒˆãƒˆãƒ¬ãƒ©ãƒ³ãƒˆ**: éšœå®³ã‹ã‚‰ã®è‡ªå‹•å¾©æ—§

### åŸºæœ¬ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```go
type CompetingConsumerSystem struct {
    messageQueue    MessageQueue
    consumers       map[string]*Consumer
    coordinator     *ConsumerCoordinator
    loadBalancer    LoadBalancer
    healthChecker   *HealthChecker
    metrics         *SystemMetrics
}

type Consumer struct {
    ID              string
    Status          ConsumerStatus
    ProcessingChan  chan *Message
    ErrorChan       chan error
    HeartbeatTicker *time.Ticker
    Processor       MessageProcessor
}

type ConsumerStatus string

const (
    StatusIdle       ConsumerStatus = "idle"
    StatusProcessing ConsumerStatus = "processing"
    StatusFailed     ConsumerStatus = "failed"
    StatusStopped    ConsumerStatus = "stopped"
)
```

### ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã®å®Ÿè£…

```go
type SafeMessageQueue struct {
    messages        []*Message
    inFlight        map[string]*InFlightMessage
    mu              sync.RWMutex
    notifyConsumers chan struct{}
    maxRetries      int
    visibilityTimeout time.Duration
}

type InFlightMessage struct {
    Message       *Message
    ConsumerID    string
    StartTime     time.Time
    RetryCount    int
    Timeout       time.Time
}

func (smq *SafeMessageQueue) Dequeue(consumerID string) (*Message, error) {
    smq.mu.Lock()
    defer smq.mu.Unlock()
    
    if len(smq.messages) == 0 {
        return nil, ErrNoMessages
    }
    
    // FIFOã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
    message := smq.messages[0]
    smq.messages = smq.messages[1:]
    
    // ã‚¤ãƒ³ãƒ•ãƒ©ã‚¤ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦è¿½åŠ 
    inFlight := &InFlightMessage{
        Message:    message,
        ConsumerID: consumerID,
        StartTime:  time.Now(),
        Timeout:    time.Now().Add(smq.visibilityTimeout),
    }
    smq.inFlight[message.ID] = inFlight
    
    return message, nil
}

func (smq *SafeMessageQueue) Acknowledge(messageID, consumerID string) error {
    smq.mu.Lock()
    defer smq.mu.Unlock()
    
    inFlight, exists := smq.inFlight[messageID]
    if !exists {
        return ErrMessageNotFound
    }
    
    if inFlight.ConsumerID != consumerID {
        return ErrUnauthorizedAck
    }
    
    delete(smq.inFlight, messageID)
    return nil
}

func (smq *SafeMessageQueue) Nack(messageID, consumerID string) error {
    smq.mu.Lock()
    defer smq.mu.Unlock()
    
    inFlight, exists := smq.inFlight[messageID]
    if !exists {
        return ErrMessageNotFound
    }
    
    if inFlight.ConsumerID != consumerID {
        return ErrUnauthorizedNack
    }
    
    // å†è©¦è¡Œå›æ•°ã‚’ãƒã‚§ãƒƒã‚¯
    if inFlight.RetryCount >= smq.maxRetries {
        // DLQã«é€ä¿¡
        return smq.sendToDeadLetterQueue(inFlight.Message)
    }
    
    // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚­ãƒ¥ãƒ¼ã«æˆ»ã™
    inFlight.RetryCount++
    smq.messages = append(smq.messages, inFlight.Message)
    delete(smq.inFlight, messageID)
    
    // ä»–ã®ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ã«é€šçŸ¥
    select {
    case smq.notifyConsumers <- struct{}{}:
    default:
    }
    
    return nil
}
```

### è² è·åˆ†æ•£æˆ¦ç•¥

```go
type LoadBalancer interface {
    SelectConsumer(consumers []*Consumer) *Consumer
}

type RoundRobinLoadBalancer struct {
    current int
    mu      sync.Mutex
}

func (rr *RoundRobinLoadBalancer) SelectConsumer(consumers []*Consumer) *Consumer {
    rr.mu.Lock()
    defer rr.mu.Unlock()
    
    availableConsumers := make([]*Consumer, 0)
    for _, consumer := range consumers {
        if consumer.Status == StatusIdle {
            availableConsumers = append(availableConsumers, consumer)
        }
    }
    
    if len(availableConsumers) == 0 {
        return nil
    }
    
    selected := availableConsumers[rr.current%len(availableConsumers)]
    rr.current++
    return selected
}

type WeightedLoadBalancer struct {
    weights map[string]int
    mu      sync.RWMutex
}

func (wlb *WeightedLoadBalancer) SelectConsumer(consumers []*Consumer) *Consumer {
    wlb.mu.RLock()
    defer wlb.mu.RUnlock()
    
    totalWeight := 0
    for _, consumer := range consumers {
        if consumer.Status == StatusIdle {
            totalWeight += wlb.weights[consumer.ID]
        }
    }
    
    if totalWeight == 0 {
        return nil
    }
    
    rand.Seed(time.Now().UnixNano())
    target := rand.Intn(totalWeight)
    
    current := 0
    for _, consumer := range consumers {
        if consumer.Status == StatusIdle {
            current += wlb.weights[consumer.ID]
            if current > target {
                return consumer
            }
        }
    }
    
    return nil
}

type LeastConnectionsLoadBalancer struct {
    connections map[string]int
    mu          sync.RWMutex
}

func (lcb *LeastConnectionsLoadBalancer) SelectConsumer(consumers []*Consumer) *Consumer {
    lcb.mu.RLock()
    defer lcb.mu.RUnlock()
    
    var selected *Consumer
    minConnections := int(^uint(0) >> 1) // max int
    
    for _, consumer := range consumers {
        if consumer.Status == StatusIdle {
            connections := lcb.connections[consumer.ID]
            if connections < minConnections {
                minConnections = connections
                selected = consumer
            }
        }
    }
    
    return selected
}
```

### ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã¨ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼

```go
type HealthChecker struct {
    consumers       map[string]*Consumer
    checkInterval   time.Duration
    healthTimeout   time.Duration
    failureThreshold int
    failures        map[string]int
    mu              sync.RWMutex
}

func (hc *HealthChecker) StartMonitoring(ctx context.Context) {
    ticker := time.NewTicker(hc.checkInterval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            hc.performHealthChecks()
        case <-ctx.Done():
            return
        }
    }
}

func (hc *HealthChecker) performHealthChecks() {
    hc.mu.Lock()
    defer hc.mu.Unlock()
    
    for consumerID, consumer := range hc.consumers {
        if err := hc.checkConsumerHealth(consumer); err != nil {
            hc.failures[consumerID]++
            
            if hc.failures[consumerID] >= hc.failureThreshold {
                consumer.Status = StatusFailed
                hc.triggerFailover(consumer)
            }
        } else {
            hc.failures[consumerID] = 0
            if consumer.Status == StatusFailed {
                consumer.Status = StatusIdle
            }
        }
    }
}

func (hc *HealthChecker) checkConsumerHealth(consumer *Consumer) error {
    // ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
    if time.Since(consumer.LastHeartbeat) > hc.healthTimeout {
        return errors.New("heartbeat timeout")
    }
    
    // ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒã‚¹ãƒã‚§ãƒƒã‚¯
    healthCheck := make(chan error, 1)
    go func() {
        healthCheck <- consumer.Ping()
    }()
    
    select {
    case err := <-healthCheck:
        return err
    case <-time.After(hc.healthTimeout):
        return errors.New("health check timeout")
    }
}

func (hc *HealthChecker) triggerFailover(failedConsumer *Consumer) {
    // ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ãƒ­ã‚¸ãƒƒã‚¯
    // 1. å‡¦ç†ä¸­ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä»–ã®ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ã«å†é…å¸ƒ
    // 2. æ–°ã—ã„ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®èµ·å‹•
    // 3. ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
}
```

### å‹•çš„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

```go
type AutoScaler struct {
    minConsumers    int
    maxConsumers    int
    scaleUpThreshold   float64
    scaleDownThreshold float64
    cooldownPeriod     time.Duration
    lastScaleAction    time.Time
    metrics           *SystemMetrics
    consumerFactory   ConsumerFactory
    mu               sync.RWMutex
}

func (as *AutoScaler) MonitorAndScale(ctx context.Context, system *CompetingConsumerSystem) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            as.evaluateScaling(system)
        case <-ctx.Done():
            return
        }
    }
}

func (as *AutoScaler) evaluateScaling(system *CompetingConsumerSystem) {
    as.mu.Lock()
    defer as.mu.Unlock()
    
    // ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ä¸­ã¯ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ãªã„
    if time.Since(as.lastScaleAction) < as.cooldownPeriod {
        return
    }
    
    currentConsumers := len(system.consumers)
    queueDepth := system.messageQueue.GetDepth()
    avgProcessingTime := as.metrics.GetAverageProcessingTime()
    
    // ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã®åˆ¤å®š
    if queueDepth > 0 && avgProcessingTime > 0 {
        estimatedThroughput := float64(currentConsumers) / avgProcessingTime.Seconds()
        queueGrowthRate := float64(queueDepth) / estimatedThroughput
        
        if queueGrowthRate > as.scaleUpThreshold && currentConsumers < as.maxConsumers {
            as.scaleUp(system)
            return
        }
    }
    
    // ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã®åˆ¤å®š
    if queueDepth == 0 && currentConsumers > as.minConsumers {
        idleConsumers := 0
        for _, consumer := range system.consumers {
            if consumer.Status == StatusIdle {
                idleConsumers++
            }
        }
        
        idleRatio := float64(idleConsumers) / float64(currentConsumers)
        if idleRatio > as.scaleDownThreshold {
            as.scaleDown(system)
        }
    }
}

func (as *AutoScaler) scaleUp(system *CompetingConsumerSystem) {
    newConsumer := as.consumerFactory.CreateConsumer()
    system.AddConsumer(newConsumer)
    as.lastScaleAction = time.Now()
    
    log.Printf("Scaled up: added consumer %s", newConsumer.ID)
}

func (as *AutoScaler) scaleDown(system *CompetingConsumerSystem) {
    // æœ€ã‚‚ã‚¢ã‚¤ãƒ‰ãƒ«æ™‚é–“ã®é•·ã„ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ã‚’åœæ­¢
    var longestIdle *Consumer
    var maxIdleTime time.Duration
    
    for _, consumer := range system.consumers {
        if consumer.Status == StatusIdle {
            idleTime := time.Since(consumer.LastActivity)
            if idleTime > maxIdleTime {
                maxIdleTime = idleTime
                longestIdle = consumer
            }
        }
    }
    
    if longestIdle != nil {
        system.RemoveConsumer(longestIdle.ID)
        as.lastScaleAction = time.Now()
        
        log.Printf("Scaled down: removed consumer %s", longestIdle.ID)
    }
}
```

### ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ã®å®Ÿè£…

```go
type MessageProcessor interface {
    Process(ctx context.Context, message *Message) error
}

type AsyncMessageProcessor struct {
    workerPool  *WorkerPool
    timeout     time.Duration
    retryPolicy RetryPolicy
}

func (amp *AsyncMessageProcessor) Process(ctx context.Context, message *Message) error {
    processCtx, cancel := context.WithTimeout(ctx, amp.timeout)
    defer cancel()
    
    return amp.workerPool.Submit(processCtx, func(ctx context.Context) error {
        return amp.processWithRetry(ctx, message)
    })
}

func (amp *AsyncMessageProcessor) processWithRetry(ctx context.Context, message *Message) error {
    var lastErr error
    
    for attempt := 0; attempt < amp.retryPolicy.MaxAttempts; attempt++ {
        if attempt > 0 {
            delay := amp.retryPolicy.CalculateDelay(attempt)
            select {
            case <-time.After(delay):
            case <-ctx.Done():
                return ctx.Err()
            }
        }
        
        if err := amp.processMessage(ctx, message); err != nil {
            lastErr = err
            if !amp.retryPolicy.ShouldRetry(err) {
                break
            }
            continue
        }
        
        return nil
    }
    
    return lastErr
}
```

## ğŸ“ èª²é¡Œ (The Problem)

ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æŒã¤åŒ…æ‹¬çš„ãªç«¶åˆã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š

### 1. åŸºæœ¬æ©Ÿèƒ½
- å®‰å…¨ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼
- è¤‡æ•°ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ã®ç®¡ç†
- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å¯è¦–æ€§åˆ¶å¾¡

### 2. è² è·åˆ†æ•£
- ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³æ–¹å¼
- é‡ã¿ä»˜ãåˆ†æ•£
- æœ€å°æ¥ç¶šæ•°æ–¹å¼

### 3. éšœå®³å‡¦ç†
- ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
- è‡ªå‹•ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼
- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å†å‡¦ç†

### 4. ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£
- å‹•çš„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
- è² è·äºˆæ¸¬

### 5. é‹ç”¨æ©Ÿèƒ½
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
- ãƒ­ã‚°è¨˜éŒ²
- ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½

## âœ… æœŸå¾…ã•ã‚Œã‚‹æŒ™å‹• (Expected Behavior)

å®Ÿè£…ãŒæ­£ã—ãå®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ†ã‚¹ãƒˆçµæœãŒå¾—ã‚‰ã‚Œã¾ã™ï¼š

```bash
$ go test -v
=== RUN   TestCompetingConsumer_BasicOperation
    main_test.go:45: Multiple consumers processing messages correctly
--- PASS: TestCompetingConsumer_BasicOperation (0.02s)

=== RUN   TestCompetingConsumer_LoadBalancing
    main_test.go:65: Load balancing distributing work evenly
--- PASS: TestCompetingConsumer_LoadBalancing (0.03s)

=== RUN   TestCompetingConsumer_Failover
    main_test.go:85: Failover handling working correctly
--- PASS: TestCompetingConsumer_Failover (0.04s)

PASS
ok      day56-competing-consumer   0.156s
```

## ğŸ’¡ ãƒ’ãƒ³ãƒˆ (Hints)

å®Ÿè£…ã«è©°ã¾ã£ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®ãƒ’ãƒ³ãƒˆã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š

### åŸºæœ¬çš„ãªã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼å®Ÿè£…

```go
func (c *Consumer) Start(ctx context.Context, queue MessageQueue) {
    go func() {
        for {
            select {
            case <-ctx.Done():
                return
            default:
                message, err := queue.Dequeue(c.ID)
                if err != nil {
                    time.Sleep(100 * time.Millisecond)
                    continue
                }
                
                c.processMessage(ctx, message, queue)
            }
        }
    }()
}
```

### ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å¯è¦–æ€§åˆ¶å¾¡

```go
func (smq *SafeMessageQueue) startVisibilityTimeoutChecker() {
    go func() {
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            smq.checkTimeouts()
        }
    }()
}

func (smq *SafeMessageQueue) checkTimeouts() {
    smq.mu.Lock()
    defer smq.mu.Unlock()
    
    now := time.Now()
    for messageID, inFlight := range smq.inFlight {
        if now.After(inFlight.Timeout) {
            // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚­ãƒ¥ãƒ¼ã«æˆ»ã™
            smq.messages = append(smq.messages, inFlight.Message)
            delete(smq.inFlight, messageID)
        }
    }
}
```

## ğŸš€ ç™ºå±•èª²é¡Œ (Advanced Challenges)

åŸºæœ¬å®Ÿè£…ãŒå®Œäº†ã—ãŸã‚‰ã€ä»¥ä¸‹ã®ç™ºå±•çš„ãªæ©Ÿèƒ½ã«ã‚‚ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ã¦ã¿ã¦ãã ã•ã„ï¼š

1. **å„ªå…ˆåº¦ã‚­ãƒ¥ãƒ¼**: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å„ªå…ˆåº¦ã«åŸºã¥ãå‡¦ç†
2. **ãƒãƒƒãƒå‡¦ç†**: è¤‡æ•°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä¸€æ‹¬å‡¦ç†
3. **åˆ†æ•£ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚·ãƒ§ãƒ³**: è¤‡æ•°ãƒãƒ¼ãƒ‰é–“ã§ã®èª¿æ•´
4. **æ©Ÿæ¢°å­¦ç¿’äºˆæ¸¬**: è² è·ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­¦ç¿’ã¨äºˆæ¸¬
5. **ã‚¼ãƒ­ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ æ›´æ–°**: ç„¡åœæ­¢ã§ã®ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼æ›´æ–°

ç«¶åˆã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®Ÿè£…ã‚’é€šã˜ã¦ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§å …ç‰¢ãªåˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰æ‰‹æ³•ã‚’ç¿’å¾—ã—ã¾ã—ã‚‡ã†ï¼