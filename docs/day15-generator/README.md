# Day 15: Generatorãƒ‘ã‚¿ãƒ¼ãƒ³

## ğŸ¯ æœ¬æ—¥ã®ç›®æ¨™ (Today's Goal)

ãƒãƒ£ãƒãƒ«ã¨ã‚¸ã‚§ãƒãƒªã‚¯ã‚¹ã‚’ä½¿ã£ãŸé…å»¶è©•ä¾¡ã®Generatorãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè£…ã—ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®è‰¯ã„ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã®æ¦‚å¿µã‚’ç†è§£ã™ã‚‹ã€‚

## ğŸ“– è§£èª¬ (Explanation)

### Generatorãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã¯

Generatorãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã€å€¤ã‚’é€æ¬¡ç”Ÿæˆã—ã¦æä¾›ã™ã‚‹ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã«ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã‚€ã®ã§ã¯ãªãã€å¿…è¦ã«å¿œã˜ã¦å€¤ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®è‰¯ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚

### å¾“æ¥ã®å‡¦ç†ã¨ã®æ¯”è¼ƒ

```go
// ã€Generatorãƒ‘ã‚¿ãƒ¼ãƒ³ã®é‡è¦æ€§ã€‘ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã¨é…å»¶è©•ä¾¡ã«ã‚ˆã‚‹æœ€é©åŒ–
// âŒ å•é¡Œä¾‹ï¼šä¸€æ‹¬å‡¦ç†ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªæ¯æ¸‡ã¨ã‚·ã‚¹ãƒ†ãƒ éšœå®³
func disastrousEagerProcessing() {
    // ğŸš¨ ç½å®³ä¾‹ï¼šå¤§é‡ãƒ‡ãƒ¼ã‚¿ã®ä¸€æ‹¬èª­ã¿è¾¼ã¿ã§ã‚·ã‚¹ãƒ†ãƒ å´©å£Š
    log.Printf("Processing 10 million records eagerly...")
    
    // âŒ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã«ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¿
    var allUsers []User
    
    // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰1000ä¸‡ä»¶ã‚’ä¸€åº¦ã«å–å¾—
    rows, err := db.Query("SELECT id, name, email, profile FROM users")
    if err != nil {
        log.Fatal("Query failed:", err)
    }
    defer rows.Close()
    
    for rows.Next() {
        var user User
        rows.Scan(&user.ID, &user.Name, &user.Email, &user.Profile)
        allUsers = append(allUsers, user)
        
        // âŒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒæŒ‡æ•°é–¢æ•°çš„ã«å¢—å¤§
        // 1000ä¸‡ä»¶ Ã— å¹³å‡1KB = 10GBä»¥ä¸Šã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨
        // âŒ ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒé »ç™ºã—ã¦CPUä½¿ç”¨ç‡100%
        // âŒ ã‚¹ãƒ¯ãƒƒãƒ—ç™ºç”Ÿã§ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ãŒå¿œç­”ä¸èƒ½
    }
    
    log.Printf("âŒ Loaded %d users into memory (%.2f GB used)", 
        len(allUsers), float64(len(allUsers)*1024)/1024/1024/1024)
    
    // ã€å‡¦ç†é–‹å§‹ã€‘ã™ã§ã«æ‰‹é…ã‚Œ
    for i, user := range allUsers {
        processUser(user) // CPUé›†ç´„çš„ãªå‡¦ç†
        
        if i%100000 == 0 {
            // âŒ ã“ã®æ™‚ç‚¹ã§ãƒ¡ãƒ¢ãƒªä¸è¶³ã§ãƒ—ãƒ­ã‚»ã‚¹å¼·åˆ¶çµ‚äº†
            log.Printf("Processed %d users...", i)
            // OOM Killerç™ºå‹•ã€ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢
        }
    }
    // çµæœï¼šã‚µãƒ¼ãƒãƒ¼ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã€ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢ã€é¡§å®¢å½±éŸ¿ã€ã‚¤ãƒ³ãƒ•ãƒ©ã‚³ã‚¹ãƒˆå¢—å¤§
}

// âœ… æ­£è§£ï¼šãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³å“è³ªã®Generatorãƒ‘ã‚¿ãƒ¼ãƒ³å®Ÿè£…
// ã€é…å»¶è©•ä¾¡ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’æœ€å¤§åŒ–ã€‘
type EnterpriseGenerator[T any] struct {
    // ã€åŸºæœ¬æ§‹æˆã€‘
    ch          <-chan T             // ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒªãƒ¼ãƒ 
    cancel      context.CancelFunc   // ã‚­ãƒ£ãƒ³ã‚»ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡
    ctx         context.Context      // ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†
    
    // ã€é«˜åº¦ãªæ©Ÿèƒ½ã€‘
    buffer      chan T               // ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°æ©Ÿèƒ½
    bufferSize  int                  // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º
    
    // ã€ç›£è¦–ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€‘
    generated   int64                // ç”Ÿæˆæ¸ˆã¿è¦ç´ æ•°
    consumed    int64                // æ¶ˆè²»æ¸ˆã¿è¦ç´ æ•°
    startTime   time.Time            // ç”Ÿæˆé–‹å§‹æ™‚åˆ»
    
    // ã€ã‚¨ãƒ©ãƒ¼å‡¦ç†ã€‘
    errorChan   chan error           // ã‚¨ãƒ©ãƒ¼é€šçŸ¥ãƒãƒ£ãƒãƒ«
    logger      *log.Logger          // ãƒ­ã‚°å‡ºåŠ›
    
    // ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã€‘
    batchSize   int                  // ãƒãƒƒãƒå‡¦ç†ã‚µã‚¤ã‚º
    prefetch    bool                 // ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒæœ‰åŠ¹åŒ–
}

// ã€é‡è¦é–¢æ•°ã€‘ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†Generator
func NewMemoryEfficientUserGenerator(ctx context.Context, batchSize int) *EnterpriseGenerator[User] {
    generatorCtx, cancel := context.WithCancel(ctx)
    
    gen := &EnterpriseGenerator[User]{
        cancel:     cancel,
        ctx:        generatorCtx,
        bufferSize: 1000,               // 1000ä»¶ã®ãƒãƒƒãƒ•ã‚¡
        batchSize:  batchSize,          // ãƒãƒƒãƒã‚µã‚¤ã‚º
        startTime:  time.Now(),
        logger:     log.New(os.Stdout, "[GENERATOR] ", log.LstdFlags),
        errorChan:  make(chan error, 10),
    }
    
    // ãƒãƒƒãƒ•ã‚¡ä»˜ããƒãƒ£ãƒãƒ«ä½œæˆ
    gen.buffer = make(chan User, gen.bufferSize)
    gen.ch = gen.buffer
    
    // ã€é‡è¦ã€‘éåŒæœŸã§ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé–‹å§‹
    go gen.generateUsersLazily()
    
    gen.logger.Printf("ğŸš€ Memory-efficient generator started (batch: %d, buffer: %d)", 
        batchSize, gen.bufferSize)
    
    return gen
}

// ã€æ ¸å¿ƒãƒ¡ã‚½ãƒƒãƒ‰ã€‘é…å»¶è©•ä¾¡ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
func (g *EnterpriseGenerator[User]) generateUsersLazily() {
    defer close(g.buffer)
    defer close(g.errorChan)
    
    offset := 0
    
    for {
        select {
        case <-g.ctx.Done():
            g.logger.Printf("ğŸ›‘ Generator cancelled after %d items", 
                atomic.LoadInt64(&g.generated))
            return
            
        default:
            // ã€ãƒãƒƒãƒã‚¯ã‚¨ãƒªã€‘å°‘é‡ãšã¤ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—
            query := `SELECT id, name, email, profile FROM users 
                     ORDER BY id LIMIT ? OFFSET ?`
            
            rows, err := db.QueryContext(g.ctx, query, g.batchSize, offset)
            if err != nil {
                g.errorChan <- fmt.Errorf("batch query failed at offset %d: %w", offset, err)
                return
            }
            
            batchCount := 0
            batchStart := time.Now()
            
            for rows.Next() {
                var user User
                if err := rows.Scan(&user.ID, &user.Name, &user.Email, &user.Profile); err != nil {
                    rows.Close()
                    g.errorChan <- fmt.Errorf("scan failed: %w", err)
                    return
                }
                
                // ã€é‡è¦ã€‘ãƒãƒƒãƒ•ã‚¡ãŒãƒ•ãƒ«ã®å ´åˆã¯æ¶ˆè²»è€…ã‚’å¾…æ©Ÿ
                select {
                case g.buffer <- user:
                    atomic.AddInt64(&g.generated, 1)
                    batchCount++
                    
                case <-g.ctx.Done():
                    rows.Close()
                    return
                }
            }
            rows.Close()
            
            batchDuration := time.Since(batchStart)
            
            if batchCount == 0 {
                // ãƒ‡ãƒ¼ã‚¿çµ‚äº†
                g.logger.Printf("âœ… Generation completed: %d total items in %v", 
                    atomic.LoadInt64(&g.generated), time.Since(g.startTime))
                return
            }
            
            g.logger.Printf("ğŸ“¦ Batch loaded: %d items (offset: %d, took: %v, rate: %.0f items/sec)", 
                batchCount, offset, batchDuration, float64(batchCount)/batchDuration.Seconds())
            
            offset += g.batchSize
            
            // ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã€‘å°‘ã—å¾…æ©Ÿã—ã¦GCã«ä½™è£•ã‚’ä¸ãˆã‚‹
            if offset%10000 == 0 {
                runtime.GC()
                time.Sleep(10 * time.Millisecond)
            }
        }
    }
}

// ã€é‡è¦ãƒ¡ã‚½ãƒƒãƒ‰ã€‘ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–ä»˜ãè¦ç´ å–å¾—
func (g *EnterpriseGenerator[User]) Next() (User, bool) {
    select {
    case user, ok := <-g.ch:
        if ok {
            atomic.AddInt64(&g.consumed, 1)
            
            // ã€å®šæœŸãƒ¬ãƒãƒ¼ãƒˆã€‘
            consumed := atomic.LoadInt64(&g.consumed)
            if consumed%10000 == 0 {
                generated := atomic.LoadInt64(&g.generated)
                var m runtime.MemStats
                runtime.ReadMemStats(&m)
                
                g.logger.Printf("ğŸ“Š Progress: consumed=%d, generated=%d, memory=%.2fMB", 
                    consumed, generated, float64(m.Alloc)/1024/1024)
            }
        }
        return user, ok
        
    case <-g.ctx.Done():
        var zero User
        return zero, false
    }
}

// ã€å®Ÿç”¨ä¾‹ã€‘ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†
func EfficientBigDataProcessing() {
    ctx := context.Background()
    
    // ã€åˆæœŸåŒ–ã€‘1000ä»¶ãšã¤ãƒãƒƒãƒå‡¦ç†
    generator := NewMemoryEfficientUserGenerator(ctx, 1000)
    defer generator.Cancel()
    
    processedCount := 0
    errorCount := 0
    startTime := time.Now()
    
    log.Printf("ğŸš€ Starting memory-efficient processing of millions of users")
    
    // ã€ã‚¨ãƒ©ãƒ¼ç›£è¦–ã€‘
    go func() {
        for err := range generator.GetErrors() {
            log.Printf("âŒ Generator error: %v", err)
            errorCount++
        }
    }()
    
    // ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„å‡¦ç†ã€‘ä¸€åº¦ã«1ä»¶ãšã¤å‡¦ç†
    for {
        user, ok := generator.Next()
        if !ok {
            break
        }
        
        // ã€å®Ÿéš›ã®å‡¦ç†ã€‘CPUã‚’ä½¿ã†é‡ã„å‡¦ç†ã‚‚å®‰å…¨
        if err := processUserWithMLAnalysis(user); err != nil {
            log.Printf("âŒ Processing failed for user %d: %v", user.ID, err)
            errorCount++
            continue
        }
        
        processedCount++
        
        // ã€å®šæœŸãƒ¬ãƒãƒ¼ãƒˆã€‘
        if processedCount%50000 == 0 {
            elapsed := time.Since(startTime)
            rate := float64(processedCount) / elapsed.Seconds()
            
            var m runtime.MemStats
            runtime.ReadMemStats(&m)
            
            log.Printf("âœ… Processed %d users (%.0f/sec, memory: %.2fMB, errors: %d)", 
                processedCount, rate, float64(m.Alloc)/1024/1024, errorCount)
        }
    }
    
    totalTime := time.Since(startTime)
    finalRate := float64(processedCount) / totalTime.Seconds()
    
    log.Printf("ğŸ¯ Processing completed:")
    log.Printf("   Total processed: %d users", processedCount)
    log.Printf("   Total errors: %d", errorCount)
    log.Printf("   Processing time: %v", totalTime)
    log.Printf("   Processing rate: %.0f users/sec", finalRate)
    log.Printf("   Success rate: %.2f%%", float64(processedCount)/(float64(processedCount+errorCount))*100)
    
    // ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç¢ºèªã€‘
    var m runtime.MemStats
    runtime.ReadMemStats(&m)
    log.Printf("   Final memory usage: %.2fMB (peak: %.2fMB)", 
        float64(m.Alloc)/1024/1024, float64(m.Sys)/1024/1024)
}

// ã€é«˜åº¦ãªæ©Ÿèƒ½ã€‘ä¸¦åˆ—å‡¦ç†å¯¾å¿œGenerator
func processUserWithMLAnalysis(user User) error {
    // æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹åˆ†æå‡¦ç†ï¼ˆCPUé›†ç´„çš„ï¼‰
    time.Sleep(100 * time.Millisecond) // é‡ã„å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    
    // 10%ã®ç¢ºç‡ã§ã‚¨ãƒ©ãƒ¼
    if rand.Float64() < 0.1 {
        return fmt.Errorf("ML analysis failed for user %d", user.ID)
    }
    
    return nil
}
```

### Goã§ã®å®Ÿè£…ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

Goã§ã¯ã€ãƒãƒ£ãƒãƒ«ã¨Goroutineã‚’ä½¿ã£ã¦Generatorãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

#### 1. ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³å“è³ªã®åŸºæœ¬æ§‹é€ 

```go
// ã€ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³å“è³ªã€‘å‹å®‰å…¨ã§é«˜æ€§èƒ½ãªGenerator
type Generator[T any] struct {
    // ã€åŸºæœ¬æ©Ÿèƒ½ã€‘
    ch          <-chan T              // èª­ã¿å–ã‚Šå°‚ç”¨ãƒãƒ£ãƒãƒ«
    cancel      context.CancelFunc    // ã‚­ãƒ£ãƒ³ã‚»ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡
    ctx         context.Context       // ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†
    
    // ã€é«˜åº¦ãªæ©Ÿèƒ½ã€‘
    buffer      int                   // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º
    generated   *atomic.Int64         // ç”Ÿæˆæ•°ã‚«ã‚¦ãƒ³ã‚¿ï¼ˆthread-safeï¼‰
    consumed    *atomic.Int64         // æ¶ˆè²»æ•°ã‚«ã‚¦ãƒ³ã‚¿ï¼ˆthread-safeï¼‰
    
    // ã€ã‚¨ãƒ©ãƒ¼å‡¦ç†ã€‘
    errorChan   <-chan error          // ã‚¨ãƒ©ãƒ¼é€šçŸ¥ãƒãƒ£ãƒãƒ«
    onError     func(error)           // ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©
    
    // ã€çŠ¶æ…‹ç®¡ç†ã€‘
    state       *atomic.Int32         // 0:running, 1:completed, 2:cancelled
    startTime   time.Time             // é–‹å§‹æ™‚åˆ»
    
    // ã€ç›£è¦–æ©Ÿèƒ½ã€‘
    metrics     *GeneratorMetrics     // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    logger      *log.Logger           // ãƒ­ã‚°å‡ºåŠ›
}

// GeneratorFunc defines the function signature for generator functions
type GeneratorFunc[T any] func(ctx context.Context, yield func(T) bool) error

// GeneratorMetrics tracks performance statistics
type GeneratorMetrics struct {
    ItemsGenerated   int64         // ç”Ÿæˆã•ã‚ŒãŸã‚¢ã‚¤ãƒ†ãƒ æ•°
    ItemsConsumed    int64         // æ¶ˆè²»ã•ã‚ŒãŸã‚¢ã‚¤ãƒ†ãƒ æ•°  
    GenerationRate   float64       // ç”Ÿæˆãƒ¬ãƒ¼ãƒˆï¼ˆitems/secï¼‰
    ConsumptionRate  float64       // æ¶ˆè²»ãƒ¬ãƒ¼ãƒˆï¼ˆitems/secï¼‰
    BufferUtilization float64      // ãƒãƒƒãƒ•ã‚¡åˆ©ç”¨ç‡
    ErrorCount       int64         // ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿå›æ•°
    LastActivity     time.Time     // æœ€çµ‚æ´»å‹•æ™‚åˆ»
}
```

#### 2. ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ¬ãƒ™ãƒ«Generatorä½œæˆ

```go
// ã€é‡è¦é–¢æ•°ã€‘é«˜æ€§èƒ½ã§ã‚¨ãƒ©ãƒ¼è€æ€§ã®ã‚ã‚‹Generatorä½œæˆ
func NewEnterpriseGenerator[T any](
    ctx context.Context, 
    fn GeneratorFunc[T], 
    bufferSize int,
) *Generator[T] {
    if bufferSize <= 0 {
        bufferSize = 100 // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º
    }
    
    generatorCtx, cancel := context.WithCancel(ctx)
    
    // ãƒãƒ£ãƒãƒ«ä½œæˆï¼ˆãƒãƒƒãƒ•ã‚¡ä»˜ãï¼‰
    dataChan := make(chan T, bufferSize)
    errorChan := make(chan error, 10)
    
    // ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆæœŸåŒ–
    metrics := &GeneratorMetrics{
        LastActivity: time.Now(),
    }
    
    generator := &Generator[T]{
        ch:          dataChan,
        cancel:      cancel,
        ctx:         generatorCtx,
        buffer:      bufferSize,
        generated:   &atomic.Int64{},
        consumed:    &atomic.Int64{},
        errorChan:   errorChan,
        state:       &atomic.Int32{}, // 0 = running
        startTime:   time.Now(),
        metrics:     metrics,
        logger:      log.New(os.Stdout, "[GENERATOR] ", log.LstdFlags),
    }
    
    // ã€é‡è¦ã€‘éåŒæœŸã§ç”Ÿæˆå‡¦ç†é–‹å§‹
    go generator.runGeneratorWithRecovery(fn, dataChan, errorChan)
    
    // ã€é‡è¦ã€‘ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°goroutineé–‹å§‹  
    go generator.updateMetrics()
    
    generator.logger.Printf("ğŸš€ Enterprise generator started (buffer: %d)", bufferSize)
    return generator
}

// ã€æ ¸å¿ƒãƒ¡ã‚½ãƒƒãƒ‰ã€‘ãƒ‘ãƒ‹ãƒƒã‚¯å›å¾©ä»˜ãGeneratorå®Ÿè¡Œ
func (g *Generator[T]) runGeneratorWithRecovery(
    fn GeneratorFunc[T], 
    dataChan chan<- T,
    errorChan chan<- error,
) {
    defer func() {
        close(dataChan)
        close(errorChan)
        g.state.Store(1) // completed
        
        // ãƒ‘ãƒ‹ãƒƒã‚¯å›å¾©
        if r := recover(); r != nil {
            g.logger.Printf("âŒ Generator panic recovered: %v", r)
            if g.onError != nil {
                g.onError(fmt.Errorf("generator panic: %v", r))
            }
        }
        
        generated := g.generated.Load()
        duration := time.Since(g.startTime)
        rate := float64(generated) / duration.Seconds()
        
        g.logger.Printf("âœ… Generator completed: %d items in %v (%.0f items/sec)", 
            generated, duration, rate)
    }()
    
    // yieldé–¢æ•°ã®å®šç¾©ï¼ˆthread-safeï¼‰
    yield := func(value T) bool {
        select {
        case dataChan <- value:
            count := g.generated.Add(1)
            g.metrics.LastActivity = time.Now()
            
            // å®šæœŸçš„ãªãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ
            if count%10000 == 0 {
                g.logger.Printf("ğŸ“Š Generated %d items", count)
            }
            return true
            
        case <-g.ctx.Done():
            g.state.Store(2) // cancelled
            return false
        }
    }
    
    // ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ã®ç”Ÿæˆé–¢æ•°å®Ÿè¡Œ
    if err := fn(g.ctx, yield); err != nil {
        select {
        case errorChan <- err:
            g.logger.Printf("âŒ Generator function error: %v", err)
        case <-g.ctx.Done():
        }
    }
}

// ã€ç›£è¦–æ©Ÿèƒ½ã€‘ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
func (g *Generator[T]) updateMetrics() {
    ticker := time.NewTicker(5 * time.Second)
    defer ticker.Stop()
    
    var lastGenerated, lastConsumed int64
    var lastTime = time.Now()
    
    for {
        select {
        case <-ticker.C:
            now := time.Now()
            elapsed := now.Sub(lastTime).Seconds()
            
            currentGenerated := g.generated.Load()
            currentConsumed := g.consumed.Load()
            
            // ãƒ¬ãƒ¼ãƒˆè¨ˆç®—
            generationRate := float64(currentGenerated-lastGenerated) / elapsed
            consumptionRate := float64(currentConsumed-lastConsumed) / elapsed
            
            // ãƒãƒƒãƒ•ã‚¡åˆ©ç”¨ç‡è¨ˆç®—
            bufferUtilization := float64(currentGenerated-currentConsumed) / float64(g.buffer) * 100
            if bufferUtilization > 100 {
                bufferUtilization = 100
            }
            
            // ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
            g.metrics.GenerationRate = generationRate
            g.metrics.ConsumptionRate = consumptionRate
            g.metrics.BufferUtilization = bufferUtilization
            g.metrics.ItemsGenerated = currentGenerated
            g.metrics.ItemsConsumed = currentConsumed
            
            // ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶ãƒã‚§ãƒƒã‚¯
            if bufferUtilization > 90 {
                g.logger.Printf("âš ï¸  High buffer utilization: %.1f%%", bufferUtilization)
            }
            
            if generationRate > 0 && consumptionRate > 0 && generationRate > consumptionRate*2 {
                g.logger.Printf("âš ï¸  Generation outpacing consumption: gen=%.0f/sec, cons=%.0f/sec", 
                    generationRate, consumptionRate)
            }
            
            lastGenerated = currentGenerated
            lastConsumed = currentConsumed  
            lastTime = now
            
        case <-g.ctx.Done():
            return
        }
    }
}
```

#### 3. é«˜æ€§èƒ½ãªæ•°å€¤ç¯„å›²Generator

```go
// ã€å®Ÿç”¨ä¾‹ã€‘é«˜æ€§èƒ½ãªæ•°å€¤ç¯„å›²Generatorï¼ˆä¸¦åˆ—åŒ–å¯¾å¿œï¼‰
func NewParallelRangeGenerator(ctx context.Context, start, end int, workers int) *Generator[int] {
    if workers <= 0 {
        workers = runtime.NumCPU()
    }
    
    return NewEnterpriseGenerator(ctx, func(ctx context.Context, yield func(int) bool) error {
        // ã€ä¸¦åˆ—åŒ–ã€‘ç¯„å›²ã‚’è¤‡æ•°ãƒ¯ãƒ¼ã‚«ãƒ¼ã«åˆ†å‰²
        chunkSize := (end - start + 1) / workers
        if chunkSize == 0 {
            chunkSize = 1
        }
        
        var wg sync.WaitGroup
        resultChan := make(chan int, workers*100)
        
        for i := 0; i < workers; i++ {
            wg.Add(1)
            go func(workerID int) {
                defer wg.Done()
                
                workerStart := start + workerID*chunkSize
                workerEnd := workerStart + chunkSize - 1
                if workerID == workers-1 {
                    workerEnd = end // æœ€å¾Œã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã¯æ®‹ã‚Šå…¨ã¦
                }
                
                log.Printf("ğŸ”§ Worker %d processing range [%d, %d]", workerID, workerStart, workerEnd)
                
                for num := workerStart; num <= workerEnd; num++ {
                    select {
                    case resultChan <- num:
                    case <-ctx.Done():
                        return
                    }
                }
            }(i)
        }
        
        // çµæœã‚’é †åºä¿è¨¼ã§å‡ºåŠ›
        go func() {
            wg.Wait()
            close(resultChan)
        }()
        
        // ã‚½ãƒ¼ãƒˆç”¨ã®ä¸€æ™‚ãƒãƒƒãƒ•ã‚¡
        var buffer []int
        for num := range resultChan {
            buffer = append(buffer, num)
        }
        
        // ã‚½ãƒ¼ãƒˆã—ã¦é †åºä¿è¨¼
        sort.Ints(buffer)
        
        // é †åºé€šã‚Šã«yield
        for _, num := range buffer {
            if !yield(num) {
                return nil
            }
        }
        
        return nil
    }, 1000)
}

// ã€å®Ÿç”¨ä¾‹ã€‘ç„¡é™ãƒ•ã‚£ãƒœãƒŠãƒƒãƒGeneratorï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ï¼‰
func NewFibonacciGenerator(ctx context.Context) *Generator[int] {
    return NewEnterpriseGenerator(ctx, func(ctx context.Context, yield func(int) bool) error {
        a, b := 0, 1
        
        // æœ€åˆã®2ã¤ã®å€¤
        if !yield(a) || !yield(b) {
            return nil
        }
        
        for {
            select {
            case <-ctx.Done():
                return ctx.Err()
            default:
                next := a + b
                
                // ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼æ¤œå‡º
                if next < 0 {
                    return fmt.Errorf("fibonacci overflow detected at %d + %d", a, b)
                }
                
                if !yield(next) {
                    return nil
                }
                
                a, b = b, next
                
                // å®šæœŸçš„ã«GCã‚’å‘¼ã³å‡ºã—ã¦ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
                if next%1000000 == 0 {
                    runtime.GC()
                }
            }
        }
    }, 100)
}
```

### å¤‰æ›æ“ä½œï¼ˆTransformationï¼‰

Generatorãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¼·åŠ›ãªç‚¹ã¯ã€é–¢æ•°å‹ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®æ“ä½œã‚’çµ„ã¿åˆã‚ã›ã‚‰ã‚Œã‚‹ã“ã¨ã§ã™ï¼š

#### ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³å“è³ªã®Mapå¤‰æ›

```go
// ã€é«˜æ€§èƒ½Mapå¤‰æ›ã€‘ä¸¦åˆ—å‡¦ç†å¯¾å¿œã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
func Map[T, U any](gen *Generator[T], fn func(T) (U, error), workers int) *Generator[U] {
    if workers <= 0 {
        workers = runtime.NumCPU()
    }
    
    return NewEnterpriseGenerator(gen.ctx, func(ctx context.Context, yield func(U) bool) error {
        // ã€ä¸¦åˆ—å‡¦ç†ã€‘è¤‡æ•°ãƒ¯ãƒ¼ã‚«ãƒ¼ã§å¤‰æ›å‡¦ç†
        inputChan := make(chan T, workers*2)
        resultChan := make(chan transformResult[U], workers*2)
        
        var wg sync.WaitGroup
        
        // ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•
        for i := 0; i < workers; i++ {
            wg.Add(1)
            go func(workerID int) {
                defer wg.Done()
                
                for {
                    select {
                    case input, ok := <-inputChan:
                        if !ok {
                            return
                        }
                        
                        // å¤‰æ›å‡¦ç†å®Ÿè¡Œ
                        result, err := fn(input)
                        
                        select {
                        case resultChan <- transformResult[U]{
                            Value:    result,
                            Error:    err,
                            WorkerID: workerID,
                        }:
                        case <-ctx.Done():
                            return
                        }
                        
                    case <-ctx.Done():
                        return
                    }
                }
            }(i)
        }
        
        // å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ä¾›çµ¦
        go func() {
            defer close(inputChan)
            for {
                select {
                case value, ok := <-gen.ch:
                    if !ok {
                        return
                    }
                    gen.consumed.Add(1)
                    
                    select {
                    case inputChan <- value:
                    case <-ctx.Done():
                        return
                    }
                    
                case <-ctx.Done():
                    return
                }
            }
        }()
        
        // çµæœã®åé›†ã¨å‡ºåŠ›
        go func() {
            wg.Wait()
            close(resultChan)
        }()
        
        successCount := 0
        errorCount := 0
        
        for result := range resultChan {
            if result.Error != nil {
                errorCount++
                gen.logger.Printf("âŒ Map transformation error (worker %d): %v", 
                    result.WorkerID, result.Error)
                continue
            }
            
            if !yield(result.Value) {
                break
            }
            
            successCount++
            
            // å®šæœŸçš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ
            if (successCount+errorCount)%10000 == 0 {
                gen.logger.Printf("ğŸ“Š Map progress: %d success, %d errors", 
                    successCount, errorCount)
            }
        }
        
        gen.logger.Printf("âœ… Map completed: %d success, %d errors", successCount, errorCount)
        return nil
    }, 1000)
}

type transformResult[T any] struct {
    Value    T
    Error    error
    WorkerID int
}

// ã€å®Ÿç”¨ä¾‹ã€‘CPUé›†ç´„çš„ãªå¤‰æ›å‡¦ç†
func CPUIntensiveMapExample() {
    ctx := context.Background()
    
    // 1ä¸‡ã‹ã‚‰10ä¸‡ã¾ã§ã®æ•°å€¤ã«å¯¾ã—ã¦CPUé›†ç´„çš„å‡¦ç†
    numbers := NewParallelRangeGenerator(ctx, 10000, 100000, 4)
    
    // å„æ•°å€¤ã«å¯¾ã—ã¦ç´ æ•°åˆ¤å®šï¼ˆCPUé›†ç´„çš„ï¼‰
    primeCheck := Map(numbers, func(n int) (bool, error) {
        if n < 2 {
            return false, nil
        }
        
        // ç´ æ•°åˆ¤å®šï¼ˆCPUé›†ç´„çš„å‡¦ç†ï¼‰
        for i := 2; i*i <= n; i++ {
            if n%i == 0 {
                return false, nil
            }
        }
        return true, nil
    }, 8) // 8ä¸¦åˆ—ã§å‡¦ç†
    
    primeCount := 0
    for isPrime, ok := primeCheck.Next(); ok; isPrime, ok = primeCheck.Next() {
        if isPrime {
            primeCount++
        }
    }
    
    log.Printf("Found %d prime numbers", primeCount)
}
```

#### é«˜æ€§èƒ½Filteræ“ä½œ

```go
// ã€é«˜æ€§èƒ½Filterã€‘æ¡ä»¶åˆ†å²æœ€é©åŒ–ã¨ãƒãƒƒãƒå‡¦ç†
func Filter[T any](gen *Generator[T], predicate func(T) bool, batchSize int) *Generator[T] {
    if batchSize <= 0 {
        batchSize = 1000
    }
    
    return NewEnterpriseGenerator(gen.ctx, func(ctx context.Context, yield func(T) bool) error {
        batch := make([]T, 0, batchSize)
        filteredCount := 0
        totalProcessed := 0
        
        for {
            select {
            case value, ok := <-gen.ch:
                if !ok {
                    // æœ€å¾Œã®ãƒãƒƒãƒã‚’å‡¦ç†
                    for _, item := range batch {
                        if predicate(item) {
                            if !yield(item) {
                                return nil
                            }
                            filteredCount++
                        }
                    }
                    
                    gen.logger.Printf("âœ… Filter completed: %d/%d items passed (%.2f%%)", 
                        filteredCount, totalProcessed, 
                        float64(filteredCount)/float64(totalProcessed)*100)
                    return nil
                }
                
                gen.consumed.Add(1)
                batch = append(batch, value)
                totalProcessed++
                
                // ãƒãƒƒãƒãŒæº€æ¯ã«ãªã£ãŸã‚‰å‡¦ç†
                if len(batch) >= batchSize {
                    batchStart := time.Now()
                    batchFiltered := 0
                    
                    for _, item := range batch {
                        if predicate(item) {
                            if !yield(item) {
                                return nil
                            }
                            batchFiltered++
                            filteredCount++
                        }
                    }
                    
                    batchDuration := time.Since(batchStart)
                    processingRate := float64(batchSize) / batchDuration.Seconds()
                    
                    gen.logger.Printf("ğŸ“¦ Batch filtered: %d/%d passed (rate: %.0f items/sec)", 
                        batchFiltered, batchSize, processingRate)
                    
                    // ãƒãƒƒãƒã‚’ãƒªã‚»ãƒƒãƒˆ
                    batch = batch[:0]
                }
                
            case <-ctx.Done():
                return ctx.Err()
            }
        }
    }, 1000)
}

// ã€å®Ÿç”¨ä¾‹ã€‘è¤‡é›‘ãªæ¡ä»¶ã§ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
func ComplexFilterExample() {
    ctx := context.Background()
    
    // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®Generatorï¼ˆä»®æƒ³ï¼‰
    users := NewMemoryEfficientUserGenerator(ctx, 1000)
    
    // è¤‡é›‘ãªæ¡ä»¶ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    activeUsers := Filter(users, func(user User) bool {
        // è¤‡æ•°ã®æ¡ä»¶ã‚’çµ„ã¿åˆã‚ã›
        return user.Active && 
               user.LastLoginDays <= 30 && 
               user.AccountType == "premium" &&
               len(user.Email) > 0
    }, 500) // 500ä»¶ãƒãƒƒãƒå‡¦ç†
    
    count := 0
    for user, ok := activeUsers.Next(); ok; user, ok = activeUsers.Next() {
        processActiveUser(user)
        count++
    }
    
    log.Printf("Processed %d active premium users", count)
}
```

#### ã‚¹ãƒãƒ¼ãƒˆTakeæ“ä½œ

```go
// ã€é«˜åº¦ãªTakeæ“ä½œã€‘å‹•çš„åˆ¶é™ã¨ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
func Take[T any](gen *Generator[T], n int) *Generator[T] {
    return NewEnterpriseGenerator(gen.ctx, func(ctx context.Context, yield func(T) bool) error {
        if n <= 0 {
            gen.logger.Printf("âš ï¸  Take with n=%d, no items will be yielded", n)
            return nil
        }
        
        count := 0
        startTime := time.Now()
        
        for {
            select {
            case value, ok := <-gen.ch:
                if !ok {
                    gen.logger.Printf("âœ… Take completed early: %d/%d items (source exhausted)", 
                        count, n)
                    return nil
                }
                
                gen.consumed.Add(1)
                
                if !yield(value) {
                    gen.logger.Printf("âœ… Take completed: %d/%d items (consumer stopped)", 
                        count, n)
                    return nil
                }
                
                count++
                
                // ç›®æ¨™æ•°ã«é”ã—ãŸã‚‰çµ‚äº†
                if count >= n {
                    duration := time.Since(startTime)
                    rate := float64(count) / duration.Seconds()
                    
                    gen.logger.Printf("âœ… Take completed: %d items in %v (%.0f items/sec)", 
                        count, duration, rate)
                    return nil
                }
                
                // é€²æ—ãƒ¬ãƒãƒ¼ãƒˆ
                if count%10000 == 0 {
                    progress := float64(count) / float64(n) * 100
                    gen.logger.Printf("ğŸ“Š Take progress: %d/%d (%.1f%%)", count, n, progress)
                }
                
            case <-ctx.Done():
                gen.logger.Printf("âš ï¸  Take cancelled: %d/%d items", count, n)
                return ctx.Err()
            }
        }
    }, min(n, 1000)) // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã‚’é©åˆ‡ã«è¨­å®š
}

// ã€å®Ÿç”¨ä¾‹ã€‘ç„¡é™ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‹ã‚‰ã®åŠ¹ç‡çš„ãªæŠ½å‡º
func InfiniteStreamSamplingExample() {
    ctx := context.Background()
    
    // ç„¡é™ãƒ•ã‚£ãƒœãƒŠãƒƒãƒæ•°åˆ—
    fibonacci := NewFibonacciGenerator(ctx)
    
    // æœ€åˆã®10ä¸‡å€‹ã‚’å–å¾—
    first100k := Take(fibonacci, 100000)
    
    // ã•ã‚‰ã«100ã§å‰²ã‚Šåˆ‡ã‚Œã‚‹ã‚‚ã®ã ã‘ã‚’ãƒ•ã‚£ãƒ«ã‚¿
    divisibleBy100 := Filter(first100k, func(n int) bool {
        return n%100 == 0
    }, 1000)
    
    // æœ€åˆã®1000å€‹ã‚’æœ€çµ‚çš„ã«å–å¾—
    final1000 := Take(divisibleBy100, 1000)
    
    results := make([]int, 0, 1000)
    for value, ok := final1000.Next(); ok; value, ok = final1000.Next() {
        results = append(results, value)
    }
    
    log.Printf("Collected %d fibonacci numbers divisible by 100", len(results))
    log.Printf("First few: %v", results[:min(len(results), 10)])
}

func min(a, b int) int {
    if a < b {
        return a
    }
    return b
}
```

### çµ„ã¿åˆã‚ã›ï¼ˆCompositionï¼‰

è¤‡æ•°ã®Generatorã‚’çµ„ã¿åˆã‚ã›ã¦è¤‡é›‘ãªå‡¦ç†ã‚’æ§‹ç¯‰ã§ãã¾ã™ï¼š

```go
// 1ã‹ã‚‰100ã¾ã§ã®æ•°å­—ã‹ã‚‰ã€3ã§å‰²ã‚Šåˆ‡ã‚Œã‚‹æ•°ã®å¹³æ–¹ã‚’æ–‡å­—åˆ—ã¨ã—ã¦å–å¾—
result := Map(
    Filter(Range(1, 100), func(x int) bool {
        return x%3 == 0
    }),
    func(x int) string {
        return fmt.Sprintf("square:%d", x*x)
    },
)

strings := result.ToSlice()
// ["square:9", "square:36", "square:81", ...]
```

### ä¸¦åˆ—å‡¦ç†

Generatorãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ä¸¦åˆ—å‡¦ç†ã¨ã‚‚ç›¸æ€§ãŒè‰¯ã„ã§ã™ï¼š

```go
func Parallel[T, U any](gen Generator[T], fn func(T) U, workers int) Generator[U] {
    return NewGenerator(func(ctx context.Context, yield func(U) bool) {
        input := make(chan T, workers)
        output := make(chan U, workers)
        
        // ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•
        var wg sync.WaitGroup
        for i := 0; i < workers; i++ {
            wg.Add(1)
            go func() {
                defer wg.Done()
                for value := range input {
                    output <- fn(value)
                }
            }()
        }
        
        // å…¥åŠ›ã‚’ãƒ¯ãƒ¼ã‚«ãƒ¼ã«åˆ†æ•£
        go func() {
            defer close(input)
            for value := range gen.ch {
                input <- value
            }
        }()
        
        // çµæœã‚’å‡ºåŠ›
        go func() {
            wg.Wait()
            close(output)
        }()
        
        for result := range output {
            if !yield(result) {
                return
            }
        }
    })
}
```

### å®Ÿè·µçš„ãªä½¿ç”¨ä¾‹

#### 1. ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
```go
func ReadLines(filename string) Generator[string] {
    return NewGenerator(func(ctx context.Context, yield func(string) bool) {
        file, err := os.Open(filename)
        if err != nil {
            return
        }
        defer file.Close()
        
        scanner := bufio.NewScanner(file)
        for scanner.Scan() {
            if !yield(scanner.Text()) {
                return
            }
        }
    })
}
```

#### 2. HTTP APIã®å¤§é‡ãƒ‡ãƒ¼ã‚¿å–å¾—
```go
func FetchPages(baseURL string) Generator[APIResponse] {
    return NewGenerator(func(ctx context.Context, yield func(APIResponse) bool) {
        page := 1
        for {
            resp, err := fetchPage(baseURL, page)
            if err != nil || resp.IsEmpty() {
                return
            }
            if !yield(resp) {
                return
            }
            page++
        }
    })
}
```

## ğŸ“ èª²é¡Œ (The Problem)

`main_test.go`ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ãƒ†ã‚¹ãƒˆã‚’ãƒ‘ã‚¹ã™ã‚‹ã‚ˆã†ã«ã€ä»¥ä¸‹ã®Generatorãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š

### å®Ÿè£…ã™ã¹ãæ§‹é€ ä½“ã¨é–¢æ•°

```go
// Generator represents a generator that produces values of type T
type Generator[T any] struct {
    ch     <-chan T
    cancel context.CancelFunc
    ctx    context.Context
}

// GeneratorFunc is a function that generates values
type GeneratorFunc[T any] func(ctx context.Context, yield func(T) bool)

// åŸºæœ¬é–¢æ•°
func NewGenerator[T any](fn GeneratorFunc[T]) Generator[T]
func (g Generator[T]) Next() (T, bool)
func (g Generator[T]) ToSlice() []T
func (g Generator[T]) ForEach(fn func(T))
func (g Generator[T]) Cancel()

// åŸºæœ¬Generator
func Range(start, end int) Generator[int]
func Repeat[T any](value T) Generator[T]
func FromSlice[T any](slice []T) Generator[T]
func Fibonacci() Generator[int]
func Timer(interval time.Duration) Generator[time.Time]

// å¤‰æ›æ“ä½œ
func Map[T, U any](gen Generator[T], fn func(T) U) Generator[U]
func Filter[T any](gen Generator[T], predicate func(T) bool) Generator[T]
func Take[T any](gen Generator[T], n int) Generator[T]
func Skip[T any](gen Generator[T], n int) Generator[T]
func TakeWhile[T any](gen Generator[T], predicate func(T) bool) Generator[T]

// çµ„ã¿åˆã‚ã›æ“ä½œ
func Chain[T any](generators ...Generator[T]) Generator[T]
func Zip[T, U any](gen1 Generator[T], gen2 Generator[U]) Generator[Pair[T, U]]

// é›†ç´„æ“ä½œ
func Reduce[T, U any](gen Generator[T], initial U, fn func(U, T) U) U
func Count[T any](gen Generator[T]) int
func Any[T any](gen Generator[T], predicate func(T) bool) bool
func All[T any](gen Generator[T], predicate func(T) bool) bool

// é«˜åº¦ãªæ©Ÿèƒ½
func Batch[T any](gen Generator[T], size int) Generator[[]T]
func Distinct[T comparable](gen Generator[T]) Generator[T]
func Parallel[T, U any](gen Generator[T], fn func(T) U, workers int) Generator[U]
func Buffer[T any](gen Generator[T], size int) Generator[T]
```

## âœ… æœŸå¾…ã•ã‚Œã‚‹æŒ™å‹• (Expected Behavior)

å®Ÿè£…ãŒå®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªå‹•ä½œãŒæœŸå¾…ã•ã‚Œã¾ã™ï¼š

### 1. åŸºæœ¬çš„ãªä½¿ç”¨
```go
// æ•°å€¤ç¯„å›²ã®ç”Ÿæˆ
gen := Range(1, 5)
values := gen.ToSlice()
// [1, 2, 3, 4, 5]
```

### 2. å¤‰æ›æ“ä½œ
```go
// Map: å„å€¤ã‚’2å€ã«
doubled := Map(Range(1, 5), func(x int) int { return x * 2 })
// [2, 4, 6, 8, 10]

// Filter: å¶æ•°ã®ã¿
evens := Filter(Range(1, 10), func(x int) bool { return x%2 == 0 })
// [2, 4, 6, 8, 10]
```

### 3. ç„¡é™ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
```go
// ãƒ•ã‚£ãƒœãƒŠãƒƒãƒæ•°åˆ—ã®æœ€åˆã®10å€‹
fibs := Take(Fibonacci(), 10).ToSlice()
// [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]
```

### 4. çµ„ã¿åˆã‚ã›å‡¦ç†
```go
// è¤‡é›‘ãªå¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
result := Map(
    Filter(Range(1, 20), func(x int) bool { return x%3 == 0 }),
    func(x int) string { return fmt.Sprintf("num-%d", x) },
).ToSlice()
// ["num-3", "num-6", "num-9", "num-12", "num-15", "num-18"]
```

### 5. ãƒ†ã‚¹ãƒˆçµæœ
```bash
$ go test -v
=== RUN   TestBasicGenerators
--- PASS: TestBasicGenerators (0.00s)
=== RUN   TestTransformations
--- PASS: TestTransformations (0.00s)
=== RUN   TestComposition
--- PASS: TestComposition (0.00s)
=== RUN   TestAggregations
--- PASS: TestAggregations (0.00s)
PASS
```

## ğŸ’¡ ãƒ’ãƒ³ãƒˆ (Hints)

è©°ã¾ã£ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®ãƒ’ãƒ³ãƒˆã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š

### 1. åŸºæœ¬çš„ãªGeneratorå®Ÿè£…
```go
func NewGenerator[T any](fn GeneratorFunc[T]) Generator[T] {
    ctx, cancel := context.WithCancel(context.Background())
    ch := make(chan T)
    
    go func() {
        defer close(ch)
        fn(ctx, func(value T) bool {
            select {
            case ch <- value:
                return true
            case <-ctx.Done():
                return false
            }
        })
    }()
    
    return Generator[T]{ch: ch, cancel: cancel, ctx: ctx}
}
```

### 2. å½¹ç«‹ã¤ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
- `context`: ã‚­ãƒ£ãƒ³ã‚»ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡
- `sync`: ä¸¦åˆ—å‡¦ç†åˆ¶å¾¡
- `time`: ã‚¿ã‚¤ãƒãƒ¼ã¨ãƒãƒ£ãƒãƒ«æ“ä½œ
- `container/list`: ãƒãƒƒãƒ•ã‚¡ç®¡ç†

### 3. ãƒãƒ£ãƒãƒ«æ“ä½œã®ãƒ‘ã‚¿ãƒ¼ãƒ³
```go
// ãƒãƒ£ãƒãƒ«ã‹ã‚‰ã®èª­ã¿å–ã‚Š
for value := range gen.ch {
    // å‡¦ç†
}

// ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒ³ã‚»ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ç›£è¦–
select {
case <-ctx.Done():
    return
case value := <-ch:
    // å‡¦ç†
}
```

### 4. Goroutineãƒªãƒ¼ã‚¯é˜²æ­¢
```go
// å¿…ãšGoroutineã‚’é©åˆ‡ã«çµ‚äº†
defer close(ch)

// ã‚­ãƒ£ãƒ³ã‚»ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚ã®å‡¦ç†
func (g Generator[T]) Cancel() {
    if g.cancel != nil {
        g.cancel()
    }
}
```

### 5. æ®µéšçš„ãªå®Ÿè£…é †åº

1. **åŸºæœ¬æ§‹é€ **: `Generator`æ§‹é€ ä½“ã¨`NewGenerator`é–¢æ•°
2. **åŸºæœ¬æ“ä½œ**: `Range`, `FromSlice`, `Next`, `ToSlice`
3. **å¤‰æ›æ“ä½œ**: `Map`, `Filter`, `Take`
4. **çµ„ã¿åˆã‚ã›**: `Chain`, `Zip`
5. **é›†ç´„æ“ä½œ**: `Reduce`, `Count`
6. **é«˜åº¦ãªæ©Ÿèƒ½**: `Parallel`, `Batch`, `Distinct`

ã“ã‚Œã‚‰ã®ãƒ’ãƒ³ãƒˆã‚’å‚è€ƒã«ã€æ®µéšçš„ã«å®Ÿè£…ã‚’é€²ã‚ã¦ãã ã•ã„ã€‚ã¾ãšã¯æœ€ã‚‚åŸºæœ¬çš„ãª`Range`ã¨`ToSlice`ã‹ã‚‰å§‹ã‚ã¦ã€å¾ã€…ã«è¤‡é›‘ãªæ“ä½œã‚’è¿½åŠ ã—ã¦ã„ãã®ãŒãŠã™ã™ã‚ã§ã™ã€‚