# Day 48: gRPC Client-side Streaming

## ğŸ¯ æœ¬æ—¥ã®ç›®æ¨™ (Today's Goal)

gRPCã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’å®Œå…¨ã«ç†è§£ã—ã€å®Ÿè£…ã™ã‚‹ã€‚å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®åŠ¹ç‡çš„ãªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ãƒãƒƒãƒå‡¦ç†ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿åé›†ã€ãƒ­ã‚°é›†ç´„ãªã©ã®å®Ÿç”¨çš„ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’é€šã˜ã¦ã€é«˜æ€§èƒ½ã§å …ç‰¢ãªãƒ‡ãƒ¼ã‚¿é€ä¿¡ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚

## ğŸ“– è§£èª¬ (Explanation)

```go
// ã€gRPCã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã®é‡è¦æ€§ã€‘å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã®æ ¸å¿ƒæŠ€è¡“
// âŒ å•é¡Œä¾‹ï¼šä¸é©åˆ‡ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè£…ã«ã‚ˆã‚‹å£Šæ»…çš„ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¾µå®³ã¨ã‚·ã‚¹ãƒ†ãƒ å´©å£Š
func clientStreamingDisasters() {
    // ğŸš¨ ç½å®³ä¾‹ï¼šä¸æ­£å®Ÿè£…ã«ã‚ˆã‚‹DoSæ”»æ’ƒã€ãƒ‡ãƒ¼ã‚¿ç ´æã€ã‚µãƒ¼ãƒãƒ¼ä¹—ã£å–ã‚Š
    
    // âŒ æœ€æ‚ªã®å®Ÿè£…1ï¼šç„¡åˆ¶é™ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸çˆ†ç™º
    func BadFileUpload(stream pb.FileUploadService_UploadFileServer) error {
        // âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™ãªã— - æ”»æ’ƒè€…ãŒ1TB ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯èƒ½
        var totalSize int64
        var fileName string
        
        for {
            chunk, err := stream.Recv()
            if err == io.EOF {
                break
            }
            if err != nil {
                return err
            }
            
            // âŒ ãƒ•ã‚¡ã‚¤ãƒ«åæ¤œè¨¼ãªã— - ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«æ”»æ’ƒå¯èƒ½
            // æ”»æ’ƒè€…: "../../../../etc/passwd" ã§é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ä¸Šæ›¸ã
            if fileName == "" {
                fileName = chunk.GetFileName() // å±é™ºï¼
            }
            
            // âŒ ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ãªã— - ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡æ¯æ¸‡æ”»æ’ƒ
            data := chunk.GetData()
            totalSize += int64(len(data))
            
            // âŒ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆæ™‚ã®ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³
            // æ”»æ’ƒè€…ãŒåŒæ™‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ¨æ¸¬ãƒ»æ“ä½œå¯èƒ½
            tempFile := "/tmp/upload_" + fileName // äºˆæ¸¬å¯èƒ½ãªåå‰
            
            // âŒ ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™è¨­å®šãªã— - èª°ã§ã‚‚èª­ã¿æ›¸ãå¯èƒ½
            file, _ := os.OpenFile(tempFile, os.O_CREATE|os.O_APPEND|os.O_WRONLY, 0777)
            file.Write(data) // ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ãªã—
            file.Close()
        }
        
        // âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†é€šçŸ¥å‰ã«å‡¦ç†å®Ÿè¡Œ - ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆ
        result := &pb.UploadResult{
            Status: "SUCCESS", // å®Ÿéš›ã«ã¯å¤±æ•—ã—ã¦ã„ã¦ã‚‚æˆåŠŸæ‰±ã„
        }
        return stream.SendAndClose(result)
        
        // ã€ç½å®³çš„çµæœã€‘
        // - æ”»æ’ƒè€…ãŒ100GBãƒ•ã‚¡ã‚¤ãƒ«ã‚’1000å€‹åŒæ™‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        // - ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡100TBæ¯æ¸‡ã€å…¨ã‚µãƒ¼ãƒ“ã‚¹æ›¸ãè¾¼ã¿ä¸èƒ½
        // - é‡è¦ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ä¸Šæ›¸ãã§ã‚µãƒ¼ãƒãƒ¼å®Œå…¨åˆ¶å¾¡å¥ªå–
        // - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ç·Šæ€¥åœæ­¢ã€å¾©æ—§ã«2é€±é–“ã€æå¤±50å„„å††
    }
    
    // âŒ æœ€æ‚ªã®å®Ÿè£…2ï¼šSQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³è„†å¼±æ€§ã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿åé›†
    func BadDataCollection(stream pb.DataCollectionService_CollectDataPointsServer) error {
        // âŒ å…¥åŠ›æ¤œè¨¼ãªã— - æ‚ªæ„ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã§å†…éƒ¨ã‚·ã‚¹ãƒ†ãƒ ä¾µå®³
        var dataPoints []*pb.DataPoint
        
        for {
            dataPoint, err := stream.Recv()
            if err == io.EOF {
                break
            }
            
            // âŒ SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³æ”»æ’ƒã«è„†å¼±
            // æ”»æ’ƒè€…ã®ãƒ‡ãƒ¼ã‚¿: source = "'; DROP TABLE users; --"
            source := dataPoint.GetSource()
            
            // âŒ ç›´æ¥SQLå®Ÿè¡Œ - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å®Œå…¨ç ´å£Š
            query := fmt.Sprintf("INSERT INTO data_points (source) VALUES ('%s')", source)
            database.Exec(query) // å…¨ãƒ†ãƒ¼ãƒ–ãƒ«å‰Šé™¤ã•ã‚Œã‚‹ï¼
            
            dataPoints = append(dataPoints, dataPoint)
        }
        
        // âŒ å‡¦ç†çµæœã‚’å½è£… - æ”»æ’ƒæˆåŠŸã‚’éš è”½
        result := &pb.CollectionResult{
            TotalProcessed:  int32(len(dataPoints)),
            SuccessfulCount: int32(len(dataPoints)), // å…¨ã¦æˆåŠŸã¨å½è£…
        }
        return stream.SendAndClose(result)
        
        // ã€ç½å®³çš„çµæœã€‘
        // - é¡§å®¢ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ãƒ†ãƒ¼ãƒ–ãƒ«å‰Šé™¤
        // - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚‚åŒæ™‚ç ´å£Šã§å®Œå…¨å¾©æ—§ä¸èƒ½
        // - 10å¹´åˆ†ã®äº‹æ¥­ãƒ‡ãƒ¼ã‚¿æ¶ˆå¤±ã€ä¼šç¤¾å€’ç”£
    }
    
    // âŒ æœ€æ‚ªã®å®Ÿè£…3ï¼šãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã¨ã‚´ãƒ«ãƒ¼ãƒãƒ³çˆ†ç™ºã®ãƒ­ã‚°åé›†
    func BadLogCollection(stream pb.DataCollectionService_CollectLogsServer) error {
        // âŒ ç„¡åˆ¶é™ã«ãƒ­ã‚°ã‚’è“„ç© - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç„¡é™å¢—åŠ 
        var allLogs []*pb.LogEntry // è§£æ”¾ã•ã‚Œãªã„ï¼
        
        // âŒ ã‚´ãƒ«ãƒ¼ãƒãƒ³ãƒªãƒ¼ã‚¯ã‚’å¼•ãèµ·ã“ã™ä¸¦è¡Œå‡¦ç†
        processingChan := make(chan *pb.LogEntry) // unbuffered
        
        // âŒ çµ‚äº†ã—ãªã„ã‚´ãƒ«ãƒ¼ãƒãƒ³
        go func() {
            for log := range processingChan {
                // âŒ é‡ã„å‡¦ç†ã§ãƒ–ãƒ­ãƒƒã‚¯ - ä»–ã®å‡¦ç†ãŒåœæ­¢
                time.Sleep(time.Second) // æ„å›³çš„ãªé…å»¶å‡¦ç†
                
                // âŒ æ©Ÿå¯†ãƒ­ã‚°ã‚’ãã®ã¾ã¾æ¨™æº–å‡ºåŠ› - æƒ…å ±æ¼æ´©
                fmt.Printf("Processing log: %+v\n", log) // ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç­‰ã‚‚å‡ºåŠ›
                
                // âŒ ãƒ­ã‚°ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«è“„ç© - ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯
                allLogs = append(allLogs, log)
            }
        }()
        
        for {
            logEntry, err := stream.Recv()
            if err == io.EOF {
                // âŒ ã‚´ãƒ«ãƒ¼ãƒãƒ³ã‚’åœæ­¢ã›ãšã«çµ‚äº† - ãƒªãƒ¼ã‚¯ç¢ºå®š
                break
            }
            
            // âŒ ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼åˆ¶å¾¡ãªã— - ãƒãƒ£ãƒãƒ«ãƒ–ãƒ­ãƒƒã‚¯
            processingChan <- logEntry // ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯ç™ºç”Ÿ
        }
        
        // âŒ çµ±è¨ˆæƒ…å ±ã‚’å½è£…
        result := &pb.LogCollectionResult{
            TotalReceived: 999999, // å®Ÿéš›ã®æ•°å€¤ã¨ç•°ãªã‚‹å½è£…
            Status:       "SUCCESS",
        }
        return stream.SendAndClose(result)
        
        // ã€ç½å®³çš„çµæœã€‘
        // - 1æ™‚é–“ã§10ä¸‡ã‚´ãƒ«ãƒ¼ãƒãƒ³ç”Ÿæˆã€CPUä½¿ç”¨ç‡100%
        // - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡500GBã€ã‚·ã‚¹ãƒ†ãƒ å¿œç­”ä¸èƒ½
        // - ãƒ­ã‚°ã«å«ã¾ã‚Œã‚‹ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ»APIã‚­ãƒ¼ãŒæ¨™æº–å‡ºåŠ›ã§æ¼æ´©
        // - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¾µå®³ã§å…¨ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨åœæ­¢
    }
    
    // âŒ æœ€æ‚ªã®å®Ÿè£…4ï¼šèªè¨¼ãƒã‚¤ãƒ‘ã‚¹å¯èƒ½ãªãƒãƒƒãƒå‡¦ç†
    func BadBatchProcessing(stream pb.BatchService_ProcessBatchServer) error {
        // âŒ èªè¨¼ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹æ™‚ã®ã¿å®Ÿè¡Œ
        // é•·æ™‚é–“ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¸­ã«ãƒˆãƒ¼ã‚¯ãƒ³æœŸé™åˆ‡ã‚Œã—ã¦ã‚‚æ¤œè¨¼ãªã—
        
        var batchData []*pb.BatchItem
        var processedCount int
        
        for {
            item, err := stream.Recv()
            if err == io.EOF {
                break
            }
            
            // âŒ ãƒãƒƒãƒã‚¢ã‚¤ãƒ†ãƒ ã®æ¨©é™ãƒã‚§ãƒƒã‚¯ãªã—
            // æ”»æ’ƒè€…ãŒä»–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿æ“ä½œè¦æ±‚ã‚’æ··å…¥å¯èƒ½
            
            // âŒ å±é™ºãªæ“ä½œã‚‚ç„¡æ¡ä»¶å®Ÿè¡Œ
            if item.GetOperation() == "DELETE_ALL_DATA" {
                // âŒ ç®¡ç†è€…æ¨©é™ãƒã‚§ãƒƒã‚¯ãªã— - èª°ã§ã‚‚å…¨ãƒ‡ãƒ¼ã‚¿å‰Šé™¤å¯èƒ½
                deleteAllUserData() // å…¨é¡§å®¢ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ï¼
            }
            
            batchData = append(batchData, item)
            processedCount++
        }
        
        result := &pb.BatchResult{
            ProcessedCount: int32(processedCount),
            Status:        "COMPLETED",
        }
        return stream.SendAndClose(result)
        
        // ã€ç½å®³çš„çµæœã€‘
        // - ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç®¡ç†è€…æ©Ÿèƒ½ã«ã‚¢ã‚¯ã‚»ã‚¹
        // - å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã§æ•°ç™¾ä¸‡äººã®æƒ…å ±æ¶ˆå¤±
        // - æ³•çš„è²¬ä»»è¿½åŠã§çµŒå–¶é™£é€®æ•ã€ä¼šç¤¾è§£æ•£
    }
    
    // ã€å®Ÿéš›ã®è¢«å®³ä¾‹ã€‘
    // - ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä¼æ¥­ï¼šç„¡åˆ¶é™ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ã‚³ã‚¹ãƒˆæœˆé¡1000ä¸‡å††ã«æ€¥å¢—
    // - é‡‘èã‚·ã‚¹ãƒ†ãƒ ï¼šSQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã§å–å¼•ãƒ‡ãƒ¼ã‚¿æ”¹ã–ã‚“ã€ä¿¡ç”¨å¤±å¢œ
    // - åŒ»ç™‚ã‚·ã‚¹ãƒ†ãƒ ï¼šæ‚£è€…è¨˜éŒ²ä¸€æ‹¬å‰Šé™¤ã§åŒ»ç™‚äº‹æ•…ã€é›†å›£è¨´è¨Ÿã«ç™ºå±•
    // - ECã‚µã‚¤ãƒˆï¼šå•†å“ãƒ‡ãƒ¼ã‚¿ç ´æã§æ³¨æ–‡ãƒ»æ±ºæ¸ˆã‚·ã‚¹ãƒ†ãƒ å®Œå…¨åœæ­¢ã€å£²ä¸Šã‚¼ãƒ­
    
    fmt.Println("âŒ Client-side streaming disasters caused complete business collapse!")
    // çµæœï¼šã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¾µå®³ã€ãƒ‡ãƒ¼ã‚¿ç ´å£Šã€ã‚·ã‚¹ãƒ†ãƒ ä¹—ã£å–ã‚Šã€ä¼æ¥­å­˜ç¶šå±æ©Ÿ
}

// âœ… æ­£è§£ï¼šã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç´šã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
type EnterpriseClientStreamingSystem struct {
    // ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€‘
    authManager          *AuthManager            // èªè¨¼ãƒ»èªå¯ç®¡ç†
    encryptionManager    *EncryptionManager      // ãƒ‡ãƒ¼ã‚¿æš—å·åŒ–
    inputValidator       *InputValidator         // å…¥åŠ›æ¤œè¨¼
    sqlInjectionPreventer *SQLInjectionPreventer // SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³é˜²æ­¢
    
    // ã€ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã€‘
    permissionManager    *PermissionManager      // æ¨©é™ç®¡ç†
    auditLogger          *AuditLogger            // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»
    accessController     *AccessController       // ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡
    
    // ã€ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†ã€‘
    quotaManager         *QuotaManager           // å®¹é‡åˆ¶é™ç®¡ç†
    rateLimiter          *RateLimiter            // ãƒ¬ãƒ¼ãƒˆåˆ¶é™
    resourceMonitor      *ResourceMonitor        // ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
    memoryManager        *MemoryManager          // ãƒ¡ãƒ¢ãƒªç®¡ç†
    
    // ã€ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã€‘
    transactionManager   *TransactionManager     // ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†
    checksumValidator    *ChecksumValidator       // ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼
    duplicateDetector    *DuplicateDetector      // é‡è¤‡æ¤œå‡º
    
    // ã€ã‚¹ãƒˆãƒªãƒ¼ãƒ ç®¡ç†ã€‘
    streamRegistry       *StreamRegistry         // ã‚¹ãƒˆãƒªãƒ¼ãƒ ç™»éŒ²ç®¡ç†
    sessionManager       *SessionManager         // ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
    connectionPool       *ConnectionPool         // æ¥ç¶šãƒ—ãƒ¼ãƒ«
    
    // ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‘
    compressionManager   *CompressionManager     // ãƒ‡ãƒ¼ã‚¿åœ§ç¸®
    bufferManager        *BufferManager          // ãƒãƒƒãƒ•ã‚¡ç®¡ç†
    loadBalancer         *LoadBalancer           // è² è·åˆ†æ•£
    
    // ã€ç›£è¦–ãƒ»è¨ºæ–­ã€‘
    metricsCollector     *MetricsCollector       // ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
    healthChecker        *HealthChecker          // ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    performanceAnalyzer  *PerformanceAnalyzer    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
    
    // ã€éšœå®³å¯¾å¿œã€‘
    circuitBreaker       *CircuitBreaker         // ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼
    retryManager         *RetryManager           // ãƒªãƒˆãƒ©ã‚¤ç®¡ç†
    failoverManager      *FailoverManager        // ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼
    
    config               *StreamingConfig        // è¨­å®šç®¡ç†
    mu                   sync.RWMutex            // ä¸¦è¡Œã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡
}

// ã€é‡è¦é–¢æ•°ã€‘ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
func NewEnterpriseClientStreamingSystem(config *StreamingConfig) *EnterpriseClientStreamingSystem {
    return &EnterpriseClientStreamingSystem{
        config:                config,
        authManager:           NewAuthManager(),
        encryptionManager:     NewEncryptionManager(),
        inputValidator:        NewInputValidator(),
        sqlInjectionPreventer: NewSQLInjectionPreventer(),
        permissionManager:     NewPermissionManager(),
        auditLogger:           NewAuditLogger(),
        accessController:      NewAccessController(),
        quotaManager:          NewQuotaManager(),
        rateLimiter:           NewRateLimiter(),
        resourceMonitor:       NewResourceMonitor(),
        memoryManager:         NewMemoryManager(),
        transactionManager:    NewTransactionManager(),
        checksumValidator:     NewChecksumValidator(),
        duplicateDetector:     NewDuplicateDetector(),
        streamRegistry:        NewStreamRegistry(),
        sessionManager:        NewSessionManager(),
        connectionPool:        NewConnectionPool(),
        compressionManager:    NewCompressionManager(),
        bufferManager:         NewBufferManager(),
        loadBalancer:          NewLoadBalancer(),
        metricsCollector:      NewMetricsCollector(),
        healthChecker:         NewHealthChecker(),
        performanceAnalyzer:   NewPerformanceAnalyzer(),
        circuitBreaker:        NewCircuitBreaker(),
        retryManager:          NewRetryManager(),
        failoverManager:       NewFailoverManager(),
    }
}
```

### ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã¨ã¯

ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒ**è¤‡æ•°ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é †æ¬¡é€ä¿¡**ã—ã€ã‚µãƒ¼ãƒãƒ¼ãŒ**å˜ä¸€ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹**ã‚’è¿”ã™gRPCã®é€šä¿¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹ç‡çš„ã«ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡ã§ãã¾ã™ã€‚

```
Client                    Server
   |                         |
   |-------- Request 1 ----->|
   |-------- Request 2 ----->|
   |-------- Request 3 ----->|
   |-------- ... ----------->|
   |-------- Request N ----->|
   |-------- EOF ----------->|
   |                         |
   |<------- Response -------|
```

**å¾“æ¥ã®HTTP APIã¨ã®æ¯”è¼ƒï¼š**

```go
// HTTP REST APIï¼ˆéåŠ¹ç‡ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
func UploadDataHTTP(data []DataPoint) error {
    for _, point := range data {
        // å„ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã§å€‹åˆ¥ã®HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        jsonData, _ := json.Marshal(point)
        resp, err := http.Post("/api/data", "application/json", bytes.NewReader(jsonData))
        if err != nil {
            return err
        }
        resp.Body.Close()
        // 1000å€‹ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ = 1000å›ã®HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    }
    return nil
}

// gRPC Client Streamingï¼ˆåŠ¹ç‡çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
func UploadDataGRPC(client pb.DataServiceClient, data []DataPoint) error {
    stream, err := client.CollectData(context.Background())
    if err != nil {
        return err
    }
    
    // å˜ä¸€ã®æ¥ç¶šã§å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
    for _, point := range data {
        if err := stream.Send(&point); err != nil {
            return err
        }
    }
    
    // å˜ä¸€ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡
    result, err := stream.CloseAndRecv()
    if err != nil {
        return err
    }
    
    log.Printf("Successfully uploaded %d data points", result.TotalProcessed)
    return nil
}
```

### ä¸»ãªç”¨é€”ã¨å®Ÿéš›ã®æ´»ç”¨ä¾‹

#### 1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ 

```go
// ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒãƒƒãƒ•ã‚¡å®šç¾©
syntax = "proto3";

package fileupload;

service FileUploadService {
    rpc UploadFile(stream FileChunk) returns (UploadResult);
}

message FileChunk {
    string file_name = 1;
    bytes data = 2;
    int64 offset = 3;
    int64 total_size = 4;
    bool is_last_chunk = 5;
    string checksum = 6;
}

message UploadResult {
    string file_id = 1;
    string file_name = 2;
    int64 total_size = 3;
    string checksum = 4;
    string status = 5;
    repeated string errors = 6;
}

// ã‚µãƒ¼ãƒãƒ¼å®Ÿè£…
type FileUploadServer struct {
    pb.UnimplementedFileUploadServiceServer
    uploadDir string
    maxFileSize int64
}

func (s *FileUploadServer) UploadFile(stream pb.FileUploadService_UploadFileServer) error {
    var (
        fileName    string
        totalSize   int64
        receivedSize int64
        file        *os.File
        hasher      hash.Hash
        chunks      []FileChunkInfo
    )
    
    hasher = sha256.New()
    
    for {
        chunk, err := stream.Recv()
        if err == io.EOF {
            // ãƒ•ã‚¡ã‚¤ãƒ«è»¢é€å®Œäº†
            break
        }
        if err != nil {
            return status.Errorf(codes.Internal, "receive error: %v", err)
        }
        
        // åˆå›ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†
        if file == nil {
            fileName = chunk.GetFileName()
            totalSize = chunk.GetTotalSize()
            
            // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
            if err := s.validateUpload(fileName, totalSize); err != nil {
                return status.Errorf(codes.InvalidArgument, "validation failed: %v", err)
            }
            
            // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            tempPath := filepath.Join(s.uploadDir, fmt.Sprintf("upload_%s_%d", fileName, time.Now().Unix()))
            file, err = os.Create(tempPath)
            if err != nil {
                return status.Errorf(codes.Internal, "failed to create file: %v", err)
            }
            defer file.Close()
        }
        
        // ãƒãƒ£ãƒ³ã‚¯ã®æ¤œè¨¼
        if chunk.GetOffset() != receivedSize {
            return status.Errorf(codes.InvalidArgument, 
                "chunk offset mismatch: expected %d, got %d", receivedSize, chunk.GetOffset())
        }
        
        // ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿
        data := chunk.GetData()
        n, err := file.Write(data)
        if err != nil {
            return status.Errorf(codes.Internal, "write error: %v", err)
        }
        
        receivedSize += int64(n)
        hasher.Write(data)
        
        // ãƒãƒ£ãƒ³ã‚¯æƒ…å ±ã‚’è¨˜éŒ²
        chunks = append(chunks, FileChunkInfo{
            Offset: chunk.GetOffset(),
            Size:   int64(len(data)),
            Checksum: fmt.Sprintf("%x", sha256.Sum256(data)),
        })
        
        // ã‚µã‚¤ã‚ºåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if receivedSize > s.maxFileSize {
            return status.Errorf(codes.ResourceExhausted, 
                "file size exceeds limit: %d > %d", receivedSize, s.maxFileSize)
        }
        
        // æœ€çµ‚ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†
        if chunk.GetIsLastChunk() {
            break
        }
    }
    
    // ãƒ•ã‚¡ã‚¤ãƒ«æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    if receivedSize != totalSize {
        return status.Errorf(codes.DataLoss, 
            "size mismatch: expected %d, received %d", totalSize, receivedSize)
    }
    
    // ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼
    finalChecksum := fmt.Sprintf("%x", hasher.Sum(nil))
    
    // ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€çµ‚å‡¦ç†
    fileID := s.processUploadedFile(fileName, file.Name(), chunks)
    
    // ãƒ¬ã‚¹ãƒãƒ³ã‚¹é€ä¿¡
    result := &pb.UploadResult{
        FileId:    fileID,
        FileName:  fileName,
        TotalSize: receivedSize,
        Checksum:  finalChecksum,
        Status:    "SUCCESS",
    }
    
    return stream.SendAndClose(result)
}

type FileChunkInfo struct {
    Offset   int64
    Size     int64
    Checksum string
}

func (s *FileUploadServer) validateUpload(fileName string, size int64) error {
    // ãƒ•ã‚¡ã‚¤ãƒ«åã®æ¤œè¨¼
    if fileName == "" {
        return fmt.Errorf("file name is required")
    }
    
    // ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«æ”»æ’ƒã‚’é˜²ã
    if strings.Contains(fileName, "..") || strings.Contains(fileName, "/") {
        return fmt.Errorf("invalid file name")
    }
    
    // ã‚µã‚¤ã‚ºåˆ¶é™
    if size > s.maxFileSize {
        return fmt.Errorf("file size too large: %d > %d", size, s.maxFileSize)
    }
    
    // æ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯
    allowedExts := []string{".txt", ".csv", ".json", ".xml"}
    ext := strings.ToLower(filepath.Ext(fileName))
    for _, allowed := range allowedExts {
        if ext == allowed {
            return nil
        }
    }
    
    return fmt.Errorf("file type not allowed: %s", ext)
}

func (s *FileUploadServer) processUploadedFile(fileName, tempPath string, chunks []FileChunkInfo) string {
    fileID := fmt.Sprintf("file_%s_%d", fileName, time.Now().Unix())
    
    // æœ€çµ‚çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã«ç§»å‹•
    finalPath := filepath.Join(s.uploadDir, fileID)
    os.Rename(tempPath, finalPath)
    
    // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    metadata := FileMetadata{
        FileID:    fileID,
        FileName:  fileName,
        Path:      finalPath,
        Chunks:    chunks,
        UploadTime: time.Now(),
    }
    s.saveMetadata(metadata)
    
    return fileID
}
```

#### 2. ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ 

```go
// ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿åé›†ç”¨ãƒ—ãƒ­ãƒˆã‚³ãƒ«
service DataCollectionService {
    rpc CollectDataPoints(stream DataPoint) returns (CollectionResult);
    rpc CollectLogs(stream LogEntry) returns (LogCollectionResult);
}

message DataPoint {
    string source = 1;
    int64 timestamp = 2;
    map<string, double> metrics = 3;
    map<string, string> tags = 4;
}

message LogEntry {
    string application = 1;
    string level = 2;
    int64 timestamp = 3;
    string message = 4;
    map<string, string> fields = 5;
}

message CollectionResult {
    int32 total_processed = 1;
    int32 successful_count = 2;
    int32 error_count = 3;
    repeated string errors = 4;
    int64 processing_time_ms = 5;
}

// ãƒ‡ãƒ¼ã‚¿åé›†ã‚µãƒ¼ãƒãƒ¼å®Ÿè£…
type DataCollectionServer struct {
    pb.UnimplementedDataCollectionServiceServer
    storage DataStorage
    validator DataValidator
    aggregator MetricsAggregator
}

func (s *DataCollectionServer) CollectDataPoints(stream pb.DataCollectionService_CollectDataPointsServer) error {
    startTime := time.Now()
    
    var (
        totalProcessed = 0
        successCount   = 0
        errorCount     = 0
        errors         []string
        batch          []*pb.DataPoint
        batchSize      = 100 // ãƒãƒƒãƒå‡¦ç†ã‚µã‚¤ã‚º
    )
    
    for {
        dataPoint, err := stream.Recv()
        if err == io.EOF {
            // æœ€å¾Œã®ãƒãƒƒãƒã‚’å‡¦ç†
            if len(batch) > 0 {
                batchResults := s.processBatch(batch)
                successCount += batchResults.SuccessCount
                errorCount += batchResults.ErrorCount
                errors = append(errors, batchResults.Errors...)
            }
            break
        }
        if err != nil {
            return status.Errorf(codes.Internal, "receive error: %v", err)
        }
        
        totalProcessed++
        
        // ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        if err := s.validator.ValidateDataPoint(dataPoint); err != nil {
            errorCount++
            errors = append(errors, fmt.Sprintf("validation error for point %d: %v", totalProcessed, err))
            continue
        }
        
        batch = append(batch, dataPoint)
        
        // ãƒãƒƒãƒã‚µã‚¤ã‚ºã«é”ã—ãŸã‚‰å‡¦ç†
        if len(batch) >= batchSize {
            batchResults := s.processBatch(batch)
            successCount += batchResults.SuccessCount
            errorCount += batchResults.ErrorCount
            errors = append(errors, batchResults.Errors...)
            batch = batch[:0] // ãƒãƒƒãƒã‚’ã‚¯ãƒªã‚¢
        }
    }
    
    processingTime := time.Since(startTime)
    
    result := &pb.CollectionResult{
        TotalProcessed:   int32(totalProcessed),
        SuccessfulCount:  int32(successCount),
        ErrorCount:       int32(errorCount),
        Errors:          errors,
        ProcessingTimeMs: processingTime.Milliseconds(),
    }
    
    return stream.SendAndClose(result)
}

type BatchResult struct {
    SuccessCount int
    ErrorCount   int
    Errors       []string
}

func (s *DataCollectionServer) processBatch(batch []*pb.DataPoint) BatchResult {
    var result BatchResult
    
    // ãƒãƒƒãƒå˜ä½ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
    if err := s.storage.SaveDataPointsBatch(batch); err != nil {
        result.ErrorCount = len(batch)
        result.Errors = append(result.Errors, fmt.Sprintf("batch save error: %v", err))
        return result
    }
    
    // ãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†ç´„
    for _, point := range batch {
        if err := s.aggregator.AggregateMetrics(point); err != nil {
            result.ErrorCount++
            result.Errors = append(result.Errors, fmt.Sprintf("aggregation error: %v", err))
        } else {
            result.SuccessCount++
        }
    }
    
    return result
}
```

#### 3. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°åé›†ã‚·ã‚¹ãƒ†ãƒ 

```go
// ãƒ­ã‚°åé›†ç”¨å®Ÿè£…
func (s *DataCollectionServer) CollectLogs(stream pb.DataCollectionService_CollectLogsServer) error {
    var (
        logBuffer   []*pb.LogEntry
        flushTimer  = time.NewTicker(5 * time.Second) // 5ç§’æ¯ã«ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
        totalLogs   = 0
        indexedLogs = 0
    )
    defer flushTimer.Stop()
    
    // éåŒæœŸã§ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
    flushChan := make(chan bool, 1)
    go func() {
        for {
            select {
            case <-flushTimer.C:
                if len(logBuffer) > 0 {
                    select {
                    case flushChan <- true:
                    default: // ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ä¸­ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    }
                }
            }
        }
    }()
    
    for {
        select {
        case <-flushChan:
            // ãƒãƒƒãƒ•ã‚¡ã®ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
            if len(logBuffer) > 0 {
                indexed := s.indexLogs(logBuffer)
                indexedLogs += indexed
                logBuffer = logBuffer[:0]
            }
            
        default:
            logEntry, err := stream.Recv()
            if err == io.EOF {
                // æœ€å¾Œã®ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
                if len(logBuffer) > 0 {
                    indexed := s.indexLogs(logBuffer)
                    indexedLogs += indexed
                }
                
                result := &pb.LogCollectionResult{
                    TotalReceived: int32(totalLogs),
                    IndexedCount:  int32(indexedLogs),
                    Status:       "SUCCESS",
                }
                return stream.SendAndClose(result)
            }
            if err != nil {
                return status.Errorf(codes.Internal, "receive error: %v", err)
            }
            
            totalLogs++
            logBuffer = append(logBuffer, logEntry)
            
            // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºåˆ¶é™
            if len(logBuffer) >= 1000 {
                indexed := s.indexLogs(logBuffer)
                indexedLogs += indexed
                logBuffer = logBuffer[:0]
            }
        }
    }
}

func (s *DataCollectionServer) indexLogs(logs []*pb.LogEntry) int {
    indexed := 0
    for _, log := range logs {
        if err := s.storage.IndexLogEntry(log); err == nil {
            indexed++
        }
    }
    return indexed
}
```

#### 4. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå®Ÿè£…ä¾‹

```go
// é«˜åº¦ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå®Ÿè£…
type StreamingClient struct {
    client     pb.DataCollectionServiceClient
    conn       *grpc.ClientConn
    rateLimiter *rate.Limiter
}

func NewStreamingClient(address string, rateLimit rate.Limit) (*StreamingClient, error) {
    conn, err := grpc.Dial(address, 
        grpc.WithInsecure(),
        grpc.WithKeepaliveParams(keepalive.ClientParameters{
            Time:    30 * time.Second,
            Timeout: 5 * time.Second,
        }),
    )
    if err != nil {
        return nil, err
    }
    
    return &StreamingClient{
        client:      pb.NewDataCollectionServiceClient(conn),
        conn:        conn,
        rateLimiter: rate.NewLimiter(rateLimit, int(rateLimit)),
    }, nil
}

// ä¸¦è¡Œãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
func (c *StreamingClient) UploadFilesConcurrently(files []string, maxConcurrency int) error {
    semaphore := make(chan struct{}, maxConcurrency)
    errChan := make(chan error, len(files))
    
    var wg sync.WaitGroup
    
    for _, filePath := range files {
        wg.Add(1)
        go func(path string) {
            defer wg.Done()
            
            semaphore <- struct{}{} // ã‚»ãƒãƒ•ã‚©å–å¾—
            defer func() { <-semaphore }() // ã‚»ãƒãƒ•ã‚©è§£æ”¾
            
            if err := c.UploadFile(path); err != nil {
                errChan <- fmt.Errorf("failed to upload %s: %w", path, err)
            }
        }(filePath)
    }
    
    wg.Wait()
    close(errChan)
    
    var errors []error
    for err := range errChan {
        errors = append(errors, err)
    }
    
    if len(errors) > 0 {
        return fmt.Errorf("upload errors: %v", errors)
    }
    
    return nil
}

// ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ããƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
func (c *StreamingClient) UploadFile(filePath string) error {
    file, err := os.Open(filePath)
    if err != nil {
        return err
    }
    defer file.Close()
    
    fileInfo, err := file.Stat()
    if err != nil {
        return err
    }
    
    stream, err := c.client.UploadFile(context.Background())
    if err != nil {
        return err
    }
    
    buffer := make([]byte, 32*1024) // 32KB chunks
    offset := int64(0)
    totalSize := fileInfo.Size()
    fileName := filepath.Base(filePath)
    
    for {
        // ãƒ¬ãƒ¼ãƒˆåˆ¶é™é©ç”¨
        if err := c.rateLimiter.Wait(context.Background()); err != nil {
            return err
        }
        
        n, err := file.Read(buffer)
        if err == io.EOF {
            break
        }
        if err != nil {
            return err
        }
        
        chunk := &pb.FileChunk{
            FileName:     fileName,
            Data:         buffer[:n],
            Offset:       offset,
            TotalSize:    totalSize,
            IsLastChunk:  offset+int64(n) >= totalSize,
        }
        
        if err := stream.Send(chunk); err != nil {
            return err
        }
        
        offset += int64(n)
    }
    
    result, err := stream.CloseAndRecv()
    if err != nil {
        return err
    }
    
    log.Printf("Upload completed: %s (ID: %s)", result.FileName, result.FileId)
    return nil
}

// ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é€ä¿¡
func (c *StreamingClient) SendDataPoints(ctx context.Context, dataPoints <-chan *pb.DataPoint) (*pb.CollectionResult, error) {
    stream, err := c.client.CollectDataPoints(ctx)
    if err != nil {
        return nil, err
    }
    
    // é€ä¿¡çµ±è¨ˆ
    var sentCount int
    startTime := time.Now()
    
    // é€²è¡ŒçŠ¶æ³ãƒ¬ãƒãƒ¼ãƒˆ
    progressTicker := time.NewTicker(10 * time.Second)
    defer progressTicker.Stop()
    
    go func() {
        for {
            select {
            case <-progressTicker.C:
                log.Printf("Sent %d data points in %v", sentCount, time.Since(startTime))
            case <-ctx.Done():
                return
            }
        }
    }()
    
    // ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’é€ä¿¡
    for {
        select {
        case dataPoint, ok := <-dataPoints:
            if !ok {
                // ãƒãƒ£ãƒãƒ«ã‚¯ãƒ­ãƒ¼ã‚º = é€ä¿¡å®Œäº†
                result, err := stream.CloseAndRecv()
                if err != nil {
                    return nil, err
                }
                
                log.Printf("Stream completed: sent %d, processed %d", 
                    sentCount, result.TotalProcessed)
                return result, nil
            }
            
            if err := stream.Send(dataPoint); err != nil {
                return nil, err
            }
            sentCount++
            
        case <-ctx.Done():
            return nil, ctx.Err()
        }
    }
}
```

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨å†æ¥ç¶š

```go
// å …ç‰¢ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
func (c *StreamingClient) UploadWithRetry(filePath string, maxRetries int) error {
    backoff := time.Second
    
    for attempt := 0; attempt < maxRetries; attempt++ {
        err := c.UploadFile(filePath)
        if err == nil {
            return nil
        }
        
        // ãƒªãƒˆãƒ©ã‚¤å¯èƒ½ãªã‚¨ãƒ©ãƒ¼ã‹åˆ¤å®š
        if !isRetryableError(err) {
            return err
        }
        
        if attempt < maxRetries-1 {
            log.Printf("Upload failed (attempt %d/%d): %v. Retrying in %v...", 
                attempt+1, maxRetries, err, backoff)
            
            time.Sleep(backoff)
            backoff *= 2
        }
    }
    
    return fmt.Errorf("upload failed after %d attempts", maxRetries)
}

func isRetryableError(err error) bool {
    if err == nil {
        return false
    }
    
    st, ok := status.FromError(err)
    if !ok {
        return false
    }
    
    switch st.Code() {
    case codes.Unavailable, codes.DeadlineExceeded, codes.ResourceExhausted:
        return true
    default:
        return false
    }
}

// æ¥ç¶šçŠ¶æ…‹ç›£è¦–
func (c *StreamingClient) MonitorConnection() {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            state := c.conn.GetState()
            log.Printf("Connection state: %v", state)
            
            if state == connectivity.TransientFailure {
                log.Println("Connection in failure state, attempting to reconnect...")
                c.conn.Connect()
            }
        }
    }
}
```

## ğŸ“ èª²é¡Œ (The Problem)

`main_test.go`ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ã™ã¹ã¦ãƒ‘ã‚¹ã™ã‚‹ã‚ˆã†ã«ã€ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š

### 1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹
- å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŠ¹ç‡çš„ã«åˆ†å‰²ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
- ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼ã¨ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèª
- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é€²è¡ŒçŠ¶æ³ã®ç›£è¦–
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã€ã‚µã‚¤ã‚ºã€ã‚¿ã‚¤ãƒ—ï¼‰

### 2. ãƒ‡ãƒ¼ã‚¿åé›†ã‚µãƒ¼ãƒ“ã‚¹
- å¤§é‡ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã®ãƒãƒƒãƒåé›†
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã®åŠ¹ç‡çš„ãªå‡¦ç†
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†ç´„ã¨çµ±è¨ˆæƒ…å ±ç”Ÿæˆ
- ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼

### 3. ãƒ­ã‚°é›†ç´„ã‚µãƒ¼ãƒ“ã‚¹
- è¤‡æ•°ã®ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’ä¸€æ‹¬åé›†
- ãƒ­ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨åˆ†é¡
- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã¨æ¤œç´¢æº–å‚™
- ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã¨å®šæœŸãƒ•ãƒ©ãƒƒã‚·ãƒ¥

### 4. ãƒãƒƒãƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
- å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®åŠ¹ç‡çš„ãªå‡¦ç†
- ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¨ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡
- ä¸¦è¡Œã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
- é€²è¡ŒçŠ¶æ³ç›£è¦–ã¨ãƒ¬ãƒãƒ¼ãƒˆ

**å®Ÿè£…ã™ã¹ãé–¢æ•°ï¼š**

```go
// ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
func (s *FileUploadServer) UploadFile(stream pb.FileUploadService_UploadFileServer) error

// ãƒ‡ãƒ¼ã‚¿åé›†
func (s *DataCollectionServer) CollectDataPoints(stream pb.DataCollectionService_CollectDataPointsServer) error

// ãƒ­ã‚°é›†ç´„
func (s *DataCollectionServer) CollectLogs(stream pb.DataCollectionService_CollectLogsServer) error

// ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå®Ÿè£…
func (c *StreamingClient) UploadFile(filePath string) error
func (c *StreamingClient) SendDataPoints(ctx context.Context, dataPoints <-chan *pb.DataPoint) (*pb.CollectionResult, error)
```

**é‡è¦ãªå®Ÿè£…è¦ä»¶ï¼š**
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†
- é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
- ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¨ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡
- ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®ä¿è¨¼
- ä¸¦è¡Œå‡¦ç†ã®å®‰å…¨æ€§

## âœ… æœŸå¾…ã•ã‚Œã‚‹æŒ™å‹• (Expected Behavior)

å®Ÿè£…ãŒæ­£ã—ãå®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªçµæœãŒå¾—ã‚‰ã‚Œã¾ã™ï¼š

### ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¾‹
```bash
$ go test -v
=== RUN   TestFileUpload
=== RUN   TestFileUpload/Small_file_upload
=== RUN   TestFileUpload/Large_file_upload
=== RUN   TestFileUpload/Checksum_verification
--- PASS: TestFileUpload (0.30s)

=== RUN   TestDataCollection
=== RUN   TestDataCollection/Batch_data_points
=== RUN   TestDataCollection/Real_time_streaming
--- PASS: TestDataCollection (0.20s)

=== RUN   TestLogAggregation
=== RUN   TestLogAggregation/Log_collection
=== RUN   TestLogAggregation/Filtering_and_indexing
--- PASS: TestLogAggregation (0.15s)

PASS
```

### ãƒ—ãƒ­ã‚°ãƒ©ãƒ å®Ÿè¡Œä¾‹
```bash
$ go run main.go
=== gRPC Client-side Streaming Demo ===

Starting servers on :8080...

File upload server ready
Data collection server ready
Log aggregation server ready

Testing file upload...
Uploading test_file.txt (10MB)...
Upload progress: 32KB/10MB (0.3%)
Upload progress: 1024KB/10MB (10.2%)
Upload progress: 5120KB/10MB (51.2%)
Upload completed: test_file.txt (ID: file_test_file.txt_1642597800)

Testing data collection...
Sending 10000 data points...
Batch 1: 100 points processed
Batch 50: 5000 points processed
Batch 100: 10000 points processed
Collection completed: 10000 total, 9985 successful, 15 errors

Press Ctrl+C to stop...
```

### ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœä¾‹
```bash
$ go test -bench=.
BenchmarkFileUpload-8        100    15000000 ns/op   1024 B/op    5 allocs/op
BenchmarkDataCollection-8   2000     1000000 ns/op    200 B/op    3 allocs/op
BenchmarkLogCollection-8    1500     1200000 ns/op    150 B/op    2 allocs/op
```

## ğŸ’¡ ãƒ’ãƒ³ãƒˆ (Hints)

è©°ã¾ã£ã¦ã—ã¾ã£ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®ãƒ’ãƒ³ãƒˆã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š

### åŸºæœ¬çš„ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
```go
func (c *Client) SendData(data []DataPoint) error {
    stream, err := c.client.CollectData(context.Background())
    if err != nil {
        return err
    }
    
    for _, point := range data {
        if err := stream.Send(&point); err != nil {
            return err
        }
    }
    
    result, err := stream.CloseAndRecv()
    if err != nil {
        return err
    }
    
    log.Printf("Processed: %d", result.TotalProcessed)
    return nil
}
```

### ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ã®å—ä¿¡å‡¦ç†
```go
func (s *Server) CollectData(stream pb.Service_CollectDataServer) error {
    var count int
    
    for {
        data, err := stream.Recv()
        if err == io.EOF {
            // ã‚¹ãƒˆãƒªãƒ¼ãƒ çµ‚äº†
            return stream.SendAndClose(&pb.Result{
                TotalProcessed: int32(count),
                Status:        "SUCCESS",
            })
        }
        if err != nil {
            return err
        }
        
        // ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        if err := s.processData(data); err != nil {
            return err
        }
        count++
    }
}
```

### ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ£ãƒ³ã‚¯ã®é€ä¿¡
```go
func (c *Client) UploadFile(filePath string) error {
    file, err := os.Open(filePath)
    if err != nil {
        return err
    }
    defer file.Close()
    
    stream, err := c.client.UploadFile(context.Background())
    if err != nil {
        return err
    }
    
    buffer := make([]byte, 32*1024) // 32KB chunks
    for {
        n, err := file.Read(buffer)
        if err == io.EOF {
            break
        }
        if err != nil {
            return err
        }
        
        chunk := &pb.FileChunk{
            Data: buffer[:n],
        }
        
        if err := stream.Send(chunk); err != nil {
            return err
        }
    }
    
    result, err := stream.CloseAndRecv()
    return err
}
```

## å®Ÿè¡Œæ–¹æ³•

```bash
# ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒãƒƒãƒ•ã‚¡ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
protoc --go_out=. --go-grpc_out=. *.proto

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
go test -v

# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¸¬å®š
go test -bench=.

# ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
go run main.go

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ†ã‚¹ãƒˆï¼ˆåˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ï¼‰
grpcurl -d '{"file_name":"test.txt"}' localhost:8080 FileUploadService/UploadFile
```

## å‚è€ƒè³‡æ–™

- [gRPC Go Documentation](https://grpc.io/docs/languages/go/)
- [Protocol Buffers Guide](https://developers.google.com/protocol-buffers)
- [gRPC Client-side Streaming](https://grpc.io/docs/what-is-grpc/core-concepts/#client-streaming-rpc)
- [gRPC Error Handling](https://grpc.io/docs/guides/error/)