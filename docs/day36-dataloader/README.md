# Day 36: DataLoaderãƒ‘ã‚¿ãƒ¼ãƒ³å®Ÿè£…

## ğŸ¯ æœ¬æ—¥ã®ç›®æ¨™

N+1å•é¡Œã‚’æ ¹æœ¬çš„ã«è§£æ±ºã™ã‚‹DataLoaderãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ·±ãç†è§£ã—ã€é«˜æ€§èƒ½ãªãƒãƒƒãƒå‡¦ç†ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚å®Ÿç”¨çš„ãªã‚·ãƒŠãƒªã‚ªã‚’é€šã˜ã¦ã€å¤§è¦æ¨¡ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§æ±‚ã‚ã‚‰ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹æœ€é©åŒ–æŠ€è¡“ã‚’ç¿’å¾—ã™ã‚‹ã€‚

## ğŸ“– è§£èª¬

### DataLoaderãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã¯

DataLoaderãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã€**ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã®æœ€é©åŒ–**ã¨**ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®å‘ä¸Š**ã‚’åŒæ™‚ã«å®Ÿç¾ã™ã‚‹ç”»æœŸçš„ãªãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚Facebookï¼ˆç¾Metaï¼‰ãŒé–‹ç™ºã—ãŸGraphQLã®å®Ÿè£…ã§æ¡ç”¨ã•ã‚Œã€ç¾åœ¨ã§ã¯æ§˜ã€…ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚

**å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å•é¡Œï¼š**

```go
// âŒ éåŠ¹ç‡ãªN+1å•é¡Œã®ã‚ã‚‹å®Ÿè£…
func GetUsersWithPosts(userIDs []int) ([]UserWithPosts, error) {
    var users []UserWithPosts
    
    for _, userID := range userIDs {
        // 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å–å¾—ï¼ˆNå›ã®ã‚¯ã‚¨ãƒªï¼‰
        user, err := db.QueryRow("SELECT * FROM users WHERE id = ?", userID).Scan(...)
        if err != nil {
            return nil, err
        }
        
        // 2. å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŠ•ç¨¿ã‚’å–å¾—ï¼ˆã•ã‚‰ã«Nå›ã®ã‚¯ã‚¨ãƒªï¼‰
        posts, err := db.Query("SELECT * FROM posts WHERE user_id = ?", userID).Scan(...)
        if err != nil {
            return nil, err
        }
        
        users = append(users, UserWithPosts{User: user, Posts: posts})
    }
    
    return users // åˆè¨ˆ 1 + N + N = 2N+1 å›ã®ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
}
```

**DataLoaderã‚’ä½¿ã£ãŸåŠ¹ç‡çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼š**

```go
// âœ… DataLoaderã«ã‚ˆã‚‹æœ€é©åŒ–ã•ã‚ŒãŸå®Ÿè£…
func GetUsersWithPostsOptimized(userIDs []int) ([]UserWithPosts, error) {
    var users []UserWithPosts
    
    // 1. å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ä¸€æ‹¬å–å¾—ï¼ˆ1å›ã®ã‚¯ã‚¨ãƒªï¼‰
    usersData, err := userLoader.LoadMany(context.Background(), userIDs)
    if err != nil {
        return nil, err
    }
    
    // 2. å…¨æŠ•ç¨¿ã‚’ä¸€æ‹¬å–å¾—ï¼ˆ1å›ã®ã‚¯ã‚¨ãƒªï¼‰
    postsData, err := postLoader.LoadMany(context.Background(), userIDs)
    if err != nil {
        return nil, err
    }
    
    // 3. ãƒ‡ãƒ¼ã‚¿ã‚’çµ„ã¿åˆã‚ã›
    for i, user := range usersData {
        users = append(users, UserWithPosts{
            User:  user,
            Posts: postsData[i],
        })
    }
    
    return users // åˆè¨ˆ 2å›ã®ã‚¯ã‚¨ãƒªã®ã¿
}
```

### DataLoaderã®æ ¸å¿ƒåŸç†

#### 1. **ãƒãƒƒãƒãƒ³ã‚°ï¼ˆBatchingï¼‰**

è¤‡æ•°ã®å€‹åˆ¥ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å˜ä¸€ã®ãƒãƒƒãƒãƒªã‚¯ã‚¨ã‚¹ãƒˆã«è‡ªå‹•çš„ã«çµåˆï¼š

```go
// å€‹åˆ¥ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
userLoader.Load(ctx, 1)    // SELECT * FROM users WHERE id = 1
userLoader.Load(ctx, 2)    // SELECT * FROM users WHERE id = 2
userLoader.Load(ctx, 3)    // SELECT * FROM users WHERE id = 3

// DataLoaderãŒè‡ªå‹•çš„ã«ä»¥ä¸‹ã«æœ€é©åŒ–ï¼š
// SELECT * FROM users WHERE id IN (1, 2, 3)
```

#### 2. **ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°**

åŒä¸€ãƒªã‚¯ã‚¨ã‚¹ãƒˆå†…ã§ã®é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ã‚’å®Œå…¨ã«é™¤å»ï¼š

```go
// æœ€åˆã®ã‚¢ã‚¯ã‚»ã‚¹
user1 := userLoader.Load(ctx, 1) // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰

// åŒã˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆå†…ã§ã®å†ã‚¢ã‚¯ã‚»ã‚¹
user1Again := userLoader.Load(ctx, 1) // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å³åº§ã«è¿”å´ï¼ˆDBæœªã‚¢ã‚¯ã‚»ã‚¹ï¼‰
```

#### 3. **é…å»¶å®Ÿè¡Œï¼ˆDeferred Executionï¼‰**

ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å³åº§ã«å®Ÿè¡Œã›ãšã€æœ€é©ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ãƒãƒƒãƒå‡¦ç†ï¼š

```go
// ã“ã‚Œã‚‰ã®å‘¼ã³å‡ºã—ã¯å³åº§ã«ã¯å®Ÿè¡Œã•ã‚Œãªã„
thunk1 := userLoader.LoadThunk(ctx, 1)
thunk2 := userLoader.LoadThunk(ctx, 2) 
thunk3 := userLoader.LoadThunk(ctx, 3)

// å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã«ãªã£ãŸæ™‚ç‚¹ã§ã€ã¾ã¨ã‚ã¦å®Ÿè¡Œ
user1, err1 := thunk1()  // ã“ã®æ™‚ç‚¹ã§ä¸€æ‹¬ã‚¯ã‚¨ãƒªãŒå®Ÿè¡Œã•ã‚Œã‚‹
user2, err2 := thunk2()  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
user3, err3 := thunk3()  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
```

### å®Œå…¨ãªDataLoaderå®Ÿè£…

#### æ ¸å¿ƒã®DataLoaderæ§‹é€ ä½“

```go
package main

import (
    "context"
    "fmt"
    "sync"
    "time"
)

// DataLoader ã¯é«˜æ€§èƒ½ãƒãƒƒãƒãƒ³ã‚°ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã‚’æä¾›
type DataLoader[K comparable, V any] struct {
    batchFn       BatchFunc[K, V]      // ãƒãƒƒãƒå‡¦ç†é–¢æ•°
    cache         map[K]*result[V]     // ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    batch         []K                  // ç¾åœ¨ã®ãƒãƒƒãƒã‚­ãƒ¥ãƒ¼
    waiting       map[K][]chan *result[V] // å¾…æ©Ÿä¸­ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    maxBatchSize  int                  // æœ€å¤§ãƒãƒƒãƒã‚µã‚¤ã‚º
    batchTimeout  time.Duration        // ãƒãƒƒãƒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    mu            sync.Mutex           // ä¸¦è¡Œåˆ¶å¾¡
    stats         *LoaderStats         // çµ±è¨ˆæƒ…å ±
}

// BatchFunc ã¯ãƒãƒƒãƒå‡¦ç†ã®é–¢æ•°å‹å®šç¾©
type BatchFunc[K comparable, V any] func(ctx context.Context, keys []K) ([]V, []error)

// result ã¯å€¤ã¨ã‚¨ãƒ©ãƒ¼ã‚’ãƒšã‚¢ã§ä¿æŒ
type result[V any] struct {
    value V
    err   error
    loadTime time.Time
}

// LoaderStats ã¯ DataLoader ã®çµ±è¨ˆæƒ…å ±
type LoaderStats struct {
    BatchCount      int64         // ãƒãƒƒãƒå®Ÿè¡Œå›æ•°
    CacheHits       int64         // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ•°
    CacheMisses     int64         // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹æ•°
    TotalLoadTime   time.Duration // ç´¯ç©ãƒ­ãƒ¼ãƒ‰æ™‚é–“
    AverageBatchSize float64      // å¹³å‡ãƒãƒƒãƒã‚µã‚¤ã‚º
    mu              sync.RWMutex
}

// NewDataLoader ã¯æ–°ã—ã„ DataLoader ã‚’ä½œæˆ
func NewDataLoader[K comparable, V any](
    batchFn BatchFunc[K, V],
    options ...Option[K, V],
) *DataLoader[K, V] {
    dl := &DataLoader[K, V]{
        batchFn:       batchFn,
        cache:         make(map[K]*result[V]),
        waiting:       make(map[K][]chan *result[V]),
        maxBatchSize:  100,
        batchTimeout:  16 * time.Millisecond,
        stats:         &LoaderStats{},
    }
    
    for _, opt := range options {
        opt(dl)
    }
    
    return dl
}

// Load ã¯å˜ä¸€ã‚­ãƒ¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
func (dl *DataLoader[K, V]) Load(ctx context.Context, key K) (V, error) {
    return dl.LoadThunk(ctx, key)()
}

// LoadMany ã¯è¤‡æ•°ã‚­ãƒ¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬ãƒ­ãƒ¼ãƒ‰
func (dl *DataLoader[K, V]) LoadMany(ctx context.Context, keys []K) ([]V, []error) {
    thunks := make([]Thunk[V], len(keys))
    for i, key := range keys {
        thunks[i] = dl.LoadThunk(ctx, key)
    }
    
    values := make([]V, len(keys))
    errors := make([]error, len(keys))
    
    // ä¸¦è¡Œå®Ÿè¡Œã§åŠ¹ç‡åŒ–
    var wg sync.WaitGroup
    for i, thunk := range thunks {
        wg.Add(1)
        go func(index int, t Thunk[V]) {
            defer wg.Done()
            values[index], errors[index] = t()
        }(i, thunk)
    }
    wg.Wait()
    
    return values, errors
}

// Thunk ã¯é…å»¶å®Ÿè¡Œå¯èƒ½ãªè¨ˆç®—ã‚’è¡¨ç¾
type Thunk[V any] func() (V, error)

// LoadThunk ã¯é…å»¶å®Ÿè¡Œç”¨ã® thunk ã‚’è¿”å´
func (dl *DataLoader[K, V]) LoadThunk(ctx context.Context, key K) Thunk[V] {
    dl.mu.Lock()
    defer dl.mu.Unlock()
    
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
    if result, exists := dl.cache[key]; exists {
        dl.stats.recordCacheHit()
        return func() (V, error) {
            return result.value, result.err
        }
    }
    
    dl.stats.recordCacheMiss()
    
    // çµæœãƒãƒ£ãƒãƒ«ä½œæˆ
    resultCh := make(chan *result[V], 1)
    
    // å¾…æ©Ÿãƒªã‚¹ãƒˆã«è¿½åŠ 
    if dl.waiting[key] == nil {
        dl.waiting[key] = []chan *result[V]{}
        dl.batch = append(dl.batch, key)
    }
    dl.waiting[key] = append(dl.waiting[key], resultCh)
    
    // ãƒãƒƒãƒå®Ÿè¡Œãƒˆãƒªã‚¬ãƒ¼
    if len(dl.batch) >= dl.maxBatchSize {
        dl.executeImmediately(ctx)
    } else if len(dl.batch) == 1 {
        // æœ€åˆã®è¦ç´ ã§ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹
        go dl.executeAfterTimeout(ctx)
    }
    
    return func() (V, error) {
        select {
        case result := <-resultCh:
            return result.value, result.err
        case <-ctx.Done():
            var zero V
            return zero, ctx.Err()
        }
    }
}

// executeImmediately ã¯ç¾åœ¨ã®ãƒãƒƒãƒã‚’å³åº§ã«å®Ÿè¡Œ
func (dl *DataLoader[K, V]) executeImmediately(ctx context.Context) {
    if len(dl.batch) == 0 {
        return
    }
    
    keys := make([]K, len(dl.batch))
    copy(keys, dl.batch)
    waiting := make(map[K][]chan *result[V])
    for k, v := range dl.waiting {
        waiting[k] = v
    }
    
    // ãƒãƒƒãƒã‚¯ãƒªã‚¢
    dl.batch = dl.batch[:0]
    dl.waiting = make(map[K][]chan *result[V])
    
    go func() {
        startTime := time.Now()
        values, errors := dl.batchFn(ctx, keys)
        loadTime := time.Since(startTime)
        
        dl.stats.recordBatch(len(keys), loadTime)
        
        for i, key := range keys {
            var result *result[V]
            if i < len(values) && i < len(errors) {
                result = &result[V]{
                    value:    values[i],
                    err:      errors[i],
                    loadTime: time.Now(),
                }
            } else {
                var zero V
                result = &result[V]{
                    value:    zero,
                    err:      fmt.Errorf("missing result for key"),
                    loadTime: time.Now(),
                }
            }
            
            // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            dl.mu.Lock()
            dl.cache[key] = result
            dl.mu.Unlock()
            
            // å¾…æ©Ÿä¸­ã®å…¨ãƒãƒ£ãƒãƒ«ã«é€ä¿¡
            for _, ch := range waiting[key] {
                select {
                case ch <- result:
                default:
                }
                close(ch)
            }
        }
    }()
}

// executeAfterTimeout ã¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¾Œã«ãƒãƒƒãƒã‚’å®Ÿè¡Œ
func (dl *DataLoader[K, V]) executeAfterTimeout(ctx context.Context) {
    timer := time.NewTimer(dl.batchTimeout)
    defer timer.Stop()
    
    select {
    case <-timer.C:
        dl.mu.Lock()
        if len(dl.batch) > 0 {
            dl.executeImmediately(ctx)
        }
        dl.mu.Unlock()
    case <-ctx.Done():
        return
    }
}

// GetStats ã¯çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
func (dl *DataLoader[K, V]) GetStats() LoaderStats {
    return dl.stats.get()
}

// ClearCache ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
func (dl *DataLoader[K, V]) ClearCache() {
    dl.mu.Lock()
    defer dl.mu.Unlock()
    dl.cache = make(map[K]*result[V])
}

// Prime ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«å€¤ã‚’äº‹å‰è¨­å®š
func (dl *DataLoader[K, V]) Prime(key K, value V) {
    dl.mu.Lock()
    defer dl.mu.Unlock()
    dl.cache[key] = &result[V]{
        value:    value,
        err:      nil,
        loadTime: time.Now(),
    }
}
```

#### çµ±è¨ˆæƒ…å ±ç®¡ç†

```go
// recordCacheHit ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã‚’è¨˜éŒ²
func (s *LoaderStats) recordCacheHit() {
    s.mu.Lock()
    defer s.mu.Unlock()
    s.CacheHits++
}

// recordCacheMiss ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã‚’è¨˜éŒ²
func (s *LoaderStats) recordCacheMiss() {
    s.mu.Lock()
    defer s.mu.Unlock()
    s.CacheMisses++
}

// recordBatch ã¯ãƒãƒƒãƒå®Ÿè¡Œã‚’è¨˜éŒ²
func (s *LoaderStats) recordBatch(batchSize int, loadTime time.Duration) {
    s.mu.Lock()
    defer s.mu.Unlock()
    
    s.BatchCount++
    s.TotalLoadTime += loadTime
    
    // ç§»å‹•å¹³å‡ã§å¹³å‡ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’è¨ˆç®—
    alpha := 0.1 // å¹³æ»‘åŒ–ä¿‚æ•°
    s.AverageBatchSize = alpha*float64(batchSize) + (1-alpha)*s.AverageBatchSize
}

// get ã¯çµ±è¨ˆæƒ…å ±ã®ã‚³ãƒ”ãƒ¼ã‚’å–å¾—
func (s *LoaderStats) get() LoaderStats {
    s.mu.RLock()
    defer s.mu.RUnlock()
    return LoaderStats{
        BatchCount:       s.BatchCount,
        CacheHits:        s.CacheHits,
        CacheMisses:      s.CacheMisses,
        TotalLoadTime:    s.TotalLoadTime,
        AverageBatchSize: s.AverageBatchSize,
    }
}

// CacheHitRate ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã‚’è¨ˆç®—
func (s *LoaderStats) CacheHitRate() float64 {
    s.mu.RLock()
    defer s.mu.RUnlock()
    
    total := s.CacheHits + s.CacheMisses
    if total == 0 {
        return 0
    }
    return float64(s.CacheHits) / float64(total)
}
```

#### è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³

```go
// Option ã¯ DataLoader ã®è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
type Option[K comparable, V any] func(*DataLoader[K, V])

// WithMaxBatchSize ã¯æœ€å¤§ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’è¨­å®š
func WithMaxBatchSize[K comparable, V any](size int) Option[K, V] {
    return func(dl *DataLoader[K, V]) {
        if size > 0 {
            dl.maxBatchSize = size
        }
    }
}

// WithBatchTimeout ã¯ãƒãƒƒãƒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
func WithBatchTimeout[K comparable, V any](timeout time.Duration) Option[K, V] {
    return func(dl *DataLoader[K, V]) {
        if timeout > 0 {
            dl.batchTimeout = timeout
        }
    }
}

// WithCache ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’è¨­å®š
func WithCache[K comparable, V any](enabled bool) Option[K, V] {
    return func(dl *DataLoader[K, V]) {
        if !enabled {
            dl.cache = nil
        }
    }
}

// WithStats ã¯çµ±è¨ˆæƒ…å ±åé›†ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’è¨­å®š
func WithStats[K comparable, V any](enabled bool) Option[K, V] {
    return func(dl *DataLoader[K, V]) {
        if !enabled {
            dl.stats = nil
        }
    }
}
```

### å®Ÿç”¨çš„ãªDataLoaderå®Ÿè£…ä¾‹

#### ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»æŠ•ç¨¿ã‚·ã‚¹ãƒ†ãƒ ã§ã®æ´»ç”¨

```go
// User ã¨ Post ã®å®Ÿä½“
type User struct {
    ID    int    `json:"id"`
    Name  string `json:"name"`
    Email string `json:"email"`
}

type Post struct {
    ID     int    `json:"id"`
    Title  string `json:"title"`
    UserID int    `json:"user_id"`
    Body   string `json:"body"`
}

// UserLoader ã®å®Ÿè£…
type UserLoader struct {
    loader *DataLoader[int, *User]
    db     *sql.DB
}

func NewUserLoader(db *sql.DB) *UserLoader {
    batchFn := func(ctx context.Context, userIDs []int) ([]*User, []error) {
        // INå¥ã‚’ä½¿ã£ãŸåŠ¹ç‡çš„ãªä¸€æ‹¬å–å¾—
        query := `SELECT id, name, email FROM users WHERE id IN (` + 
                strings.Repeat("?,", len(userIDs)-1) + "?)"
        
        args := make([]interface{}, len(userIDs))
        for i, id := range userIDs {
            args[i] = id
        }
        
        rows, err := db.QueryContext(ctx, query, args...)
        if err != nil {
            // å…¨ã¦åŒã˜ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™
            errors := make([]error, len(userIDs))
            users := make([]*User, len(userIDs))
            for i := range errors {
                errors[i] = err
            }
            return users, errors
        }
        defer rows.Close()
        
        // çµæœã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
        userMap := make(map[int]*User)
        for rows.Next() {
            user := &User{}
            if err := rows.Scan(&user.ID, &user.Name, &user.Email); err != nil {
                continue
            }
            userMap[user.ID] = user
        }
        
        // å…ƒã®é †åºã§çµæœã‚’æ§‹ç¯‰
        users := make([]*User, len(userIDs))
        errors := make([]error, len(userIDs))
        for i, id := range userIDs {
            if user, found := userMap[id]; found {
                users[i] = user
                errors[i] = nil
            } else {
                users[i] = nil
                errors[i] = fmt.Errorf("user not found: %d", id)
            }
        }
        
        return users, errors
    }
    
    return &UserLoader{
        loader: NewDataLoader(batchFn,
            WithMaxBatchSize[int, *User](50),
            WithBatchTimeout[int, *User](10*time.Millisecond),
        ),
        db: db,
    }
}

func (ul *UserLoader) Load(ctx context.Context, userID int) (*User, error) {
    return ul.loader.Load(ctx, userID)
}

func (ul *UserLoader) LoadMany(ctx context.Context, userIDs []int) ([]*User, []error) {
    return ul.loader.LoadMany(ctx, userIDs)
}

// PostLoader ã®å®Ÿè£…
type PostLoader struct {
    loader *DataLoader[int, []*Post]
    db     *sql.DB
}

func NewPostLoader(db *sql.DB) *PostLoader {
    batchFn := func(ctx context.Context, userIDs []int) ([][]*Post, []error) {
        query := `SELECT id, title, user_id, body FROM posts WHERE user_id IN (` +
                strings.Repeat("?,", len(userIDs)-1) + "?) ORDER BY user_id, id"
        
        args := make([]interface{}, len(userIDs))
        for i, id := range userIDs {
            args[i] = id
        }
        
        rows, err := db.QueryContext(ctx, query, args...)
        if err != nil {
            errors := make([]error, len(userIDs))
            posts := make([][]*Post, len(userIDs))
            for i := range errors {
                errors[i] = err
                posts[i] = []*Post{}
            }
            return posts, errors
        }
        defer rows.Close()
        
        // ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã”ã¨ã«æŠ•ç¨¿ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        postMap := make(map[int][]*Post)
        for rows.Next() {
            post := &Post{}
            if err := rows.Scan(&post.ID, &post.Title, &post.UserID, &post.Body); err != nil {
                continue
            }
            postMap[post.UserID] = append(postMap[post.UserID], post)
        }
        
        // çµæœã‚’æ§‹ç¯‰
        posts := make([][]*Post, len(userIDs))
        errors := make([]error, len(userIDs))
        for i, userID := range userIDs {
            if userPosts, found := postMap[userID]; found {
                posts[i] = userPosts
            } else {
                posts[i] = []*Post{} // ç©ºã®ã‚¹ãƒ©ã‚¤ã‚¹
            }
            errors[i] = nil
        }
        
        return posts, errors
    }
    
    return &PostLoader{
        loader: NewDataLoader(batchFn,
            WithMaxBatchSize[int, []*Post](30),
            WithBatchTimeout[int, []*Post](15*time.Millisecond),
        ),
        db: db,
    }
}

func (pl *PostLoader) Load(ctx context.Context, userID int) ([]*Post, error) {
    return pl.loader.Load(ctx, userID)
}
```

#### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šã‚·ã‚¹ãƒ†ãƒ 

```go
// LoaderMetrics ã¯è¤‡æ•°ã®DataLoaderã®çµ±è¨ˆã‚’é›†è¨ˆ
type LoaderMetrics struct {
    loaders map[string]StatProvider
    mu      sync.RWMutex
}

type StatProvider interface {
    GetStats() LoaderStats
}

func NewLoaderMetrics() *LoaderMetrics {
    return &LoaderMetrics{
        loaders: make(map[string]StatProvider),
    }
}

func (lm *LoaderMetrics) RegisterLoader(name string, loader StatProvider) {
    lm.mu.Lock()
    defer lm.mu.Unlock()
    lm.loaders[name] = loader
}

func (lm *LoaderMetrics) GetAggregatedStats() map[string]LoaderStats {
    lm.mu.RLock()
    defer lm.mu.RUnlock()
    
    stats := make(map[string]LoaderStats)
    for name, loader := range lm.loaders {
        stats[name] = loader.GetStats()
    }
    return stats
}

func (lm *LoaderMetrics) PrintReport() {
    stats := lm.GetAggregatedStats()
    
    fmt.Println("=== DataLoader Performance Report ===")
    for name, stat := range stats {
        fmt.Printf("\n%s:\n", name)
        fmt.Printf("  Batches: %d\n", stat.BatchCount)
        fmt.Printf("  Cache Hit Rate: %.2f%%\n", stat.CacheHitRate()*100)
        fmt.Printf("  Avg Batch Size: %.1f\n", stat.AverageBatchSize)
        if stat.BatchCount > 0 {
            avgTime := stat.TotalLoadTime / time.Duration(stat.BatchCount)
            fmt.Printf("  Avg Load Time: %v\n", avgTime)
        }
    }
}
```

#### GraphQLçµ±åˆä¾‹

```go
// GraphQL ãƒªã‚¾ãƒ«ãƒã§ã®DataLoaderæ´»ç”¨
type Resolvers struct {
    userLoader *UserLoader
    postLoader *PostLoader
}

func (r *Resolvers) User(ctx context.Context, id int) (*User, error) {
    return r.userLoader.Load(ctx, id)
}

func (r *Resolvers) UserPosts(ctx context.Context, user *User) ([]*Post, error) {
    return r.postLoader.Load(ctx, user.ID)
}

// è¤‡é›‘ãªã‚¯ã‚¨ãƒªã§ã®åŠ¹æœ
func (r *Resolvers) UsersWithPosts(ctx context.Context, userIDs []int) ([]*UserWithPosts, error) {
    // ä¸¦è¡Œã—ã¦ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    usersCh := make(chan []*User, 1)
    postsCh := make(chan [][]*Post, 1)
    errCh := make(chan error, 2)
    
    go func() {
        users, errs := r.userLoader.LoadMany(ctx, userIDs)
        for _, err := range errs {
            if err != nil {
                errCh <- err
                return
            }
        }
        usersCh <- users
    }()
    
    go func() {
        posts, errs := r.postLoader.LoadMany(ctx, userIDs)
        for _, err := range errs {
            if err != nil {
                errCh <- err
                return
            }
        }
        postsCh <- posts
    }()
    
    var users []*User
    var posts [][]*Post
    
    for i := 0; i < 2; i++ {
        select {
        case u := <-usersCh:
            users = u
        case p := <-postsCh:
            posts = p
        case err := <-errCh:
            return nil, err
        case <-ctx.Done():
            return nil, ctx.Err()
        }
    }
    
    // çµæœã‚’çµåˆ
    result := make([]*UserWithPosts, len(userIDs))
    for i := range userIDs {
        result[i] = &UserWithPosts{
            User:  users[i],
            Posts: posts[i],
        }
    }
    
    return result, nil
}

type UserWithPosts struct {
    User  *User   `json:"user"`
    Posts []*Post `json:"posts"`
}
```

## ğŸ“ èª²é¡Œï¼ˆå®Ÿè£…è¦ä»¶ï¼‰

`main_test.go`ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ã™ã¹ã¦ãƒ‘ã‚¹ã™ã‚‹ã‚ˆã†ã«ã€ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š

### 1. **æ±ç”¨DataLoaderã‚·ã‚¹ãƒ†ãƒ **
- ã‚¸ã‚§ãƒãƒªã‚¯ã‚¹ã‚’æ´»ç”¨ã—ãŸå‹å®‰å…¨ãªå®Ÿè£…
- ãƒãƒƒãƒãƒ³ã‚°ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ»é…å»¶å®Ÿè¡Œã®å®Œå…¨ã‚µãƒãƒ¼ãƒˆ
- çµ±è¨ˆæƒ…å ±åé›†ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

### 2. **UserLoaderï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å°‚ç”¨ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼‰**
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®åŠ¹ç‡çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€æ‹¬å–å¾—
- æ¬ æãƒ‡ãƒ¼ã‚¿ã®é©åˆ‡ãªãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ‰åŠ¹æ´»ç”¨

### 3. **PostLoaderï¼ˆæŠ•ç¨¿å°‚ç”¨ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼‰**
- ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’ã‚­ãƒ¼ã¨ã—ãŸæŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã®ä¸€æ‹¬å–å¾—
- 1å¯¾å¤šé–¢ä¿‚ã®åŠ¹ç‡çš„ãªå‡¦ç†
- ç©ºã®çµæœã‚»ãƒƒãƒˆã®é©åˆ‡ãªå‡¦ç†

### 4. **çµ±åˆãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª**
- N+1å•é¡Œã®å›é¿æ¤œè¨¼
- ä¸¦è¡Œã‚¢ã‚¯ã‚»ã‚¹æ™‚ã®å®‰å…¨æ€§ç¢ºèª
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„åŠ¹æœã®æ¸¬å®š

**å®Ÿè£…ã™ã¹ãé–¢æ•°ï¼š**

```go
// æ±ç”¨DataLoader
func NewDataLoader[K comparable, V any](batchFn BatchFunc[K, V], options ...Option[K, V]) *DataLoader[K, V]
func (dl *DataLoader[K, V]) Load(ctx context.Context, key K) (V, error)
func (dl *DataLoader[K, V]) LoadMany(ctx context.Context, keys []K) ([]V, []error)
func (dl *DataLoader[K, V]) GetStats() LoaderStats

// å°‚ç”¨ãƒ­ãƒ¼ãƒ€ãƒ¼
func NewUserLoader(db *sql.DB) *UserLoader
func NewPostLoader(db *sql.DB) *PostLoader
```

## âœ… æœŸå¾…ã•ã‚Œã‚‹æŒ™å‹•

å®Ÿè£…ãŒæ­£ã—ãå®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªçµæœãŒå¾—ã‚‰ã‚Œã¾ã™ï¼š

### ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¾‹
```bash
$ go test -v
=== RUN   TestDataLoader_Load
=== RUN   TestDataLoader_Load/Single_user_load
=== RUN   TestDataLoader_Load/Cache_effectiveness
--- PASS: TestDataLoader_Load (0.01s)

=== RUN   TestDataLoader_LoadMany
=== RUN   TestDataLoader_LoadMany/Batch_loading
=== RUN   TestDataLoader_LoadMany/Mixed_cache_miss_hit
--- PASS: TestDataLoader_LoadMany (0.02s)

=== RUN   TestDataLoader_Batch
=== RUN   TestDataLoader_Batch/Automatic_batching
=== RUN   TestDataLoader_Batch/Timeout_batching
--- PASS: TestDataLoader_Batch (0.02s)

=== RUN   TestUserLoader_Integration
=== RUN   TestUserLoader_Integration/N_plus_one_prevention
--- PASS: TestUserLoader_Integration (0.01s)

=== RUN   TestPostLoader_Integration
=== RUN   TestPostLoader_Integration/User_posts_batching
--- PASS: TestPostLoader_Integration (0.01s)

PASS
ok      day36-dataloader    0.075s
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¾‹
```bash
$ go test -bench=.
BenchmarkDataLoader_Load-8           5000000    250 ns/op      48 B/op    2 allocs/op
BenchmarkDataLoader_LoadMany-8       1000000   1500 ns/op     256 B/op    8 allocs/op
BenchmarkUserLoader_NPlus1-8           10000 100000 ns/op    2048 B/op   50 allocs/op
BenchmarkUserLoader_Optimized-8      500000   3000 ns/op     512 B/op   10 allocs/op
```

### å®Ÿè¡Œæ™‚ãƒ­ã‚°ä¾‹
```
=== DataLoader Performance Report ===

UserLoader:
  Batches: 15
  Cache Hit Rate: 73.50%
  Avg Batch Size: 8.2
  Avg Load Time: 2.5ms

PostLoader:
  Batches: 12
  Cache Hit Rate: 45.20%
  Avg Batch Size: 12.1
  Avg Load Time: 4.1ms

Performance Improvement:
  Traditional N+1: 250 queries in 1.2s
  DataLoader: 27 batches in 85ms
  Speed Improvement: 14.1x
```

## ğŸ’¡ ãƒ’ãƒ³ãƒˆ

å®Ÿè£…ã«è©°ã¾ã£ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®ãƒ’ãƒ³ãƒˆã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š

### åŸºæœ¬çš„ãªãƒãƒƒãƒé–¢æ•°ã®å®Ÿè£…
```go
func userBatchFn(ctx context.Context, userIDs []int) ([]*User, []error) {
    // 1. INå¥ã§ã¾ã¨ã‚ã¦å–å¾—
    query := "SELECT id, name, email FROM users WHERE id IN (...)"
    
    // 2. çµæœã‚’ãƒãƒƒãƒ—ã«æ ¼ç´
    userMap := make(map[int]*User)
    
    // 3. å…ƒã®é †åºã§çµæœã‚’å†æ§‹ç¯‰
    users := make([]*User, len(userIDs))
    errors := make([]error, len(userIDs))
    
    return users, errors
}
```

### ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ´»ç”¨æ–¹æ³•
```go
// äº‹å‰ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
userLoader.Prime(1, &User{ID: 1, Name: "Alice"})

// ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã®ãƒ’ãƒƒãƒˆ
user, err := userLoader.Load(ctx, 1) // DBæœªã‚¢ã‚¯ã‚»ã‚¹
```

### çµ±è¨ˆæƒ…å ±ã®æ´»ç”¨
```go
stats := userLoader.GetStats()
fmt.Printf("Cache Hit Rate: %.2f%%\n", stats.CacheHitRate()*100)
```

**é‡è¦ãªå®Ÿè£…ãƒã‚¤ãƒ³ãƒˆï¼š**
- **ä¸¦è¡Œå®‰å…¨æ€§**: `sync.Mutex`ã‚’é©åˆ‡ã«ä½¿ç”¨
- **ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†**: goroutineãƒªãƒ¼ã‚¯ã®é˜²æ­¢
- **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: å€‹åˆ¥ã‚¨ãƒ©ãƒ¼ã¨ãƒãƒƒãƒã‚¨ãƒ©ãƒ¼ã®åŒºåˆ¥
- **ãƒ¡ãƒ¢ãƒªåŠ¹ç‡**: ä¸è¦ãªãƒ‡ãƒ¼ã‚¿ã‚³ãƒ”ãƒ¼ã®å›é¿

## å®Ÿè¡Œæ–¹æ³•

```bash
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æº–å‚™
docker run -d -p 5432:5432 -e POSTGRES_PASSWORD=test -e POSTGRES_DB=testdb postgres:15

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
go test -v
go test -race          # ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³æ¤œå‡º
go test -bench=.       # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¸¬å®š
go test -cover         # ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª
```