# Day 18: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®ã‚µã‚¤ã‚ºåˆ¶é™

## ğŸ¯ æœ¬æ—¥ã®ç›®æ¨™ (Today's Goal)

HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®ã‚µã‚¤ã‚ºã‚’åˆ¶é™ã™ã‚‹ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã‚’å®Ÿè£…ã—ã€ãƒ¡ãƒ¢ãƒªæ¯æ¸‡æ”»æ’ƒã‚„DoSæ”»æ’ƒã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã‚’ä¿è­·ã™ã‚‹ã€‚å‹•çš„ã‚µã‚¤ã‚ºåˆ¶é™ã€Content-Typeåˆ¥åˆ¶é™ã€é€²æ—ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã€ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ãªå‡¦ç†ã‚’å«ã‚€åŒ…æ‹¬çš„ãªãƒœãƒ‡ã‚£ã‚µã‚¤ã‚ºåˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

## ğŸ“– è§£èª¬ (Explanation)

### ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚µã‚¤ã‚ºåˆ¶é™ã®é‡è¦æ€§

```go
// ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚µã‚¤ã‚ºåˆ¶é™ã®é‡è¦æ€§ã€‘DoSæ”»æ’ƒã¨ãƒ¡ãƒ¢ãƒªæ¯æ¸‡ã‹ã‚‰ã®ä¿è­·
// âŒ å•é¡Œä¾‹ï¼šã‚µã‚¤ã‚ºåˆ¶é™ãªã—ã§ã®å£Šæ»…çš„ãªDoSæ”»æ’ƒè¢«å®³
func catastrophicNoBodySizeLimit() {
    // ğŸš¨ ç½å®³ä¾‹ï¼šç„¡åˆ¶é™ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£å—ä¿¡ã§ã‚µãƒ¼ãƒãƒ¼å´©å£Š
    
    http.HandleFunc("/upload", func(w http.ResponseWriter, r *http.Request) {
        log.Printf("Receiving upload request from %s", r.RemoteAddr)
        
        // âŒ ã‚µã‚¤ã‚ºåˆ¶é™ãªã—ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚’èª­ã¿å–ã‚Š
        bodyBytes, err := ioutil.ReadAll(r.Body)
        if err != nil {
            http.Error(w, "Failed to read body", http.StatusInternalServerError)
            return
        }
        
        // âŒ 100GB ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚‚ãƒ¡ãƒ¢ãƒªã«å…¨ã¦èª­ã¿è¾¼ã‚€
        // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: 100GB Ã— åŒæ™‚æ¥ç¶šæ•° = ã‚µãƒ¼ãƒãƒ¼ã‚¯ãƒ©ãƒƒã‚·ãƒ¥
        
        log.Printf("Received %d bytes from %s", len(bodyBytes), r.RemoteAddr)
        
        // âŒ æ”»æ’ƒè€…ãŒ100å€‹ã®æ¥ç¶šã§10GBãšã¤é€ä¿¡
        // åˆè¨ˆ1TB ã®ãƒ¡ãƒ¢ãƒªæ¶ˆè²» â†’ OOM Killerç™ºå‹•
        // âŒ æ­£å¸¸ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚‚å·»ãè¾¼ã¾ã‚Œã¦ã‚µãƒ¼ãƒ“ã‚¹å…¨åœæ­¢
        // âŒ ã‚¤ãƒ³ãƒ•ãƒ©ã‚³ã‚¹ãƒˆãŒçˆ†ç™ºçš„ã«å¢—å¤§
        
        w.WriteHeader(http.StatusOK)
        w.Write([]byte("Upload processed"))
    })
    
    log.Println("âŒ Starting server without body size limits...")
    http.ListenAndServe(":8080", nil)
    // çµæœï¼šãƒ¡ãƒ¢ãƒªæ¯æ¸‡æ”»æ’ƒã«ã‚ˆã‚Šæ•°åˆ†ã§ã‚µãƒ¼ãƒãƒ¼ãƒ€ã‚¦ãƒ³ã€å…¨ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢
}

// âœ… æ­£è§£ï¼šã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç´šãƒœãƒ‡ã‚£ã‚µã‚¤ã‚ºåˆ¶é™ã‚·ã‚¹ãƒ†ãƒ 
type EnterpriseBodySizeLimiter struct {
    // ã€åŸºæœ¬è¨­å®šã€‘
    globalMaxSize     int64                    // ã‚°ãƒ­ãƒ¼ãƒãƒ«æœ€å¤§ã‚µã‚¤ã‚º
    contentTypeLimits map[string]int64         // Content-Typeåˆ¥åˆ¶é™
    
    // ã€é«˜åº¦ãªæ©Ÿèƒ½ã€‘
    dynamicLimiter    *DynamicSizeLimiter      // å‹•çš„åˆ¶é™èª¿æ•´
    progressTracker   *ProgressTracker         // é€²æ—è¿½è·¡
    rateLimiter       *UploadRateLimiter       // ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é€Ÿåº¦åˆ¶é™
    
    // ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€‘
    blacklist         *IPBlacklist             // æ‚ªæ„IPãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆ
    anomalyDetector   *AnomalyDetector         // ç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
    
    // ã€ç›£è¦–ãƒ»ãƒ­ã‚°ã€‘
    metrics           *DetailedMetrics         // è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    logger            *log.Logger              // æ§‹é€ åŒ–ãƒ­ã‚°
    alertManager      *AlertManager            // ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†
    
    // ã€ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†ã€‘
    memoryMonitor     *MemoryMonitor           // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
    connectionLimiter *ConnectionLimiter       // åŒæ™‚æ¥ç¶šæ•°åˆ¶é™
    
    // ã€è¨­å®šç®¡ç†ã€‘
    configManager     *ConfigManager           // å‹•çš„è¨­å®šç®¡ç†
    mu                sync.RWMutex             // è¨­å®šå¤‰æ›´ç”¨ãƒŸãƒ¥ãƒ¼ãƒ†ãƒƒã‚¯ã‚¹
}

// ã€é‡è¦é–¢æ•°ã€‘ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç´šãƒœãƒ‡ã‚£ã‚µã‚¤ã‚ºåˆ¶é™ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
func NewEnterpriseBodySizeLimiter(config *LimiterConfig) *EnterpriseBodySizeLimiter {
    limiter := &EnterpriseBodySizeLimiter{
        globalMaxSize: config.GlobalMaxSize,
        contentTypeLimits: map[string]int64{
            "application/json":       1 << 20,     // 1MB - API calls
            "application/xml":        2 << 20,     // 2MB - structured data
            "multipart/form-data":    50 << 20,    // 50MB - file uploads
            "image/jpeg":             10 << 20,    // 10MB - image files
            "image/png":              10 << 20,    // 10MB - image files
            "video/mp4":              500 << 20,   // 500MB - video files
            "application/octet-stream": 100 << 20,  // 100MB - binary data
        },
        
        dynamicLimiter:    NewDynamicSizeLimiter(config.BaseLimit),
        progressTracker:   NewProgressTracker(config.MaxConcurrentUploads),
        rateLimiter:       NewUploadRateLimiter(config.MaxUploadRate),
        blacklist:         NewIPBlacklist(),
        anomalyDetector:   NewAnomalyDetector(),
        metrics:           NewDetailedMetrics(),
        logger:            log.New(os.Stdout, "[BODY-LIMITER] ", log.LstdFlags),
        alertManager:      NewAlertManager(),
        memoryMonitor:     NewMemoryMonitor(),
        connectionLimiter: NewConnectionLimiter(config.MaxConnections),
        configManager:     NewConfigManager(),
    }
    
    // ã€é‡è¦ã€‘ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆã®é–‹å§‹
    go limiter.startMonitoring()
    go limiter.startAnomalyDetection()
    go limiter.startMemoryMonitoring()
    
    limiter.logger.Printf("ğŸš€ Enterprise body size limiter initialized")
    limiter.logger.Printf("   Global limit: %.2f MB", float64(config.GlobalMaxSize)/1024/1024)
    limiter.logger.Printf("   Content-type limits: %d configured", len(limiter.contentTypeLimits))
    limiter.logger.Printf("   Max concurrent uploads: %d", config.MaxConcurrentUploads)
    
    return limiter
}

// ã€æ ¸ì‹¬ãƒ¡ã‚½ãƒƒãƒ‰ã€‘HTTPãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢å®Ÿè£…
func (limiter *EnterpriseBodySizeLimiter) Middleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        startTime := time.Now()
        requestID := generateRequestID()
        
        // ã€STEP 1ã€‘äº‹å‰ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
        if blocked, reason := limiter.blacklist.IsBlocked(getClientIP(r)); blocked {
            limiter.metrics.RecordBlocked(reason)
            limiter.logger.Printf("âŒ Blocked request from %s: %s", getClientIP(r), reason)
            http.Error(w, "Request blocked", http.StatusForbidden)
            return
        }
        
        // ã€STEP 2ã€‘åŒæ™‚æ¥ç¶šæ•°åˆ¶é™ãƒã‚§ãƒƒã‚¯
        if !limiter.connectionLimiter.AllowConnection() {
            limiter.metrics.RecordRejection("max_connections_exceeded")
            limiter.logger.Printf("âš ï¸  Connection limit exceeded from %s", getClientIP(r))
            http.Error(w, "Too many connections", http.StatusTooManyRequests)
            return
        }
        defer limiter.connectionLimiter.ReleaseConnection()
        
        // ã€STEP 3ã€‘Content-Typeåˆ¥åˆ¶é™å–å¾—
        contentType := r.Header.Get("Content-Type")
        mediaType, _, _ := mime.ParseMediaType(contentType)
        
        limiter.mu.RLock()
        typeLimit, exists := limiter.contentTypeLimits[mediaType]
        if !exists {
            typeLimit = limiter.globalMaxSize
        }
        limiter.mu.RUnlock()
        
        // å‹•çš„åˆ¶é™ã¨ã®æ¯”è¼ƒ
        dynamicLimit := limiter.dynamicLimiter.GetCurrentLimit()
        effectiveLimit := min(typeLimit, dynamicLimit)
        
        limiter.logger.Printf("ğŸ“Š Request %s: Content-Type=%s, Limit=%.2fMB", 
            requestID, mediaType, float64(effectiveLimit)/1024/1024)
        
        // ã€STEP 4ã€‘Content-Lengthäº‹å‰ãƒã‚§ãƒƒã‚¯
        if r.ContentLength > effectiveLimit {
            limiter.metrics.RecordRejection("content_length_exceeded")
            limiter.anomalyDetector.ReportSuspiciousActivity(getClientIP(r), "oversized_request", r.ContentLength)
            
            limiter.logger.Printf("âŒ Content-Length exceeded: %d > %d (client: %s)", 
                r.ContentLength, effectiveLimit, getClientIP(r))
            
            http.Error(w, fmt.Sprintf("Request body too large (limit: %.2f MB)", 
                float64(effectiveLimit)/1024/1024), http.StatusRequestEntityTooLarge)
            return
        }
        
        // ã€STEP 5ã€‘ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°é–‹å§‹
        if err := limiter.progressTracker.StartTracking(requestID, mediaType, r.ContentLength); err != nil {
            limiter.metrics.RecordRejection("tracking_failed")
            limiter.logger.Printf("âŒ Failed to start progress tracking: %v", err)
            http.Error(w, "Service temporarily unavailable", http.StatusServiceUnavailable)
            return
        }
        defer limiter.progressTracker.FinishTracking(requestID)
        
        // ã€STEP 6ã€‘ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if !limiter.rateLimiter.AllowUpload(getClientIP(r), r.ContentLength) {
            limiter.metrics.RecordRejection("rate_limit_exceeded")
            limiter.logger.Printf("âš ï¸  Upload rate limit exceeded for %s", getClientIP(r))
            http.Error(w, "Upload rate limit exceeded", http.StatusTooManyRequests)
            return
        }
        
        // ã€STEP 7ã€‘ãƒœãƒ‡ã‚£ãƒªãƒ¼ãƒ€ãƒ¼ã®ãƒ©ãƒƒãƒ—
        originalBody := r.Body
        r.Body = &EnterpriseBodyReader{
            reader:          originalBody,
            maxSize:         effectiveLimit,
            requestID:       requestID,
            progressTracker: limiter.progressTracker,
            rateLimiter:     limiter.rateLimiter,
            metrics:         limiter.metrics,
            logger:          limiter.logger,
            clientIP:        getClientIP(r),
            startTime:       startTime,
            anomalyDetector: limiter.anomalyDetector,
        }
        
        // ã€STEP 8ã€‘æ¬¡ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã¸
        limiter.metrics.RecordAccepted(mediaType)
        next.ServeHTTP(w, r)
        
        // ã€STEP 9ã€‘å®Œäº†æ™‚ã®çµ±è¨ˆæ›´æ–°
        duration := time.Since(startTime)
        limiter.metrics.RecordProcessingTime(duration)
        
        limiter.logger.Printf("âœ… Request %s completed in %v", requestID, duration)
    })
}

// ã€é«˜åº¦ãªæ©Ÿèƒ½ã€‘ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç´šãƒœãƒ‡ã‚£ãƒªãƒ¼ãƒ€ãƒ¼
type EnterpriseBodyReader struct {
    reader          io.ReadCloser
    maxSize         int64
    bytesRead       int64
    requestID       string
    progressTracker *ProgressTracker
    rateLimiter     *UploadRateLimiter
    metrics         *DetailedMetrics
    logger          *log.Logger
    clientIP        string
    startTime       time.Time
    anomalyDetector *AnomalyDetector
    lastProgressTime time.Time
}

// ã€é‡è¦ãƒ¡ã‚½ãƒƒãƒ‰ã€‘é«˜åº¦ãªReadå®Ÿè£…
func (reader *EnterpriseBodyReader) Read(p []byte) (n int, err error) {
    // ã€åˆ¶é™ãƒã‚§ãƒƒã‚¯ã€‘
    if reader.bytesRead >= reader.maxSize {
        reader.metrics.RecordRejection("stream_size_exceeded")
        reader.anomalyDetector.ReportSuspiciousActivity(reader.clientIP, "stream_size_exceeded", reader.bytesRead)
        reader.logger.Printf("âŒ Stream size exceeded for request %s: %d bytes", reader.requestID, reader.bytesRead)
        return 0, &BodySizeExceededError{
            RequestID: reader.requestID,
            BytesRead: reader.bytesRead,
            MaxSize:   reader.maxSize,
        }
    }
    
    // ã€èª­ã¿å–ã‚Šå¯èƒ½ã‚µã‚¤ã‚ºè¨ˆç®—ã€‘
    remaining := reader.maxSize - reader.bytesRead
    if int64(len(p)) > remaining {
        p = p[:remaining]
    }
    
    // ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãèª­ã¿å–ã‚Šã€‘
    readDeadline := time.Now().Add(30 * time.Second)
    if conn, ok := reader.reader.(interface{ SetReadDeadline(time.Time) error }); ok {
        conn.SetReadDeadline(readDeadline)
    }
    
    // ã€å®Ÿéš›ã®èª­ã¿å–ã‚Šã€‘
    n, err = reader.reader.Read(p)
    reader.bytesRead += int64(n)
    
    // ã€é€²æ—æ›´æ–°ã€‘
    now := time.Now()
    if now.Sub(reader.lastProgressTime) > 100*time.Millisecond {
        reader.progressTracker.UpdateProgress(reader.requestID, int64(n))
        reader.lastProgressTime = now
        
        // è»¢é€é€Ÿåº¦è¨ˆç®—
        duration := now.Sub(reader.startTime)
        if duration > 0 {
            rate := float64(reader.bytesRead) / duration.Seconds()
            reader.metrics.RecordTransferRate(rate)
            
            // ç•°å¸¸ã«é…ã„è»¢é€ã®æ¤œçŸ¥ï¼ˆSlowlorisæ”»æ’ƒå¯¾ç­–ï¼‰
            if rate < 1024 && duration > 10*time.Second { // 1KB/sæœªæº€ãŒ10ç§’ä»¥ä¸Š
                reader.anomalyDetector.ReportSuspiciousActivity(reader.clientIP, "slow_transfer", int64(rate))
                reader.logger.Printf("âš ï¸  Slow transfer detected from %s: %.2f bytes/sec", reader.clientIP, rate)
            }
        }
    }
    
    // ã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™é©ç”¨ã€‘
    reader.rateLimiter.ApplyRateLimit(reader.clientIP, int64(n))
    
    // ã€ã‚µã‚¤ã‚ºè¶…éã®æœ€çµ‚ãƒã‚§ãƒƒã‚¯ã€‘
    if reader.bytesRead > reader.maxSize {
        reader.metrics.RecordRejection("stream_size_exceeded")
        reader.logger.Printf("âŒ Final size check failed for request %s: %d > %d", 
            reader.requestID, reader.bytesRead, reader.maxSize)
        return n, &BodySizeExceededError{
            RequestID: reader.requestID,
            BytesRead: reader.bytesRead,
            MaxSize:   reader.maxSize,
        }
    }
    
    return n, err
}

// ã€ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ©ãƒ¼å‹ã€‘è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±
type BodySizeExceededError struct {
    RequestID string
    BytesRead int64
    MaxSize   int64
}

func (e *BodySizeExceededError) Error() string {
    return fmt.Sprintf("body size exceeded: %d bytes read, limit: %d bytes (request: %s)", 
        e.BytesRead, e.MaxSize, e.RequestID)
}

// ã€å®Ÿç”¨ä¾‹ã€‘é«˜è² è·ç’°å¢ƒã§ã®å®Ÿéš›ã®ä½¿ç”¨
func ProductionBodySizeLimitingUsage() {
    // ã€åˆæœŸåŒ–ã€‘æœ¬ç•ªç’°å¢ƒè¨­å®š
    config := &LimiterConfig{
        GlobalMaxSize:          100 << 20,  // 100MB
        BaseLimit:              50 << 20,   // 50MB (å‹•çš„èª¿æ•´ãƒ™ãƒ¼ã‚¹)
        MaxConcurrentUploads:   50,         // åŒæ™‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ•°
        MaxUploadRate:          10 << 20,   // 10MB/s per IP
        MaxConnections:         1000,       // æœ€å¤§åŒæ™‚æ¥ç¶šæ•°
    }
    
    limiter := NewEnterpriseBodySizeLimiter(config)
    
    // ã€ãƒ«ãƒ¼ãƒˆè¨­å®šã€‘
    mux := http.NewServeMux()
    
    // ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    mux.HandleFunc("/upload", func(w http.ResponseWriter, r *http.Request) {
        if r.Method != http.MethodPost {
            http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
            return
        }
        
        // ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£å‡¦ç†ï¼ˆåˆ¶é™ãŒé©ç”¨æ¸ˆã¿ï¼‰
        body, err := ioutil.ReadAll(r.Body)
        if err != nil {
            http.Error(w, "Failed to read body", http.StatusBadRequest)
            return
        }
        
        log.Printf("âœ… Successfully processed %d bytes upload", len(body))
        
        w.Header().Set("Content-Type", "application/json")
        w.WriteHeader(http.StatusOK)
        json.NewEncoder(w).Encode(map[string]interface{}{
            "status":       "success",
            "bytes_received": len(body),
            "timestamp":    time.Now().Unix(),
        })
    })
    
    // ç®¡ç†ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼‰
    mux.HandleFunc("/admin/metrics", func(w http.ResponseWriter, r *http.Request) {
        metrics := limiter.metrics.GetSummary()
        w.Header().Set("Content-Type", "application/json")
        json.NewEncoder(w).Encode(metrics)
    })
    
    // ã€ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢é©ç”¨ã€‘
    handler := limiter.Middleware(mux)
    
    // ã€ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ã€‘
    server := &http.Server{
        Addr:           ":8080",
        Handler:        handler,
        ReadTimeout:    30 * time.Second,
        WriteTimeout:   30 * time.Second,
        IdleTimeout:    60 * time.Second,
        MaxHeaderBytes: 1 << 20, // 1MB
    }
    
    log.Printf("ğŸš€ Production server starting on :8080")
    log.Printf("   Body size limits: Global=%.2fMB, Dynamic adjustment enabled", 
        float64(config.GlobalMaxSize)/1024/1024)
    log.Printf("   Security features: IP blacklist, anomaly detection, rate limiting")
    
    log.Fatal(server.ListenAndServe())
}
```

### åŸºæœ¬çš„ãªã‚µã‚¤ã‚ºåˆ¶é™å®Ÿè£…

```go
type BodySizeLimitMiddleware struct {
    maxSize     int64
    errorWriter ErrorWriter
    metrics     *Metrics
}

func NewBodySizeLimitMiddleware(maxSize int64) *BodySizeLimitMiddleware {
    return &BodySizeLimitMiddleware{
        maxSize:     maxSize,
        errorWriter: &DefaultErrorWriter{},
        metrics:     NewMetrics(),
    }
}

func (m *BodySizeLimitMiddleware) Handler(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // Content-Lengthãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
        if r.ContentLength > m.maxSize {
            m.metrics.RecordRejection("content_length_exceeded")
            m.errorWriter.WriteError(w, ErrRequestTooLarge)
            return
        }
        
        // ãƒªãƒ¼ãƒ€ãƒ¼ã‚’ãƒ©ãƒƒãƒ—ã—ã¦ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆ¶é™
        r.Body = &limitedReader{
            reader:  r.Body,
            maxSize: m.maxSize,
            metrics: m.metrics,
        }
        
        next.ServeHTTP(w, r)
    })
}

type limitedReader struct {
    reader   io.ReadCloser
    maxSize  int64
    readSize int64
    metrics  *Metrics
}

func (lr *limitedReader) Read(p []byte) (n int, err error) {
    if lr.readSize >= lr.maxSize {
        lr.metrics.RecordRejection("stream_size_exceeded")
        return 0, ErrRequestTooLarge
    }
    
    // èª­ã¿è¾¼ã¿å¯èƒ½ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
    remaining := lr.maxSize - lr.readSize
    if int64(len(p)) > remaining {
        p = p[:remaining]
    }
    
    n, err = lr.reader.Read(p)
    lr.readSize += int64(n)
    
    if lr.readSize > lr.maxSize {
        lr.metrics.RecordRejection("stream_size_exceeded")
        return n, ErrRequestTooLarge
    }
    
    return n, err
}

func (lr *limitedReader) Close() error {
    return lr.reader.Close()
}
```

### Content-Typeåˆ¥ã‚µã‚¤ã‚ºåˆ¶é™

```go
type ContentTypeLimits struct {
    limits map[string]int64
    defaultLimit int64
}

func NewContentTypeLimits() *ContentTypeLimits {
    return &ContentTypeLimits{
        limits: map[string]int64{
            "application/json":       1 << 20,    // 1MB
            "application/xml":        2 << 20,    // 2MB
            "text/plain":            512 << 10,   // 512KB
            "multipart/form-data":   10 << 20,    // 10MB
            "image/jpeg":            5 << 20,     // 5MB
            "image/png":             5 << 20,     // 5MB
            "video/mp4":             100 << 20,   // 100MB
        },
        defaultLimit: 1 << 20, // 1MB
    }
}

func (ctl *ContentTypeLimits) GetLimit(contentType string) int64 {
    // Content-Type ã‹ã‚‰ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—ã‚’æŠ½å‡º
    mediaType, _, err := mime.ParseMediaType(contentType)
    if err != nil {
        return ctl.defaultLimit
    }
    
    if limit, exists := ctl.limits[mediaType]; exists {
        return limit
    }
    
    return ctl.defaultLimit
}

type AdvancedBodySizeLimitMiddleware struct {
    contentTypeLimits *ContentTypeLimits
    globalMaxSize     int64
    progressTracker   *ProgressTracker
    metrics          *Metrics
}

func (m *AdvancedBodySizeLimitMiddleware) Handler(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        contentType := r.Header.Get("Content-Type")
        typeLimit := m.contentTypeLimits.GetLimit(contentType)
        
        // ã‚°ãƒ­ãƒ¼ãƒãƒ«åˆ¶é™ã¨å‹åˆ¥åˆ¶é™ã®å°ã•ã„æ–¹ã‚’æ¡ç”¨
        effectiveLimit := min(m.globalMaxSize, typeLimit)
        
        if r.ContentLength > effectiveLimit {
            m.metrics.RecordRejection("content_length_exceeded", contentType)
            http.Error(w, "Request body too large", http.StatusRequestEntityTooLarge)
            return
        }
        
        // ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒˆãƒ©ãƒƒã‚«ãƒ¼ä»˜ããƒªãƒ¼ãƒ€ãƒ¼
        r.Body = &progressTrackingReader{
            reader:    r.Body,
            maxSize:   effectiveLimit,
            tracker:   m.progressTracker,
            requestID: getRequestID(r),
            metrics:   m.metrics,
        }
        
        next.ServeHTTP(w, r)
    })
}
```

### ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°

```go
type ProgressTracker struct {
    activeReads map[string]*ReadProgress
    mu          sync.RWMutex
    maxConcurrent int
}

type ReadProgress struct {
    RequestID   string
    TotalSize   int64
    ReadSize    int64
    StartTime   time.Time
    LastUpdate  time.Time
    ContentType string
    Rate        *RateCalculator
}

func NewProgressTracker(maxConcurrent int) *ProgressTracker {
    return &ProgressTracker{
        activeReads:   make(map[string]*ReadProgress),
        maxConcurrent: maxConcurrent,
    }
}

func (pt *ProgressTracker) StartTracking(requestID, contentType string, totalSize int64) error {
    pt.mu.Lock()
    defer pt.mu.Unlock()
    
    if len(pt.activeReads) >= pt.maxConcurrent {
        return errors.New("too many concurrent reads")
    }
    
    pt.activeReads[requestID] = &ReadProgress{
        RequestID:   requestID,
        TotalSize:   totalSize,
        ReadSize:    0,
        StartTime:   time.Now(),
        LastUpdate:  time.Now(),
        ContentType: contentType,
        Rate:        NewRateCalculator(),
    }
    
    return nil
}

func (pt *ProgressTracker) UpdateProgress(requestID string, bytesRead int64) {
    pt.mu.Lock()
    defer pt.mu.Unlock()
    
    if progress, exists := pt.activeReads[requestID]; exists {
        progress.ReadSize += bytesRead
        progress.LastUpdate = time.Now()
        progress.Rate.Update(bytesRead)
        
        // é€²æ—ãƒ­ã‚°
        if progress.TotalSize > 0 {
            percentage := float64(progress.ReadSize) / float64(progress.TotalSize) * 100
            log.Printf("Request %s: %.1f%% complete (%d/%d bytes)", 
                requestID, percentage, progress.ReadSize, progress.TotalSize)
        }
    }
}

type progressTrackingReader struct {
    reader    io.ReadCloser
    maxSize   int64
    readSize  int64
    tracker   *ProgressTracker
    requestID string
    metrics   *Metrics
}

func (ptr *progressTrackingReader) Read(p []byte) (n int, err error) {
    if ptr.readSize >= ptr.maxSize {
        ptr.metrics.RecordRejection("stream_size_exceeded")
        return 0, ErrRequestTooLarge
    }
    
    n, err = ptr.reader.Read(p)
    ptr.readSize += int64(n)
    
    // ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°
    ptr.tracker.UpdateProgress(ptr.requestID, int64(n))
    
    if ptr.readSize > ptr.maxSize {
        ptr.metrics.RecordRejection("stream_size_exceeded") 
        return n, ErrRequestTooLarge
    }
    
    return n, err
}
```

### å‹•çš„ã‚µã‚¤ã‚ºåˆ¶é™

```go
type DynamicSizeLimiter struct {
    baseLimit     int64
    scaleFactor   float64
    metrics       *SystemMetrics
    loadThreshold float64
    mu            sync.RWMutex
}

func NewDynamicSizeLimiter(baseLimit int64) *DynamicSizeLimiter {
    return &DynamicSizeLimiter{
        baseLimit:     baseLimit,
        scaleFactor:   1.0,
        metrics:       NewSystemMetrics(),
        loadThreshold: 0.8,
    }
}

func (dsl *DynamicSizeLimiter) GetCurrentLimit() int64 {
    dsl.mu.RLock()
    defer dsl.mu.RUnlock()
    
    return int64(float64(dsl.baseLimit) * dsl.scaleFactor)
}

func (dsl *DynamicSizeLimiter) AdjustLimit() {
    memUsage := dsl.metrics.GetMemoryUsage()
    cpuUsage := dsl.metrics.GetCPUUsage()
    avgLoad := (memUsage + cpuUsage) / 2
    
    dsl.mu.Lock()
    defer dsl.mu.Unlock()
    
    if avgLoad > dsl.loadThreshold {
        // è² è·ãŒé«˜ã„å ´åˆã¯åˆ¶é™ã‚’å³ã—ã
        dsl.scaleFactor = max(0.1, dsl.scaleFactor*0.9)
    } else if avgLoad < dsl.loadThreshold*0.5 {
        // è² è·ãŒä½ã„å ´åˆã¯åˆ¶é™ã‚’ç·©å’Œ
        dsl.scaleFactor = min(1.0, dsl.scaleFactor*1.1)
    }
}

// å®šæœŸçš„ãªèª¿æ•´
func (dsl *DynamicSizeLimiter) StartAutoAdjustment(ctx context.Context, interval time.Duration) {
    ticker := time.NewTicker(interval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            dsl.AdjustLimit()
        case <-ctx.Done():
            return
        }
    }
}
```

### ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã¨ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼

```go
type StreamingBodyHandler struct {
    chunkSize     int
    timeout       time.Duration
    backpressure  *BackpressureController
}

func NewStreamingBodyHandler(chunkSize int, timeout time.Duration) *StreamingBodyHandler {
    return &StreamingBodyHandler{
        chunkSize:    chunkSize,
        timeout:      timeout,
        backpressure: NewBackpressureController(),
    }
}

func (sbh *StreamingBodyHandler) ProcessStream(r io.Reader, processor func([]byte) error) error {
    buffer := make([]byte, sbh.chunkSize)
    
    for {
        // ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ãƒã‚§ãƒƒã‚¯
        if err := sbh.backpressure.WaitIfNeeded(context.Background()); err != nil {
            return err
        }
        
        n, err := r.Read(buffer[:])
        if n > 0 {
            if err := processor(buffer[:n]); err != nil {
                return err
            }
        }
        
        if err == io.EOF {
            break
        }
        if err != nil {
            return err
        }
    }
    
    return nil
}

type BackpressureController struct {
    currentLoad int64
    maxLoad     int64
    throttle    chan struct{}
}

func NewBackpressureController() *BackpressureController {
    return &BackpressureController{
        maxLoad:  1000,
        throttle: make(chan struct{}, 100),
    }
}

func (bc *BackpressureController) WaitIfNeeded(ctx context.Context) error {
    if atomic.LoadInt64(&bc.currentLoad) > bc.maxLoad {
        select {
        case <-bc.throttle:
            return nil
        case <-ctx.Done():
            return ctx.Err()
        }
    }
    return nil
}
```

## ğŸ“ èª²é¡Œ (The Problem)

ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æŒã¤åŒ…æ‹¬çš„ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚µã‚¤ã‚ºåˆ¶é™ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š

### 1. åŸºæœ¬ã‚µã‚¤ã‚ºåˆ¶é™
- ã‚°ãƒ­ãƒ¼ãƒãƒ«æœ€å¤§ã‚µã‚¤ã‚ºåˆ¶é™
- Content-Length ãƒ˜ãƒƒãƒ€ãƒ¼ãƒã‚§ãƒƒã‚¯
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èª­ã¿è¾¼ã¿åˆ¶é™
- é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹

### 2. Content-Typeåˆ¥åˆ¶é™
- ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—åˆ¥ã‚µã‚¤ã‚ºåˆ¶é™
- MIME ã‚¿ã‚¤ãƒ—è§£æ
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ¶é™ã®é©ç”¨
- å‹•çš„åˆ¶é™è¨­å®š

### 3. ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
- èª­ã¿è¾¼ã¿é€²æ—ã®ç›£è¦–
- ä¸¦è¡Œèª­ã¿è¾¼ã¿æ•°åˆ¶é™
- è»¢é€é€Ÿåº¦è¨ˆç®—
- ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆåˆ¶å¾¡

### 4. å‹•çš„åˆ¶é™èª¿æ•´
- ã‚·ã‚¹ãƒ†ãƒ è² è·ã«åŸºã¥ãèª¿æ•´
- ãƒ¡ãƒ¢ãƒªãƒ»CPUä½¿ç”¨ç‡ç›£è¦–
- è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
- åˆ¶é™å±¥æ­´ã®è¨˜éŒ²

### 5. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½
- ã‚¹ãƒ­ãƒ¼ãƒã‚¹ãƒˆæ”»æ’ƒå¯¾ç­–
- ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼åˆ¶å¾¡
- ãƒªã‚½ãƒ¼ã‚¹æ¯æ¸‡é˜²æ­¢
- æ”»æ’ƒæ¤œçŸ¥ã¨ãƒ­ã‚°è¨˜éŒ²

## âœ… æœŸå¾…ã•ã‚Œã‚‹æŒ™å‹• (Expected Behavior)

å®Ÿè£…ãŒæ­£ã—ãå®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ†ã‚¹ãƒˆçµæœãŒå¾—ã‚‰ã‚Œã¾ã™ï¼š

```bash
$ go test -v
=== RUN   TestBodySizeLimit_BasicLimiting
    main_test.go:45: Basic size limiting working correctly
--- PASS: TestBodySizeLimit_BasicLimiting (0.01s)

=== RUN   TestBodySizeLimit_ContentTypeSpecific
    main_test.go:65: Content-type specific limits applied
--- PASS: TestBodySizeLimit_ContentTypeSpecific (0.02s)

=== RUN   TestBodySizeLimit_ProgressTracking
    main_test.go:85: Progress tracking functioning properly
--- PASS: TestBodySizeLimit_ProgressTracking (0.03s)

=== RUN   TestBodySizeLimit_DynamicAdjustment
    main_test.go:105: Dynamic limit adjustment working
--- PASS: TestBodySizeLimit_DynamicAdjustment (0.04s)

PASS
ok      day18-request-body-size-limit   0.156s
```

## ğŸ’¡ ãƒ’ãƒ³ãƒˆ (Hints)

å®Ÿè£…ã«è©°ã¾ã£ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®ãƒ’ãƒ³ãƒˆã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š

### åŸºæœ¬çš„ãªã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯

```go
func checkContentLength(r *http.Request, maxSize int64) error {
    if r.ContentLength < 0 {
        return nil // Content-Length ä¸æ˜
    }
    
    if r.ContentLength > maxSize {
        return ErrRequestTooLarge
    }
    
    return nil
}
```

### ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒªãƒ¼ãƒ€ãƒ¼

```go
type LimitedReader struct {
    R       io.Reader
    N       int64 // æœ€å¤§èª­ã¿è¾¼ã¿å¯èƒ½ãƒã‚¤ãƒˆæ•°
    read    int64 // æ—¢ã«èª­ã¿è¾¼ã‚“ã ãƒã‚¤ãƒˆæ•°
}

func (l *LimitedReader) Read(p []byte) (n int, err error) {
    if l.read >= l.N {
        return 0, io.EOF
    }
    
    if int64(len(p)) > l.N-l.read {
        p = p[0:l.N-l.read]
    }
    
    n, err = l.R.Read(p)
    l.read += int64(n)
    return
}
```

## ğŸš€ ç™ºå±•èª²é¡Œ (Advanced Challenges)

åŸºæœ¬å®Ÿè£…ãŒå®Œäº†ã—ãŸã‚‰ã€ä»¥ä¸‹ã®ç™ºå±•çš„ãªæ©Ÿèƒ½ã«ã‚‚ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ã¦ã¿ã¦ãã ã•ã„ï¼š

1. **åˆ†æ•£åˆ¶é™**: Redis ã‚’ä½¿ã£ãŸè¤‡æ•°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹é–“ã§ã®åˆ¶é™å…±æœ‰
2. **æ©Ÿæ¢°å­¦ç¿’äºˆæ¸¬**: éå»ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãå‹•çš„åˆ¶é™
3. **WebSocket ã‚µãƒãƒ¼ãƒˆ**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šä¿¡ã§ã®åˆ¶é™é©ç”¨
4. **åœ§ç¸®å¯¾å¿œ**: gzip åœ§ç¸®ã•ã‚ŒãŸãƒœãƒ‡ã‚£ã®åŠ¹ç‡çš„ãªå‡¦ç†
5. **ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**: Grafana ã‚’ä½¿ã£ãŸåˆ¶é™çŠ¶æ³ã®å¯è¦–åŒ–

ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚µã‚¤ã‚ºåˆ¶é™ã®å®Ÿè£…ã‚’é€šã˜ã¦ã€Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹é‡è¦ãªæŠ€è¡“ã‚’ç¿’å¾—ã—ã¾ã—ã‚‡ã†ï¼