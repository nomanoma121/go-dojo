# Day 18: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®ã‚µã‚¤ã‚ºåˆ¶é™

## ğŸ¯ æœ¬æ—¥ã®ç›®æ¨™ (Today's Goal)

HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®ã‚µã‚¤ã‚ºã‚’åˆ¶é™ã™ã‚‹ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã‚’å®Ÿè£…ã—ã€ãƒ¡ãƒ¢ãƒªæ¯æ¸‡æ”»æ’ƒã‚„DoSæ”»æ’ƒã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã‚’ä¿è­·ã™ã‚‹ã€‚å‹•çš„ã‚µã‚¤ã‚ºåˆ¶é™ã€Content-Typeåˆ¥åˆ¶é™ã€é€²æ—ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã€ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ãªå‡¦ç†ã‚’å«ã‚€åŒ…æ‹¬çš„ãªãƒœãƒ‡ã‚£ã‚µã‚¤ã‚ºåˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

## ğŸ“– è§£èª¬ (Explanation)

### ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚µã‚¤ã‚ºåˆ¶é™ã®é‡è¦æ€§

Web ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã€æ‚ªæ„ã®ã‚ã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒå·¨å¤§ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚’é€ä¿¡ã™ã‚‹ã“ã¨ã§ã€ã‚µãƒ¼ãƒãƒ¼ã®ãƒ¡ãƒ¢ãƒªã‚’æ¯æ¸‡ã•ã›ãŸã‚Šã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¸¯åŸŸã‚’å æœ‰ã™ã‚‹æ”»æ’ƒãŒå¯èƒ½ã§ã™ã€‚é©åˆ‡ãªã‚µã‚¤ã‚ºåˆ¶é™ã«ã‚ˆã‚Šã€ã“ã‚Œã‚‰ã®æ”»æ’ƒã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã‚’ä¿è­·ã§ãã¾ã™ã€‚

### åŸºæœ¬çš„ãªã‚µã‚¤ã‚ºåˆ¶é™å®Ÿè£…

```go
type BodySizeLimitMiddleware struct {
    maxSize     int64
    errorWriter ErrorWriter
    metrics     *Metrics
}

func NewBodySizeLimitMiddleware(maxSize int64) *BodySizeLimitMiddleware {
    return &BodySizeLimitMiddleware{
        maxSize:     maxSize,
        errorWriter: &DefaultErrorWriter{},
        metrics:     NewMetrics(),
    }
}

func (m *BodySizeLimitMiddleware) Handler(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // Content-Lengthãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
        if r.ContentLength > m.maxSize {
            m.metrics.RecordRejection("content_length_exceeded")
            m.errorWriter.WriteError(w, ErrRequestTooLarge)
            return
        }
        
        // ãƒªãƒ¼ãƒ€ãƒ¼ã‚’ãƒ©ãƒƒãƒ—ã—ã¦ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆ¶é™
        r.Body = &limitedReader{
            reader:  r.Body,
            maxSize: m.maxSize,
            metrics: m.metrics,
        }
        
        next.ServeHTTP(w, r)
    })
}

type limitedReader struct {
    reader   io.ReadCloser
    maxSize  int64
    readSize int64
    metrics  *Metrics
}

func (lr *limitedReader) Read(p []byte) (n int, err error) {
    if lr.readSize >= lr.maxSize {
        lr.metrics.RecordRejection("stream_size_exceeded")
        return 0, ErrRequestTooLarge
    }
    
    // èª­ã¿è¾¼ã¿å¯èƒ½ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
    remaining := lr.maxSize - lr.readSize
    if int64(len(p)) > remaining {
        p = p[:remaining]
    }
    
    n, err = lr.reader.Read(p)
    lr.readSize += int64(n)
    
    if lr.readSize > lr.maxSize {
        lr.metrics.RecordRejection("stream_size_exceeded")
        return n, ErrRequestTooLarge
    }
    
    return n, err
}

func (lr *limitedReader) Close() error {
    return lr.reader.Close()
}
```

### Content-Typeåˆ¥ã‚µã‚¤ã‚ºåˆ¶é™

```go
type ContentTypeLimits struct {
    limits map[string]int64
    defaultLimit int64
}

func NewContentTypeLimits() *ContentTypeLimits {
    return &ContentTypeLimits{
        limits: map[string]int64{
            "application/json":       1 << 20,    // 1MB
            "application/xml":        2 << 20,    // 2MB
            "text/plain":            512 << 10,   // 512KB
            "multipart/form-data":   10 << 20,    // 10MB
            "image/jpeg":            5 << 20,     // 5MB
            "image/png":             5 << 20,     // 5MB
            "video/mp4":             100 << 20,   // 100MB
        },
        defaultLimit: 1 << 20, // 1MB
    }
}

func (ctl *ContentTypeLimits) GetLimit(contentType string) int64 {
    // Content-Type ã‹ã‚‰ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—ã‚’æŠ½å‡º
    mediaType, _, err := mime.ParseMediaType(contentType)
    if err != nil {
        return ctl.defaultLimit
    }
    
    if limit, exists := ctl.limits[mediaType]; exists {
        return limit
    }
    
    return ctl.defaultLimit
}

type AdvancedBodySizeLimitMiddleware struct {
    contentTypeLimits *ContentTypeLimits
    globalMaxSize     int64
    progressTracker   *ProgressTracker
    metrics          *Metrics
}

func (m *AdvancedBodySizeLimitMiddleware) Handler(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        contentType := r.Header.Get("Content-Type")
        typeLimit := m.contentTypeLimits.GetLimit(contentType)
        
        // ã‚°ãƒ­ãƒ¼ãƒãƒ«åˆ¶é™ã¨å‹åˆ¥åˆ¶é™ã®å°ã•ã„æ–¹ã‚’æ¡ç”¨
        effectiveLimit := min(m.globalMaxSize, typeLimit)
        
        if r.ContentLength > effectiveLimit {
            m.metrics.RecordRejection("content_length_exceeded", contentType)
            http.Error(w, "Request body too large", http.StatusRequestEntityTooLarge)
            return
        }
        
        // ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒˆãƒ©ãƒƒã‚«ãƒ¼ä»˜ããƒªãƒ¼ãƒ€ãƒ¼
        r.Body = &progressTrackingReader{
            reader:    r.Body,
            maxSize:   effectiveLimit,
            tracker:   m.progressTracker,
            requestID: getRequestID(r),
            metrics:   m.metrics,
        }
        
        next.ServeHTTP(w, r)
    })
}
```

### ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°

```go
type ProgressTracker struct {
    activeReads map[string]*ReadProgress
    mu          sync.RWMutex
    maxConcurrent int
}

type ReadProgress struct {
    RequestID   string
    TotalSize   int64
    ReadSize    int64
    StartTime   time.Time
    LastUpdate  time.Time
    ContentType string
    Rate        *RateCalculator
}

func NewProgressTracker(maxConcurrent int) *ProgressTracker {
    return &ProgressTracker{
        activeReads:   make(map[string]*ReadProgress),
        maxConcurrent: maxConcurrent,
    }
}

func (pt *ProgressTracker) StartTracking(requestID, contentType string, totalSize int64) error {
    pt.mu.Lock()
    defer pt.mu.Unlock()
    
    if len(pt.activeReads) >= pt.maxConcurrent {
        return errors.New("too many concurrent reads")
    }
    
    pt.activeReads[requestID] = &ReadProgress{
        RequestID:   requestID,
        TotalSize:   totalSize,
        ReadSize:    0,
        StartTime:   time.Now(),
        LastUpdate:  time.Now(),
        ContentType: contentType,
        Rate:        NewRateCalculator(),
    }
    
    return nil
}

func (pt *ProgressTracker) UpdateProgress(requestID string, bytesRead int64) {
    pt.mu.Lock()
    defer pt.mu.Unlock()
    
    if progress, exists := pt.activeReads[requestID]; exists {
        progress.ReadSize += bytesRead
        progress.LastUpdate = time.Now()
        progress.Rate.Update(bytesRead)
        
        // é€²æ—ãƒ­ã‚°
        if progress.TotalSize > 0 {
            percentage := float64(progress.ReadSize) / float64(progress.TotalSize) * 100
            log.Printf("Request %s: %.1f%% complete (%d/%d bytes)", 
                requestID, percentage, progress.ReadSize, progress.TotalSize)
        }
    }
}

type progressTrackingReader struct {
    reader    io.ReadCloser
    maxSize   int64
    readSize  int64
    tracker   *ProgressTracker
    requestID string
    metrics   *Metrics
}

func (ptr *progressTrackingReader) Read(p []byte) (n int, err error) {
    if ptr.readSize >= ptr.maxSize {
        ptr.metrics.RecordRejection("stream_size_exceeded")
        return 0, ErrRequestTooLarge
    }
    
    n, err = ptr.reader.Read(p)
    ptr.readSize += int64(n)
    
    // ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°
    ptr.tracker.UpdateProgress(ptr.requestID, int64(n))
    
    if ptr.readSize > ptr.maxSize {
        ptr.metrics.RecordRejection("stream_size_exceeded") 
        return n, ErrRequestTooLarge
    }
    
    return n, err
}
```

### å‹•çš„ã‚µã‚¤ã‚ºåˆ¶é™

```go
type DynamicSizeLimiter struct {
    baseLimit     int64
    scaleFactor   float64
    metrics       *SystemMetrics
    loadThreshold float64
    mu            sync.RWMutex
}

func NewDynamicSizeLimiter(baseLimit int64) *DynamicSizeLimiter {
    return &DynamicSizeLimiter{
        baseLimit:     baseLimit,
        scaleFactor:   1.0,
        metrics:       NewSystemMetrics(),
        loadThreshold: 0.8,
    }
}

func (dsl *DynamicSizeLimiter) GetCurrentLimit() int64 {
    dsl.mu.RLock()
    defer dsl.mu.RUnlock()
    
    return int64(float64(dsl.baseLimit) * dsl.scaleFactor)
}

func (dsl *DynamicSizeLimiter) AdjustLimit() {
    memUsage := dsl.metrics.GetMemoryUsage()
    cpuUsage := dsl.metrics.GetCPUUsage()
    avgLoad := (memUsage + cpuUsage) / 2
    
    dsl.mu.Lock()
    defer dsl.mu.Unlock()
    
    if avgLoad > dsl.loadThreshold {
        // è² è·ãŒé«˜ã„å ´åˆã¯åˆ¶é™ã‚’å³ã—ã
        dsl.scaleFactor = max(0.1, dsl.scaleFactor*0.9)
    } else if avgLoad < dsl.loadThreshold*0.5 {
        // è² è·ãŒä½ã„å ´åˆã¯åˆ¶é™ã‚’ç·©å’Œ
        dsl.scaleFactor = min(1.0, dsl.scaleFactor*1.1)
    }
}

// å®šæœŸçš„ãªèª¿æ•´
func (dsl *DynamicSizeLimiter) StartAutoAdjustment(ctx context.Context, interval time.Duration) {
    ticker := time.NewTicker(interval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            dsl.AdjustLimit()
        case <-ctx.Done():
            return
        }
    }
}
```

### ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã¨ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼

```go
type StreamingBodyHandler struct {
    chunkSize     int
    timeout       time.Duration
    backpressure  *BackpressureController
}

func NewStreamingBodyHandler(chunkSize int, timeout time.Duration) *StreamingBodyHandler {
    return &StreamingBodyHandler{
        chunkSize:    chunkSize,
        timeout:      timeout,
        backpressure: NewBackpressureController(),
    }
}

func (sbh *StreamingBodyHandler) ProcessStream(r io.Reader, processor func([]byte) error) error {
    buffer := make([]byte, sbh.chunkSize)
    
    for {
        // ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ãƒã‚§ãƒƒã‚¯
        if err := sbh.backpressure.WaitIfNeeded(context.Background()); err != nil {
            return err
        }
        
        n, err := r.Read(buffer[:])
        if n > 0 {
            if err := processor(buffer[:n]); err != nil {
                return err
            }
        }
        
        if err == io.EOF {
            break
        }
        if err != nil {
            return err
        }
    }
    
    return nil
}

type BackpressureController struct {
    currentLoad int64
    maxLoad     int64
    throttle    chan struct{}
}

func NewBackpressureController() *BackpressureController {
    return &BackpressureController{
        maxLoad:  1000,
        throttle: make(chan struct{}, 100),
    }
}

func (bc *BackpressureController) WaitIfNeeded(ctx context.Context) error {
    if atomic.LoadInt64(&bc.currentLoad) > bc.maxLoad {
        select {
        case <-bc.throttle:
            return nil
        case <-ctx.Done():
            return ctx.Err()
        }
    }
    return nil
}
```

## ğŸ“ èª²é¡Œ (The Problem)

ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æŒã¤åŒ…æ‹¬çš„ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚µã‚¤ã‚ºåˆ¶é™ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š

### 1. åŸºæœ¬ã‚µã‚¤ã‚ºåˆ¶é™
- ã‚°ãƒ­ãƒ¼ãƒãƒ«æœ€å¤§ã‚µã‚¤ã‚ºåˆ¶é™
- Content-Length ãƒ˜ãƒƒãƒ€ãƒ¼ãƒã‚§ãƒƒã‚¯
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èª­ã¿è¾¼ã¿åˆ¶é™
- é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹

### 2. Content-Typeåˆ¥åˆ¶é™
- ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—åˆ¥ã‚µã‚¤ã‚ºåˆ¶é™
- MIME ã‚¿ã‚¤ãƒ—è§£æ
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ¶é™ã®é©ç”¨
- å‹•çš„åˆ¶é™è¨­å®š

### 3. ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
- èª­ã¿è¾¼ã¿é€²æ—ã®ç›£è¦–
- ä¸¦è¡Œèª­ã¿è¾¼ã¿æ•°åˆ¶é™
- è»¢é€é€Ÿåº¦è¨ˆç®—
- ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆåˆ¶å¾¡

### 4. å‹•çš„åˆ¶é™èª¿æ•´
- ã‚·ã‚¹ãƒ†ãƒ è² è·ã«åŸºã¥ãèª¿æ•´
- ãƒ¡ãƒ¢ãƒªãƒ»CPUä½¿ç”¨ç‡ç›£è¦–
- è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
- åˆ¶é™å±¥æ­´ã®è¨˜éŒ²

### 5. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½
- ã‚¹ãƒ­ãƒ¼ãƒã‚¹ãƒˆæ”»æ’ƒå¯¾ç­–
- ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼åˆ¶å¾¡
- ãƒªã‚½ãƒ¼ã‚¹æ¯æ¸‡é˜²æ­¢
- æ”»æ’ƒæ¤œçŸ¥ã¨ãƒ­ã‚°è¨˜éŒ²

## âœ… æœŸå¾…ã•ã‚Œã‚‹æŒ™å‹• (Expected Behavior)

å®Ÿè£…ãŒæ­£ã—ãå®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ†ã‚¹ãƒˆçµæœãŒå¾—ã‚‰ã‚Œã¾ã™ï¼š

```bash
$ go test -v
=== RUN   TestBodySizeLimit_BasicLimiting
    main_test.go:45: Basic size limiting working correctly
--- PASS: TestBodySizeLimit_BasicLimiting (0.01s)

=== RUN   TestBodySizeLimit_ContentTypeSpecific
    main_test.go:65: Content-type specific limits applied
--- PASS: TestBodySizeLimit_ContentTypeSpecific (0.02s)

=== RUN   TestBodySizeLimit_ProgressTracking
    main_test.go:85: Progress tracking functioning properly
--- PASS: TestBodySizeLimit_ProgressTracking (0.03s)

=== RUN   TestBodySizeLimit_DynamicAdjustment
    main_test.go:105: Dynamic limit adjustment working
--- PASS: TestBodySizeLimit_DynamicAdjustment (0.04s)

PASS
ok      day18-request-body-size-limit   0.156s
```

## ğŸ’¡ ãƒ’ãƒ³ãƒˆ (Hints)

å®Ÿè£…ã«è©°ã¾ã£ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®ãƒ’ãƒ³ãƒˆã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š

### åŸºæœ¬çš„ãªã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯

```go
func checkContentLength(r *http.Request, maxSize int64) error {
    if r.ContentLength < 0 {
        return nil // Content-Length ä¸æ˜
    }
    
    if r.ContentLength > maxSize {
        return ErrRequestTooLarge
    }
    
    return nil
}
```

### ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒªãƒ¼ãƒ€ãƒ¼

```go
type LimitedReader struct {
    R       io.Reader
    N       int64 // æœ€å¤§èª­ã¿è¾¼ã¿å¯èƒ½ãƒã‚¤ãƒˆæ•°
    read    int64 // æ—¢ã«èª­ã¿è¾¼ã‚“ã ãƒã‚¤ãƒˆæ•°
}

func (l *LimitedReader) Read(p []byte) (n int, err error) {
    if l.read >= l.N {
        return 0, io.EOF
    }
    
    if int64(len(p)) > l.N-l.read {
        p = p[0:l.N-l.read]
    }
    
    n, err = l.R.Read(p)
    l.read += int64(n)
    return
}
```

## ğŸš€ ç™ºå±•èª²é¡Œ (Advanced Challenges)

åŸºæœ¬å®Ÿè£…ãŒå®Œäº†ã—ãŸã‚‰ã€ä»¥ä¸‹ã®ç™ºå±•çš„ãªæ©Ÿèƒ½ã«ã‚‚ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ã¦ã¿ã¦ãã ã•ã„ï¼š

1. **åˆ†æ•£åˆ¶é™**: Redis ã‚’ä½¿ã£ãŸè¤‡æ•°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹é–“ã§ã®åˆ¶é™å…±æœ‰
2. **æ©Ÿæ¢°å­¦ç¿’äºˆæ¸¬**: éå»ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãå‹•çš„åˆ¶é™
3. **WebSocket ã‚µãƒãƒ¼ãƒˆ**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šä¿¡ã§ã®åˆ¶é™é©ç”¨
4. **åœ§ç¸®å¯¾å¿œ**: gzip åœ§ç¸®ã•ã‚ŒãŸãƒœãƒ‡ã‚£ã®åŠ¹ç‡çš„ãªå‡¦ç†
5. **ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**: Grafana ã‚’ä½¿ã£ãŸåˆ¶é™çŠ¶æ³ã®å¯è¦–åŒ–

ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚µã‚¤ã‚ºåˆ¶é™ã®å®Ÿè£…ã‚’é€šã˜ã¦ã€Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹é‡è¦ãªæŠ€è¡“ã‚’ç¿’å¾—ã—ã¾ã—ã‚‡ã†ï¼