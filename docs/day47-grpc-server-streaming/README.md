# Day 47: gRPC Server-side Streaming

## ğŸ¯ æœ¬æ—¥ã®ç›®æ¨™ (Today's Goal)

gRPCã®ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’å®Œå…¨ã«ç†è§£ã—ã€å®Ÿè£…ã™ã‚‹ã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šçŸ¥ã€ãƒ­ã‚°ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã€å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²é€ä¿¡ã€ãƒ•ã‚¡ã‚¤ãƒ«è»¢é€ãªã©ã®å®Ÿç”¨çš„ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’é€šã˜ã¦ã€é«˜æ€§èƒ½ã§å …ç‰¢ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚

## ğŸ“– è§£èª¬ (Explanation)

### gRPCã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã®ç¨®é¡ã¨ç‰¹å¾´

gRPCã«ã¯4ã¤ã®é€šä¿¡ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Šã¾ã™ï¼š

1. **Unaryï¼ˆå˜é …ï¼‰**: 1ãƒªã‚¯ã‚¨ã‚¹ãƒˆ â†’ 1ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆé€šå¸¸ã®RPCï¼‰
2. **Server Streaming**: 1ãƒªã‚¯ã‚¨ã‚¹ãƒˆ â†’ Nãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆæœ¬æ—¥ã®èª²é¡Œï¼‰
3. **Client Streaming**: Nãƒªã‚¯ã‚¨ã‚¹ãƒˆ â†’ 1ãƒ¬ã‚¹ãƒãƒ³ã‚¹
4. **Bidirectional Streaming**: Nãƒªã‚¯ã‚¨ã‚¹ãƒˆ â†” Nãƒ¬ã‚¹ãƒãƒ³ã‚¹

### ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã¨ã¯

ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒä¸€ã¤ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã—ã€ã‚µãƒ¼ãƒãƒ¼ãŒè¤‡æ•°ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’**é †æ¬¡ãƒ»é€£ç¶šçš„ã«**è¿”ã™gRPCã®é€šä¿¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚

```
Client                    Server
   |                         |
   |-------- Request ------->|
   |                         |
   |<------- Response 1 -----|
   |<------- Response 2 -----|
   |<------- Response 3 -----|
   |<------- ... ------------|
   |<------- Response N -----|
   |<------- EOF ------------|
```

**å¾“æ¥ã®HTTP APIã¨ã®æ¯”è¼ƒï¼š**

```go
// HTTP REST APIï¼ˆå•é¡Œã®ã‚ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
func GetLargeDataHTTP(w http.ResponseWriter, r *http.Request) {
    // ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã«ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¿
    data := fetchAllData() // 10GB ã®ãƒ‡ãƒ¼ã‚¿
    
    // JSON ã«å¤‰æ›ï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒ2å€ã«ï¼‰
    jsonData, _ := json.Marshal(data)
    
    // ä¸€åº¦ã«é€ä¿¡ï¼ˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚‚ä¸€åº¦ã«å—ä¿¡å¾…ã¡ï¼‰
    w.Write(jsonData)
}

// gRPC Server Streamingï¼ˆåŠ¹ç‡çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
func (s *Server) StreamLargeData(req *pb.DataRequest, stream pb.DataService_StreamLargeDataServer) error {
    // ãƒ‡ãƒ¼ã‚¿ã‚’å°ã•ãªãƒãƒ£ãƒ³ã‚¯ã§é †æ¬¡é€ä¿¡
    for chunk := range fetchDataInChunks(req.GetQuery()) {
        response := &pb.DataChunk{
            Data: chunk,
            ChunkId: chunkID,
            TotalChunks: totalChunks,
        }
        
        if err := stream.Send(response); err != nil {
            return err
        }
        // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¯å¸¸ã«ä¸€å®š
    }
    return nil
}
```

### ä¸»ãªç”¨é€”ã¨å®Ÿéš›ã®æ´»ç”¨ä¾‹

#### 1. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ 

```go
// ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒãƒƒãƒ•ã‚¡å®šç¾©
syntax = "proto3";

package notification;

service NotificationService {
    rpc SubscribeToNotifications(SubscriptionRequest) returns (stream Notification);
}

message SubscriptionRequest {
    string user_id = 1;
    repeated string event_types = 2;
    int32 priority_level = 3;
}

message Notification {
    string id = 1;
    string type = 2;
    string title = 3;
    string message = 4;
    int64 timestamp = 5;
    int32 priority = 6;
    map<string, string> metadata = 7;
}

// ã‚µãƒ¼ãƒãƒ¼å®Ÿè£…
type NotificationServer struct {
    pb.UnimplementedNotificationServiceServer
    subscribers map[string]chan *pb.Notification
    mu          sync.RWMutex
}

func (s *NotificationServer) SubscribeToNotifications(
    req *pb.SubscriptionRequest,
    stream pb.NotificationService_SubscribeToNotificationsServer,
) error {
    userID := req.GetUserId()
    
    // ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ç™»éŒ²
    notifyChan := make(chan *pb.Notification, 100)
    s.mu.Lock()
    s.subscribers[userID] = notifyChan
    s.mu.Unlock()
    
    // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    defer func() {
        s.mu.Lock()
        delete(s.subscribers, userID)
        close(notifyChan)
        s.mu.Unlock()
    }()
    
    // é€šçŸ¥ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
    for {
        select {
        case notification := <-notifyChan:
            if err := stream.Send(notification); err != nil {
                return err
            }
        case <-stream.Context().Done():
            return stream.Context().Err()
        }
    }
}

// é€šçŸ¥ã®é…ä¿¡
func (s *NotificationServer) BroadcastNotification(notification *pb.Notification) {
    s.mu.RLock()
    defer s.mu.RUnlock()
    
    for userID, ch := range s.subscribers {
        select {
        case ch <- notification:
            // é€ä¿¡æˆåŠŸ
        default:
            // ãƒãƒ£ãƒãƒ«ãŒãƒ•ãƒ«â†’å¤ã„é€šçŸ¥ã‚’ç ´æ£„
            log.Printf("Notification queue full for user %s", userID)
        }
    }
}
```

#### 2. ãƒ­ã‚°ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 

```go
// ãƒ­ã‚°ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«å®šç¾©
service LogService {
    rpc StreamLogs(LogStreamRequest) returns (stream LogEntry);
}

message LogStreamRequest {
    string application = 1;
    string log_level = 2;
    int64 start_timestamp = 3;
    repeated string filters = 4;
    bool follow = 5; // tail -f ã®ã‚ˆã†ãªæ©Ÿèƒ½
}

message LogEntry {
    int64 timestamp = 1;
    string level = 2;
    string application = 3;
    string message = 4;
    string source_file = 5;
    int32 line_number = 6;
    map<string, string> fields = 7;
}

// ãƒ­ã‚°ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè£…
type LogStreamServer struct {
    pb.UnimplementedLogServiceServer
    logBuffer *CircularBuffer
    tailMode  map[string]chan *pb.LogEntry
    mu        sync.RWMutex
}

func (s *LogStreamServer) StreamLogs(
    req *pb.LogStreamRequest,
    stream pb.LogService_StreamLogsServer,
) error {
    // éå»ã®ãƒ­ã‚°ã‚’é€ä¿¡
    historicalLogs := s.getHistoricalLogs(req)
    for _, logEntry := range historicalLogs {
        if err := stream.Send(logEntry); err != nil {
            return err
        }
    }
    
    // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ•ã‚©ãƒ­ãƒ¼ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ãªå ´åˆ
    if req.GetFollow() {
        return s.followLogs(req, stream)
    }
    
    return nil
}

func (s *LogStreamServer) followLogs(
    req *pb.LogStreamRequest,
    stream pb.LogService_StreamLogsServer,
) error {
    logChan := make(chan *pb.LogEntry, 1000)
    streamID := generateStreamID()
    
    s.mu.Lock()
    s.tailMode[streamID] = logChan
    s.mu.Unlock()
    
    defer func() {
        s.mu.Lock()
        delete(s.tailMode, streamID)
        close(logChan)
        s.mu.Unlock()
    }()
    
    for {
        select {
        case logEntry := <-logChan:
            if s.matchesFilter(logEntry, req) {
                if err := stream.Send(logEntry); err != nil {
                    return err
                }
            }
        case <-stream.Context().Done():
            return stream.Context().Err()
        }
    }
}

// æ–°ã—ã„ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’é…ä¿¡
func (s *LogStreamServer) DistributeLogEntry(entry *pb.LogEntry) {
    s.mu.RLock()
    defer s.mu.RUnlock()
    
    for _, ch := range s.tailMode {
        select {
        case ch <- entry:
        default:
            // ãƒãƒƒãƒ•ã‚¡ãƒ•ãƒ«æ™‚ã¯ã‚¹ã‚­ãƒƒãƒ—
        }
    }
}
```

#### 3. ãƒ•ã‚¡ã‚¤ãƒ«è»¢é€ã‚·ã‚¹ãƒ†ãƒ 

```go
// ãƒ•ã‚¡ã‚¤ãƒ«è»¢é€ç”¨ãƒ—ãƒ­ãƒˆã‚³ãƒ«
service FileService {
    rpc DownloadFile(FileRequest) returns (stream FileChunk);
    rpc GetFileInfo(FileRequest) returns (FileInfo);
}

message FileRequest {
    string file_path = 1;
    int32 chunk_size = 2;
    int64 offset = 3;
    int64 limit = 4;
}

message FileChunk {
    string file_path = 1;
    int64 offset = 2;
    bytes data = 3;
    int64 total_size = 4;
    string checksum = 5;
    bool is_last_chunk = 6;
}

message FileInfo {
    string file_path = 1;
    int64 size = 2;
    int64 modified_time = 3;
    string mime_type = 4;
    string checksum = 5;
}

// ãƒ•ã‚¡ã‚¤ãƒ«è»¢é€å®Ÿè£…
type FileServer struct {
    pb.UnimplementedFileServiceServer
    maxChunkSize int
    rateLimiter  *rate.Limiter
}

func NewFileServer(maxChunkSize int, rateLimit rate.Limit) *FileServer {
    return &FileServer{
        maxChunkSize: maxChunkSize,
        rateLimiter:  rate.NewLimiter(rateLimit, int(rateLimit)),
    }
}

func (s *FileServer) DownloadFile(
    req *pb.FileRequest,
    stream pb.FileService_DownloadFileServer,
) error {
    filePath := req.GetFilePath()
    
    // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
    if err := s.validateFilePath(filePath); err != nil {
        return status.Errorf(codes.InvalidArgument, "Invalid file path: %v", err)
    }
    
    file, err := os.Open(filePath)
    if err != nil {
        return status.Errorf(codes.NotFound, "File not found: %v", err)
    }
    defer file.Close()
    
    fileInfo, err := file.Stat()
    if err != nil {
        return status.Errorf(codes.Internal, "Failed to get file info: %v", err)
    }
    
    // ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®æ±ºå®š
    chunkSize := req.GetChunkSize()
    if chunkSize <= 0 || chunkSize > int32(s.maxChunkSize) {
        chunkSize = int32(s.maxChunkSize)
    }
    
    // ã‚ªãƒ•ã‚»ãƒƒãƒˆã¨ãƒªãƒŸãƒƒãƒˆã®å‡¦ç†
    offset := req.GetOffset()
    limit := req.GetLimit()
    if limit <= 0 {
        limit = fileInfo.Size() - offset
    }
    
    if _, err := file.Seek(offset, 0); err != nil {
        return status.Errorf(codes.InvalidArgument, "Invalid offset: %v", err)
    }
    
    buffer := make([]byte, chunkSize)
    bytesRemaining := limit
    currentOffset := offset
    hasher := sha256.New()
    
    for bytesRemaining > 0 {
        // ãƒ¬ãƒ¼ãƒˆåˆ¶é™
        if err := s.rateLimiter.Wait(stream.Context()); err != nil {
            return err
        }
        
        // èª­ã¿å–ã‚Šã‚µã‚¤ã‚ºã®èª¿æ•´
        readSize := int64(chunkSize)
        if bytesRemaining < readSize {
            readSize = bytesRemaining
            buffer = buffer[:readSize]
        }
        
        n, err := file.Read(buffer[:readSize])
        if err != nil && err != io.EOF {
            return status.Errorf(codes.Internal, "Failed to read file: %v", err)
        }
        
        if n == 0 {
            break
        }
        
        data := buffer[:n]
        hasher.Write(data)
        
        chunk := &pb.FileChunk{
            FilePath:     filePath,
            Offset:       currentOffset,
            Data:         data,
            TotalSize:    fileInfo.Size(),
            IsLastChunk:  bytesRemaining-int64(n) <= 0,
        }
        
        if chunk.IsLastChunk {
            chunk.Checksum = fmt.Sprintf("%x", hasher.Sum(nil))
        }
        
        if err := stream.Send(chunk); err != nil {
            return err
        }
        
        currentOffset += int64(n)
        bytesRemaining -= int64(n)
        
        if err == io.EOF {
            break
        }
    }
    
    return nil
}

func (s *FileServer) validateFilePath(path string) error {
    // ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«æ”»æ’ƒã‚’é˜²ã
    if strings.Contains(path, "..") {
        return fmt.Errorf("path traversal detected")
    }
    
    // è¨±å¯ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã¿ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
    allowedDir := "/var/files/"
    absPath, err := filepath.Abs(path)
    if err != nil {
        return err
    }
    
    if !strings.HasPrefix(absPath, allowedDir) {
        return fmt.Errorf("access denied")
    }
    
    return nil
}
```

#### 4. ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

```go
// ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–ç”¨ãƒ—ãƒ­ãƒˆã‚³ãƒ«
service MetricsService {
    rpc StreamMetrics(MetricsRequest) returns (stream MetricPoint);
}

message MetricsRequest {
    repeated string metric_names = 1;
    int32 interval_seconds = 2;
    map<string, string> labels = 3;
}

message MetricPoint {
    string name = 1;
    double value = 2;
    int64 timestamp = 3;
    map<string, string> labels = 4;
    string metric_type = 5; // counter, gauge, histogram
}

// ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–å®Ÿè£…
type MetricsServer struct {
    pb.UnimplementedMetricsServiceServer
    collector *MetricsCollector
    streams   map[string]*MetricStream
    mu        sync.RWMutex
}

type MetricStream struct {
    ctx     context.Context
    cancel  context.CancelFunc
    stream  pb.MetricsService_StreamMetricsServer
    config  *pb.MetricsRequest
    lastSent map[string]int64
}

func (s *MetricsServer) StreamMetrics(
    req *pb.MetricsRequest,
    stream pb.MetricsService_StreamMetricsServer,
) error {
    ctx, cancel := context.WithCancel(stream.Context())
    defer cancel()
    
    streamID := generateStreamID()
    metricStream := &MetricStream{
        ctx:      ctx,
        cancel:   cancel,
        stream:   stream,
        config:   req,
        lastSent: make(map[string]int64),
    }
    
    s.mu.Lock()
    s.streams[streamID] = metricStream
    s.mu.Unlock()
    
    defer func() {
        s.mu.Lock()
        delete(s.streams, streamID)
        s.mu.Unlock()
    }()
    
    interval := time.Duration(req.GetIntervalSeconds()) * time.Second
    if interval < time.Second {
        interval = time.Second
    }
    
    ticker := time.NewTicker(interval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            if err := s.sendMetrics(metricStream); err != nil {
                return err
            }
        case <-ctx.Done():
            return ctx.Err()
        }
    }
}

func (s *MetricsServer) sendMetrics(ms *MetricStream) error {
    metrics := s.collector.GetMetrics(ms.config.GetMetricNames(), ms.config.GetLabels())
    
    for _, metric := range metrics {
        // é‡è¤‡é€ä¿¡ã‚’é¿ã‘ã‚‹ãŸã‚ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ãƒã‚§ãƒƒã‚¯
        if lastSent, exists := ms.lastSent[metric.Name]; exists && metric.Timestamp <= lastSent {
            continue
        }
        
        if err := ms.stream.Send(metric); err != nil {
            return err
        }
        
        ms.lastSent[metric.Name] = metric.Timestamp
    }
    
    return nil
}
```

### é«˜åº¦ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ©Ÿèƒ½

#### 1. ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ã¨ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼

```go
type FlowControlledStream struct {
    stream     pb.DataService_StreamDataServer
    windowSize int
    pending    int
    mu         sync.Mutex
    cond       *sync.Cond
}

func NewFlowControlledStream(stream pb.DataService_StreamDataServer, windowSize int) *FlowControlledStream {
    fcs := &FlowControlledStream{
        stream:     stream,
        windowSize: windowSize,
    }
    fcs.cond = sync.NewCond(&fcs.mu)
    return fcs
}

func (fcs *FlowControlledStream) Send(data *pb.DataResponse) error {
    fcs.mu.Lock()
    
    // ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã«é”ã—ãŸã‚‰å¾…æ©Ÿ
    for fcs.pending >= fcs.windowSize {
        select {
        case <-fcs.stream.Context().Done():
            fcs.mu.Unlock()
            return fcs.stream.Context().Err()
        default:
            fcs.cond.Wait()
        }
    }
    
    fcs.pending++
    fcs.mu.Unlock()
    
    // éåŒæœŸã§é€ä¿¡
    go func() {
        defer func() {
            fcs.mu.Lock()
            fcs.pending--
            fcs.cond.Signal()
            fcs.mu.Unlock()
        }()
        
        fcs.stream.Send(data)
    }()
    
    return nil
}
```

#### 2. ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨å†æ¥ç¶š

```go
// ã‚¨ãƒ©ãƒ¼å‡¦ç†ã‚’å«ã‚€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
func (s *Server) RobustStreamData(
    req *pb.StreamRequest,
    stream pb.DataService_RobustStreamDataServer,
) error {
    ctx := stream.Context()
    
    // ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆé€ä¿¡
    heartbeatTicker := time.NewTicker(30 * time.Second)
    defer heartbeatTicker.Stop()
    
    errorChan := make(chan error, 1)
    
    // ãƒ‡ãƒ¼ã‚¿é€ä¿¡Goroutine
    go func() {
        defer close(errorChan)
        
        for data := range s.generateData(ctx, req) {
            response := &pb.DataResponse{
                Data:      data,
                Timestamp: time.Now().Unix(),
            }
            
            if err := stream.Send(response); err != nil {
                errorChan <- err
                return
            }
        }
    }()
    
    // ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆã¨ã‚¨ãƒ©ãƒ¼ç›£è¦–
    for {
        select {
        case <-heartbeatTicker.C:
            // ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆé€ä¿¡
            heartbeat := &pb.DataResponse{
                Data:        "",
                Timestamp:   time.Now().Unix(),
                IsHeartbeat: true,
            }
            if err := stream.Send(heartbeat); err != nil {
                return err
            }
            
        case err := <-errorChan:
            if err != nil {
                // ã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
                log.Printf("Stream error: %v", err)
                return err
            }
            return nil // æ­£å¸¸çµ‚äº†
            
        case <-ctx.Done():
            return ctx.Err()
        }
    }
}
```

#### 3. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå®Ÿè£…ä¾‹

```go
// ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã®å®Ÿè£…
type StreamingClient struct {
    client pb.DataServiceClient
    conn   *grpc.ClientConn
}

func NewStreamingClient(address string) (*StreamingClient, error) {
    conn, err := grpc.Dial(address, grpc.WithInsecure())
    if err != nil {
        return nil, err
    }
    
    return &StreamingClient{
        client: pb.NewDataServiceClient(conn),
        conn:   conn,
    }, nil
}

func (c *StreamingClient) ReceiveStream(ctx context.Context, req *pb.StreamRequest) error {
    stream, err := c.client.StreamData(ctx, req)
    if err != nil {
        return err
    }
    
    for {
        response, err := stream.Recv()
        if err == io.EOF {
            log.Println("Stream ended normally")
            break
        }
        if err != nil {
            return fmt.Errorf("stream error: %w", err)
        }
        
        // ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if response.GetIsHeartbeat() {
            continue
        }
        
        // ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        if err := c.processData(response); err != nil {
            log.Printf("Error processing data: %v", err)
            continue
        }
    }
    
    return nil
}

func (c *StreamingClient) ReceiveStreamWithRetry(ctx context.Context, req *pb.StreamRequest) error {
    maxRetries := 3
    backoff := time.Second
    
    for attempt := 0; attempt < maxRetries; attempt++ {
        err := c.ReceiveStream(ctx, req)
        if err == nil {
            return nil
        }
        
        // è‡´å‘½çš„ã§ãªã„ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å†è©¦è¡Œ
        if isRetryableError(err) && attempt < maxRetries-1 {
            log.Printf("Stream failed (attempt %d/%d): %v. Retrying in %v...", 
                attempt+1, maxRetries, err, backoff)
            
            select {
            case <-time.After(backoff):
                backoff *= 2 // æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
            case <-ctx.Done():
                return ctx.Err()
            }
            continue
        }
        
        return err
    }
    
    return fmt.Errorf("stream failed after %d attempts", maxRetries)
}

func isRetryableError(err error) bool {
    if err == nil {
        return false
    }
    
    // gRPCã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ã«ã‚ˆã‚‹åˆ¤å®š
    st, ok := status.FromError(err)
    if !ok {
        return false
    }
    
    switch st.Code() {
    case codes.Unavailable, codes.DeadlineExceeded, codes.ResourceExhausted:
        return true
    default:
        return false
    }
}
```

## ğŸ“ èª²é¡Œ (The Problem)

`main_test.go`ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ã™ã¹ã¦ãƒ‘ã‚¹ã™ã‚‹ã‚ˆã†ã«ã€ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š

### 1. ãƒ­ã‚°ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’é…ä¿¡
- ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€æ™‚é–“ç¯„å›²ã§ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
- `tail -f`ã®ã‚ˆã†ãªãƒ•ã‚©ãƒ­ãƒ¼ãƒ¢ãƒ¼ãƒ‰

### 2. ãƒ•ã‚¡ã‚¤ãƒ«è»¢é€ã‚µãƒ¼ãƒ“ã‚¹
- å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŠ¹ç‡çš„ã«åˆ†å‰²é€ä¿¡
- ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¨ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡
- ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼
- éƒ¨åˆ†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯¾å¿œ

### 3. ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–ã‚µãƒ¼ãƒ“ã‚¹
- ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é…ä¿¡
- è¨­å®šå¯èƒ½ãªç›£è¦–é–“éš”
- ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

### 4. é€šçŸ¥é…ä¿¡ã‚µãƒ¼ãƒ“ã‚¹
- ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥é€šçŸ¥ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é…ä¿¡
- å„ªå…ˆåº¦åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
- é€šçŸ¥ã‚­ãƒ¥ãƒ¼ã®ç®¡ç†

**å®Ÿè£…ã™ã¹ãé–¢æ•°ï¼š**

```go
// ãƒ­ã‚°ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
func (s *LogServer) StreamLogs(req *pb.LogStreamRequest, stream pb.LogService_StreamLogsServer) error

// ãƒ•ã‚¡ã‚¤ãƒ«è»¢é€
func (s *FileServer) DownloadFile(req *pb.FileRequest, stream pb.FileService_DownloadFileServer) error

// ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–
func (s *MetricsServer) StreamMetrics(req *pb.MetricsRequest, stream pb.MetricsService_StreamMetricsServer) error

// é€šçŸ¥é…ä¿¡
func (s *NotificationServer) SubscribeToNotifications(req *pb.SubscriptionRequest, stream pb.NotificationService_SubscribeToNotificationsServer) error
```

**é‡è¦ãªå®Ÿè£…è¦ä»¶ï¼š**
- é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†
- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆ‡æ–­ã®æ¤œå‡ºã¨æ¸…ç†å‡¦ç†
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
- ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã®å›é¿
- ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆæ©Ÿèƒ½ã«ã‚ˆã‚‹æ¥ç¶šç›£è¦–

## âœ… æœŸå¾…ã•ã‚Œã‚‹æŒ™å‹• (Expected Behavior)

å®Ÿè£…ãŒæ­£ã—ãå®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªçµæœãŒå¾—ã‚‰ã‚Œã¾ã™ï¼š

### ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¾‹
```bash
$ go test -v
=== RUN   TestLogStreaming
=== RUN   TestLogStreaming/Historical_logs
=== RUN   TestLogStreaming/Follow_mode
=== RUN   TestLogStreaming/Filter_by_level
--- PASS: TestLogStreaming (0.15s)

=== RUN   TestFileTransfer
=== RUN   TestFileTransfer/Complete_download
=== RUN   TestFileTransfer/Partial_download
=== RUN   TestFileTransfer/Checksum_verification
--- PASS: TestFileTransfer (0.25s)

=== RUN   TestMetricsStreaming
=== RUN   TestMetricsStreaming/Real_time_metrics
=== RUN   TestMetricsStreaming/Custom_interval
--- PASS: TestMetricsStreaming (0.20s)

PASS
```

### ãƒ—ãƒ­ã‚°ãƒ©ãƒ å®Ÿè¡Œä¾‹
```bash
$ go run main.go
=== gRPC Server-side Streaming Demo ===

Starting log streaming server on :8080...
Log streaming ready - connect with: grpcurl -d '{"application":"myapp","follow":true}' localhost:8080 LogService/StreamLogs

File transfer server ready - download with: grpcurl -d '{"file_path":"test.txt","chunk_size":1024}' localhost:8080 FileService/DownloadFile

Metrics streaming ready - monitor with: grpcurl -d '{"metric_names":["cpu","memory"],"interval_seconds":5}' localhost:8080 MetricsService/StreamMetrics

Press Ctrl+C to stop...
```

### ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœä¾‹
```bash
$ go test -bench=.
BenchmarkLogStreaming-8          1000    1500000 ns/op    150 B/op    3 allocs/op
BenchmarkFileTransfer-8           500    3000000 ns/op   1024 B/op    2 allocs/op
BenchmarkMetricsStreaming-8      2000    1000000 ns/op    200 B/op    4 allocs/op
```

## ğŸ’¡ ãƒ’ãƒ³ãƒˆ (Hints)

è©°ã¾ã£ã¦ã—ã¾ã£ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®ãƒ’ãƒ³ãƒˆã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š

### åŸºæœ¬çš„ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè£…
```go
func (s *Server) StreamData(req *pb.Request, stream pb.Service_StreamDataServer) error {
    for i := 0; i < 10; i++ {
        response := &pb.Response{
            Data: fmt.Sprintf("Message %d", i),
        }
        
        if err := stream.Send(response); err != nil {
            return err
        }
        
        time.Sleep(100 * time.Millisecond)
    }
    return nil
}
```

### ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒ³ã‚»ãƒ«ã®å‡¦ç†
```go
func (s *Server) StreamWithCancellation(req *pb.Request, stream pb.Service_StreamDataServer) error {
    ctx := stream.Context()
    
    for {
        select {
        case <-ctx.Done():
            return ctx.Err()
        default:
            // ãƒ‡ãƒ¼ã‚¿é€ä¿¡
            if err := stream.Send(response); err != nil {
                return err
            }
        }
    }
}
```

### ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
```go
func (s *Server) StreamWithCleanup(req *pb.Request, stream pb.Service_StreamDataServer) error {
    // ãƒªã‚½ãƒ¼ã‚¹åˆæœŸåŒ–
    resource := acquireResource()
    defer func() {
        // å¿…ãšã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        releaseResource(resource)
    }()
    
    // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†
    for data := range generateData() {
        if err := stream.Send(data); err != nil {
            log.Printf("Stream error: %v", err)
            return err
        }
    }
    
    return nil
}
```

## å®Ÿè¡Œæ–¹æ³•

```bash
# ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒãƒƒãƒ•ã‚¡ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
protoc --go_out=. --go-grpc_out=. *.proto

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
go test -v

# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¸¬å®š
go test -bench=.

# ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
go run main.go

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ†ã‚¹ãƒˆï¼ˆåˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ï¼‰
grpcurl -d '{"application":"test"}' localhost:8080 LogService/StreamLogs
```

## å‚è€ƒè³‡æ–™

- [gRPC Go Documentation](https://grpc.io/docs/languages/go/)
- [Protocol Buffers Guide](https://developers.google.com/protocol-buffers)
- [gRPC Streaming Examples](https://github.com/grpc/grpc-go/tree/master/examples)
- [gRPC Error Handling](https://grpc.io/docs/guides/error/)