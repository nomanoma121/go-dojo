# Day 58: Prometheus Histogram Metrics

## ğŸ¯ æœ¬æ—¥ã®ç›®æ¨™ (Today's Goal)

Prometheusãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å®Ÿè£…ã—ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·åˆ†å¸ƒã‚„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚’è¡Œã†é«˜åº¦ãªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®—ã€ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶ã®è¨­å®šã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†ææ‰‹æ³•ã‚’ç¿’å¾—ã™ã‚‹ã€‚

## ğŸ“– è§£èª¬ (Explanation)

### ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã¨ã¯

ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã¯è¦³æ¸¬å€¤ã‚’äº‹å‰å®šç¾©ã•ã‚ŒãŸãƒã‚±ãƒƒãƒˆï¼ˆåŒºé–“ï¼‰ã«åˆ†é¡ã—ã¦ã€å€¤ã®åˆ†å¸ƒã‚’æ¸¬å®šã™ã‚‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹å‹ã§ã™ã€‚ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚„ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãªã©ã€å€¤ã®ç¯„å›²ãŒåºƒãåˆ†å¸ƒã®å½¢çŠ¶ãŒé‡è¦ãªæŒ‡æ¨™ã®ç›£è¦–ã«é©ã—ã¦ã„ã¾ã™ã€‚

### ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®æ§‹é€ 

Prometheusãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã¯3ã¤ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚·ãƒªãƒ¼ã‚ºã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ï¼š

```
# ãƒã‚±ãƒƒãƒˆåˆ¥ã®ç´¯ç©ã‚«ã‚¦ãƒ³ãƒˆ
http_request_duration_seconds_bucket{le="0.1"} 850
http_request_duration_seconds_bucket{le="0.5"} 1200  
http_request_duration_seconds_bucket{le="1.0"} 1450
http_request_duration_seconds_bucket{le="+Inf"} 1500

# å…¨è¦³æ¸¬å€¤ã®åˆè¨ˆ
http_request_duration_seconds_sum 425.3

# è¦³æ¸¬å›æ•°ã®ç·æ•°
http_request_duration_seconds_count 1500
```

### ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®åˆ©ç‚¹ã¨ç‰¹å¾´

#### 1. ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®—

ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‹ã‚‰æ§˜ã€…ãªãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã‚’è¨ˆç®—ã§ãã¾ã™ï¼š

```promql
# 95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# 50ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ï¼ˆä¸­å¤®å€¤ï¼‰
histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))

# 99.9ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
histogram_quantile(0.999, rate(http_request_duration_seconds_bucket[5m]))
```

#### 2. é›†ç´„å¯èƒ½æ€§

è¤‡æ•°ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‹ã‚‰ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’é›†ç´„ã§ãã¾ã™ï¼š

```promql
# è¤‡æ•°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
histogram_quantile(0.95, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
)

# ã‚µãƒ¼ãƒ“ã‚¹åˆ¥ã®95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
histogram_quantile(0.95,
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
)
```

#### 3. SLI/SLO ç›£è¦–

Service Level Indicatorsï¼ˆSLIï¼‰ã¨Service Level Objectivesï¼ˆSLOï¼‰ã®ç›£è¦–ï¼š

```promql
# 95%ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒ100msä»¥å†…ï¼ˆSLIï¼‰
(
  sum(rate(http_request_duration_seconds_bucket{le="0.1"}[5m])) 
  / 
  sum(rate(http_request_duration_seconds_count[5m]))
) * 100

# ã‚¨ãƒ©ãƒ¼ãƒã‚¸ã‚§ãƒƒãƒˆæ¶ˆè²»ç‡
1 - (
  sum(rate(http_request_duration_seconds_bucket{le="0.1"}[5m])) 
  / 
  sum(rate(http_request_duration_seconds_count[5m]))
)
```

### ãƒã‚±ãƒƒãƒˆè¨­è¨ˆã®è€ƒæ…®äº‹é …

#### 1. é©åˆ‡ãªãƒã‚±ãƒƒãƒˆå¢ƒç•Œ

```go
// ã€Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒã‚±ãƒƒãƒˆè¨­è¨ˆã€‘ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ã‚’é‡è¦–ã—ãŸå¢ƒç•Œè¨­å®š
webBuckets := []float64{
    // ã€è¶…é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã€‘1msæœªæº€: é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€CDNã‚­ãƒ£ãƒƒã‚·ãƒ¥
    0.001, 
    // ã€é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã€‘5msæœªæº€: ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ã‚·ãƒ³ãƒ—ãƒ«API
    0.005, 
    // ã€è‰¯å¥½ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã€‘10msæœªæº€: è»½é‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒª
    0.01, 
    // ã€è¨±å®¹ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã€‘25msæœªæº€: è¤‡é›‘ãªãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯
    0.025, 
    // ã€ä½“æ„Ÿè‰¯å¥½ã€‘50msæœªæº€: ä¸€èˆ¬çš„ãªWebãƒšãƒ¼ã‚¸
    0.05, 
    // ã€ä½“æ„Ÿå¢ƒç•Œã€‘100msæœªæº€: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå³åº§ã¨æ„Ÿã˜ã‚‹é™ç•Œ
    0.1, 
    // ã€ä½“æ„Ÿé…å»¶ã€‘250msæœªæº€: è»½å¾®ãªé…å»¶ã‚’æ„Ÿã˜å§‹ã‚ã‚‹
    0.25, 
    // ã€æ˜ç¢ºãªé…å»¶ã€‘500msæœªæº€: æ˜ã‚‰ã‹ãªé…å»¶ã‚’æ„Ÿã˜ã‚‹
    0.5, 
    // ã€é•·ã„é…å»¶ã€‘1ç§’æœªæº€: ç¶™ç¶šçš„ãªæ“ä½œã«å½±éŸ¿
    1.0, 
    // ã€éå¸¸ã«é…ã„ã€‘2.5ç§’æœªæº€: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ“ä½œã‚’ä¸­æ–­ã—å§‹ã‚ã‚‹
    2.5, 
    // ã€é™ç•Œé…å»¶ã€‘5ç§’æœªæº€: å¤§åŠã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé›¢è„±
    5.0, 
    // ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¸å‰ã€‘10ç§’æœªæº€: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã®ä¸€èˆ¬çš„ãªå€¤
    10.0,
}

// ã€APIå‡¦ç†æ™‚é–“ç”¨ãƒã‚±ãƒƒãƒˆã€‘ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰å‡¦ç†ã®è©³ç´°åˆ†æ
apiBuckets := []float64{
    // ã€å³åº§å‡¦ç†ã€‘100msæœªæº€: è»½é‡APIï¼ˆèªè¨¼ã€ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    0.1, 
    // ã€è¿…é€Ÿå‡¦ç†ã€‘500msæœªæº€: æ¨™æº–çš„ãªCRUDæ“ä½œ
    0.5, 
    // ã€æ¨™æº–å‡¦ç†ã€‘1ç§’æœªæº€: è¤‡é›‘ãªè¨ˆç®—ã€å¤–éƒ¨APIå‘¼ã³å‡ºã—
    1.0, 
    // ã€é‡ã„å‡¦ç†ã€‘2ç§’æœªæº€: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã€è¤‡é›‘ãªJOIN
    2.0, 
    // ã€ãƒãƒƒãƒå‡¦ç†ã€‘5ç§’æœªæº€: ãƒ‡ãƒ¼ã‚¿é›†è¨ˆã€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
    5.0, 
    // ã€é•·æœŸå‡¦ç†ã€‘10ç§’æœªæº€: å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†
    10.0, 
    // ã€éåŒæœŸå€™è£œã€‘30ç§’æœªæº€: éåŒæœŸå‡¦ç†ã¸ã®ç§»è¡Œæ¤œè¨
    30.0, 
    // ã€éåŒæœŸå¿…é ˆã€‘60ç§’æœªæº€: éåŒæœŸå‡¦ç†ãŒå¿…è¦
    60.0, 
    // ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€‘120ç§’æœªæº€: ä¸€èˆ¬çš„ãªHTTPã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    120.0,
}

// ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç”¨ãƒã‚±ãƒƒãƒˆã€‘ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è»¢é€ã¨ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸åˆ†æ
fileSizeBuckets := []float64{
    // ã€å°ã•ãªãƒ•ã‚¡ã‚¤ãƒ«ã€‘1KB: ã‚¢ã‚¤ã‚³ãƒ³ã€å°ã•ãªJSON
    1024, 
    // ã€è»½é‡ãƒ•ã‚¡ã‚¤ãƒ«ã€‘4KB: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã€å°ã•ãªHTML
    4096, 
    // ã€ä¸­å°ãƒ•ã‚¡ã‚¤ãƒ«ã€‘16KB: åœ§ç¸®ã•ã‚ŒãŸCSS/JS
    16384, 
    // ã€æ¨™æº–ãƒ•ã‚¡ã‚¤ãƒ«ã€‘64KB: é€šå¸¸ã®Webãƒšãƒ¼ã‚¸
    65536, 
    // ã€å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã€‘256KB: å¤§ããªJSONãƒ¬ã‚¹ãƒãƒ³ã‚¹
    262144, 
    // ã€ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã€‘1MB: åœ§ç¸®ã•ã‚ŒãŸç”»åƒ
    1048576, 
    // ã€å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã€‘4MB: é«˜è§£åƒåº¦ç”»åƒ
    4194304, 
    // ã€éå¸¸ã«å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã€‘16MB: å‹•ç”»ã€å¤§ããªPDF
    16777216,
}

// ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªç”¨ãƒã‚±ãƒƒãƒˆã€‘é«˜ç²¾åº¦ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
dbBuckets := []float64{
    // ã€è¶…é«˜é€Ÿã‚¯ã‚¨ãƒªã€‘0.1msæœªæº€: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã‚ˆã‚‹ä¸»ã‚­ãƒ¼æ¤œç´¢
    0.0001, 
    // ã€é«˜é€Ÿã‚¯ã‚¨ãƒªã€‘0.5msæœªæº€: å˜ç´”ãªSELECTã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ´»ç”¨
    0.0005, 
    // ã€è‰¯å¥½ã‚¯ã‚¨ãƒªã€‘1msæœªæº€: è»½é‡ãªJOINã€å°è¦æ¨¡ãƒ†ãƒ¼ãƒ–ãƒ«
    0.001, 
    // ã€æ¨™æº–ã‚¯ã‚¨ãƒªã€‘5msæœªæº€: è¤‡é›‘ãªWHEREæ¡ä»¶
    0.005, 
    // ã€é‡ã„ã‚¯ã‚¨ãƒªã€‘10msæœªæº€: è¤‡æ•°ãƒ†ãƒ¼ãƒ–ãƒ«ã®JOIN
    0.01, 
    // ã€éå¸¸ã«é‡ã„ã‚¯ã‚¨ãƒªã€‘50msæœªæº€: å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®GROUP BY
    0.05, 
    // ã€æœ€é©åŒ–è¦æ¤œè¨ã€‘100msæœªæº€: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ ã‚’æ¤œè¨
    0.1, 
    // ã€æœ€é©åŒ–å¿…é ˆã€‘500msæœªæº€: ç·Šæ€¥ã«æœ€é©åŒ–ãŒå¿…è¦
    0.5, 
    // ã€å•é¡Œã‚¯ã‚¨ãƒªã€‘1ç§’æœªæº€: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ€§èƒ½ã«æ·±åˆ»ãªå½±éŸ¿
    1.0, 
    // ã€å±é™ºã‚¯ã‚¨ãƒªã€‘5ç§’æœªæº€: ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã«å½±éŸ¿
    5.0,
}

// ã€ãƒ“ã‚¸ãƒã‚¹å›ºæœ‰ãƒã‚±ãƒƒãƒˆã€‘æ¥­ç•Œãƒ»ç”¨é€”åˆ¥ã®ç‰¹æ®Šãªå¢ƒç•Œè¨­å®š
// ã€é‡‘èå–å¼•ã€‘ãƒŸãƒªç§’å˜ä½ã®è¶…é«˜ç²¾åº¦ç›£è¦–
financialTradingBuckets := []float64{
    0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0,
}

// ã€å‹•ç”»ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã€‘å¸¯åŸŸå¹…ã¨ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°åˆ†æ
videoStreamingBuckets := []float64{
    0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0, 120.0, 300.0,
}

// ã€æ©Ÿæ¢°å­¦ç¿’æ¨è«–ã€‘æ¨è«–æ™‚é–“ã®è©³ç´°åˆ†æ
mlInferenceBuckets := []float64{
    0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0,
}

// ã€IoTãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€‘å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†æ™‚é–“åˆ†æ
iotProcessingBuckets := []float64{
    0.001, 0.01, 0.1, 1.0, 10.0, 60.0, 300.0, 1800.0, 3600.0,
}
```

#### 2. æŒ‡æ•°çš„ãƒã‚±ãƒƒãƒˆç”Ÿæˆ

```go
import "github.com/prometheus/client_golang/prometheus"

// ã€æŒ‡æ•°çš„ãƒã‚±ãƒƒãƒˆç”Ÿæˆã€‘æ€§èƒ½è¦ä»¶ã«å¿œã˜ãŸå‹•çš„ãƒã‚±ãƒƒãƒˆè¨­è¨ˆ
func createExponentialBuckets() []float64 {
    // ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£èª¬ã€‘
    // Start=0.1: é–‹å§‹å€¤ï¼ˆ100msï¼‰
    // Factor=2: å„ãƒã‚±ãƒƒãƒˆã¯å‰ã®å€¤ã®2å€
    // Count=10: 10å€‹ã®ãƒã‚±ãƒƒãƒˆã‚’ç”Ÿæˆ
    // çµæœ: [0.1, 0.2, 0.4, 0.8, 1.6, 3.2, 6.4, 12.8, 25.6, 51.2]
    buckets := prometheus.ExponentialBuckets(0.1, 2, 10)
    
    // ã€æŒ‡æ•°çš„ãƒã‚±ãƒƒãƒˆã®ç‰¹å¾´ã€‘ï¼š
    // - ä½ã„å€¤ã«é«˜ã„è§£åƒåº¦ã‚’æä¾›
    // - é«˜ã„å€¤ã«ã¯ä½ã„è§£åƒåº¦ï¼ˆç²—ã„ç²’åº¦ï¼‰
    // - ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚„ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã«æœ€é©
    // - å¤šãã®å€¤ãŒä½ã„ç¯„å›²ã«é›†ä¸­ã™ã‚‹åˆ†å¸ƒã«é©ã—ã¦ã„ã‚‹
    
    fmt.Printf("ğŸ“Š Exponential buckets: %v\n", buckets)
    
    // ã€å®Ÿç”¨ä¾‹ã€‘ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®è©³ç´°åˆ†æ
    // 0.1sæœªæº€: 93%ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆè©³ç´°ãªåˆ†æãŒå¿…è¦ï¼‰
    // 0.1-1.0s: 6%ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ï¼‰
    // 1.0sä»¥ä¸Š: 1%ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆå•é¡Œã®ã‚ã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰
    
    return buckets
}

// ã€ç·šå½¢ãƒã‚±ãƒƒãƒˆç”Ÿæˆã€‘ç­‰é–“éš”ã§ã®ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒåˆ†æ
func createLinearBuckets() []float64 {
    // ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£èª¬ã€‘
    // Start=0: é–‹å§‹å€¤
    // Width=10: å„ãƒã‚±ãƒƒãƒˆã®å¹…
    // Count=20: 20å€‹ã®ãƒã‚±ãƒƒãƒˆã‚’ç”Ÿæˆ
    // çµæœ: [0, 10, 20, 30, ..., 190]
    linearBuckets := prometheus.LinearBuckets(0, 10, 20)
    
    // ã€ç·šå½¢ãƒã‚±ãƒƒãƒˆã®ç‰¹å¾´ã€‘ï¼š
    // - å…¨ç¯„å›²ã§ç­‰ã—ã„è§£åƒåº¦ã‚’æä¾›
    // - ä¸€æ§˜åˆ†å¸ƒã‚„æ­£è¦åˆ†å¸ƒã«é©ã—ã¦ã„ã‚‹
    // - ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã€ã‚¨ãƒ©ãƒ¼ç‡ã€å‡ç­‰ãªã‚«ãƒ†ã‚´ãƒªåˆ†æã«æœ€é©
    
    fmt.Printf("ğŸ“Š Linear buckets: %v\n", linearBuckets)
    
    // ã€å®Ÿç”¨ä¾‹ã€‘ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆåˆ†æ
    // 0-10 req/sec: ä½è² è·æ™‚é–“å¸¯
    // 10-50 req/sec: é€šå¸¸è² è·æ™‚é–“å¸¯
    // 50-100 req/sec: é«˜è² è·æ™‚é–“å¸¯
    // 100+ req/sec: ãƒ”ãƒ¼ã‚¯è² è·æ™‚é–“å¸¯
    
    return linearBuckets
}

// ã€ã‚«ã‚¹ã‚¿ãƒ ãƒã‚±ãƒƒãƒˆç”Ÿæˆã€‘ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ã«ç‰¹åŒ–ã—ãŸå¢ƒç•Œè¨­è¨ˆ
func createCustomBuckets(serviceType string) []float64 {
    switch serviceType {
    case "microservice":
        // ã€ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã€‘ã‚µãƒ¼ãƒ“ã‚¹é–“é€šä¿¡ã®æœ€é©åŒ–
        return []float64{
            0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0,
        }
        
    case "database":
        // ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€‘ã‚¯ã‚¨ãƒªæ€§èƒ½ã®è©³ç´°åˆ†æ
        return []float64{
            0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0,
        }
        
    case "batch":
        // ã€ãƒãƒƒãƒå‡¦ç†ã€‘é•·æ™‚é–“å‡¦ç†ã®ç›£è¦–
        return []float64{
            1.0, 10.0, 30.0, 60.0, 300.0, 600.0, 1800.0, 3600.0, 7200.0,
        }
        
    case "realtime":
        // ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã€‘è¶…ä½é…å»¶è¦æ±‚ã‚·ã‚¹ãƒ†ãƒ 
        return []float64{
            0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1,
        }
        
    default:
        // ã€æ±ç”¨ã€‘ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸè¨­è¨ˆ
        return prometheus.DefBuckets
    }
}

// ã€ãƒã‚±ãƒƒãƒˆè¨­è¨ˆæ¤œè¨¼ã€‘å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæœ€é©åŒ–
func validateBucketDesign(buckets []float64, sampleData []float64) BucketAnalysis {
    analysis := BucketAnalysis{
        Buckets: buckets,
        Distribution: make([]int, len(buckets)),
        TotalSamples: len(sampleData),
    }
    
    // ã€ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã®è¨ˆç®—ã€‘
    for _, value := range sampleData {
        for i, bucket := range buckets {
            if value <= bucket {
                analysis.Distribution[i]++
                break
            }
        }
    }
    
    // ã€ãƒã‚±ãƒƒãƒˆåŠ¹ç‡ã®è¨ˆç®—ã€‘
    for i, count := range analysis.Distribution {
        percentage := float64(count) / float64(analysis.TotalSamples) * 100
        analysis.Efficiency = append(analysis.Efficiency, percentage)
        
        // ã€è­¦å‘Šã€‘ï¼šç©ºã®ãƒã‚±ãƒƒãƒˆã‚„åã‚Šã®æ¤œå‡º
        if count == 0 {
            log.Printf("âš ï¸  Empty bucket: %f (may be unnecessary)", buckets[i])
        } else if percentage > 80 {
            log.Printf("âš ï¸  Overloaded bucket: %f (%.1f%% of data)", buckets[i], percentage)
        }
    }
    
    return analysis
}

// ã€å‹•çš„ãƒã‚±ãƒƒãƒˆèª¿æ•´ã€‘é‹ç”¨ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãè‡ªå‹•æœ€é©åŒ–
func optimizeBuckets(currentBuckets []float64, historicalData []float64) []float64 {
    // ã€STEP 1ã€‘ç¾åœ¨ã®åˆ†å¸ƒã‚’åˆ†æ
    analysis := validateBucketDesign(currentBuckets, historicalData)
    
    // ã€STEP 2ã€‘ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
    stats := calculateStatistics(historicalData)
    
    // ã€STEP 3ã€‘æœ€é©ãªãƒã‚±ãƒƒãƒˆã‚’ç”Ÿæˆ
    optimizedBuckets := make([]float64, 0)
    
    // ã€æˆ¦ç•¥1ã€‘ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®å¢ƒç•Œ
    percentiles := []float64{0.5, 0.75, 0.9, 0.95, 0.99, 0.999}
    for _, p := range percentiles {
        value := calculatePercentile(historicalData, p)
        optimizedBuckets = append(optimizedBuckets, value)
    }
    
    // ã€æˆ¦ç•¥2ã€‘ãƒ‡ãƒ¼ã‚¿ã®è‡ªç„¶ãªå¢ƒç•Œ
    // æ¨™æº–åå·®ã«åŸºã¥ãå¢ƒç•Œ
    for i := 1; i <= 3; i++ {
        boundary := stats.Mean + float64(i)*stats.StdDev
        optimizedBuckets = append(optimizedBuckets, boundary)
    }
    
    // ã€STEP 4ã€‘ãƒã‚±ãƒƒãƒˆã‚’ã‚½ãƒ¼ãƒˆã—ã¦é‡è¤‡ã‚’é™¤å»
    sort.Float64s(optimizedBuckets)
    uniqueBuckets := removeDuplicates(optimizedBuckets)
    
    log.Printf("ğŸ”„ Bucket optimization complete: %d -> %d buckets", 
        len(currentBuckets), len(uniqueBuckets))
    
    return uniqueBuckets
}

// ã€åˆ†æçµæœæ§‹é€ ä½“ã€‘ãƒã‚±ãƒƒãƒˆè¨­è¨ˆã®è©•ä¾¡
type BucketAnalysis struct {
    Buckets       []float64 `json:"buckets"`
    Distribution  []int     `json:"distribution"`
    Efficiency    []float64 `json:"efficiency"`
    TotalSamples  int       `json:"total_samples"`
    Recommendations []string `json:"recommendations"`
}

// ã€çµ±è¨ˆæƒ…å ±æ§‹é€ ä½“ã€‘ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã®ç‰¹æ€§
type DataStatistics struct {
    Mean   float64 `json:"mean"`
    Median float64 `json:"median"`
    StdDev float64 `json:"std_dev"`
    Min    float64 `json:"min"`
    Max    float64 `json:"max"`
    P95    float64 `json:"p95"`
    P99    float64 `json:"p99"`
}
```

### é«˜åº¦ãªãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å®Ÿè£…

#### 1. è¤‡æ•°æ¬¡å…ƒãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 

```go
// ã€é«˜åº¦ãªãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã€‘å¤šæ¬¡å…ƒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚·ã‚¹ãƒ†ãƒ 
type RequestLatencyTracker struct {
    histogram          *prometheus.HistogramVec
    slowRequestCounter *prometheus.CounterVec
    requestSizeHist    *prometheus.HistogramVec
    concurrencyGauge   *prometheus.GaugeVec
    
    // ã€çµ±è¨ˆæƒ…å ±ã€‘ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æç”¨
    stats              *LatencyStats
    slowThreshold      time.Duration
    sampleRate         float64
    mu                 sync.RWMutex
}

// ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·çµ±è¨ˆã€‘é‹ç”¨ç›£è¦–ã®ãŸã‚ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é›†è¨ˆ
type LatencyStats struct {
    TotalRequests     int64         `json:"total_requests"`
    SlowRequests      int64         `json:"slow_requests"`
    AverageLatency    time.Duration `json:"average_latency"`
    P95Latency        time.Duration `json:"p95_latency"`
    P99Latency        time.Duration `json:"p99_latency"`
    LastUpdate        time.Time     `json:"last_update"`
    EndpointStats     map[string]*EndpointStats `json:"endpoint_stats"`
}

// ã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå›ºæœ‰çµ±è¨ˆã€‘è©³ç´°ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
type EndpointStats struct {
    RequestCount      int64         `json:"request_count"`
    ErrorCount        int64         `json:"error_count"`
    AverageLatency    time.Duration `json:"average_latency"`
    MaxLatency        time.Duration `json:"max_latency"`
    MinLatency        time.Duration `json:"min_latency"`
    TotalLatency      time.Duration `json:"total_latency"`
    LastAccess        time.Time     `json:"last_access"`
}

func NewRequestLatencyTracker(slowThreshold time.Duration) *RequestLatencyTracker {
    return &RequestLatencyTracker{
        histogram: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name: "http_request_duration_seconds",
                Help: "Time spent on HTTP requests",
                // ã€æœ€é©åŒ–ã•ã‚ŒãŸãƒã‚±ãƒƒãƒˆã€‘Web ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®UXåŸºæº–ã«åŸºã¥ãè¨­è¨ˆ
                Buckets: []float64{
                    // ã€å„ªç§€ã€‘1msæœªæº€: é™çš„ãƒªã‚½ãƒ¼ã‚¹ã€ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥
                    0.001, 
                    // ã€è‰¯å¥½ã€‘5msæœªæº€: è»½é‡APIã€ã‚·ãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒª
                    0.005, 
                    // ã€æ¨™æº–ã€‘10msæœªæº€: é€šå¸¸ã®ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯
                    0.01, 
                    // ã€è¨±å®¹ã€‘25msæœªæº€: è¤‡é›‘ãªå‡¦ç†ã€å¤–éƒ¨APIå‘¼ã³å‡ºã—
                    0.025, 
                    // ã€ä½“æ„Ÿè‰¯å¥½ã€‘50msæœªæº€: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¿«é©ã«æ„Ÿã˜ã‚‹é™ç•Œ
                    0.05, 
                    // ã€ä½“æ„Ÿå¢ƒç•Œã€‘100msæœªæº€: å³åº§ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨æ„Ÿã˜ã‚‹é™ç•Œ
                    0.1, 
                    // ã€è»½å¾®ãªé…å»¶ã€‘250msæœªæº€: åƒ…ã‹ãªé…å»¶ã‚’æ„Ÿã˜å§‹ã‚ã‚‹
                    0.25, 
                    // ã€æ˜ç¢ºãªé…å»¶ã€‘500msæœªæº€: æ˜ã‚‰ã‹ãªé…å»¶ã¨ã—ã¦èªè­˜
                    0.5, 
                    // ã€é…ã„ã€‘1ç§’æœªæº€: ç¶™ç¶šçš„æ“ä½œã«æ”¯éšœ
                    1.0, 
                    // ã€éå¸¸ã«é…ã„ã€‘2.5ç§’æœªæº€: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ“ä½œæ„æ¬²ã«å½±éŸ¿
                    2.5, 
                    // ã€é™ç•Œã€‘5ç§’æœªæº€: å¤šãã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé›¢è„±
                    5.0, 
                    // ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¸å‰ã€‘10ç§’æœªæº€: ä¸€èˆ¬çš„ãªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
                    10.0,
                },
            },
            []string{"method", "endpoint", "status_class", "user_type"}, // premium, standard, guest
        ),
        
        slowRequestCounter: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "http_slow_requests_total",
                Help: "Total number of slow HTTP requests",
            },
            []string{"method", "endpoint", "threshold_type"}, // warning, critical, severe
        ),
        
        requestSizeHist: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name: "http_request_size_bytes",
                Help: "Size of HTTP requests in bytes",
                Buckets: prometheus.ExponentialBuckets(64, 4, 10), // 64B to 64MB
            },
            []string{"method", "endpoint", "content_type"},
        ),
        
        concurrencyGauge: prometheus.NewGaugeVec(
            prometheus.GaugeOpts{
                Name: "http_requests_in_flight",
                Help: "Number of HTTP requests currently being processed",
            },
            []string{"endpoint", "method"},
        ),
        
        stats: &LatencyStats{
            EndpointStats: make(map[string]*EndpointStats),
        },
        slowThreshold: slowThreshold,
        sampleRate:    1.0, // 100% sampling by default
    }
}

// ã€åŒ…æ‹¬çš„ãƒªã‚¯ã‚¨ã‚¹ãƒˆè¿½è·¡ã€‘å¤šæ¬¡å…ƒãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
func (t *RequestLatencyTracker) TrackRequest(method, endpoint string, statusCode int, duration time.Duration, requestSize int64, userType string) {
    // ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€‘é«˜è² è·æ™‚ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚³ã‚¹ãƒˆå‰Šæ¸›
    if t.sampleRate < 1.0 && rand.Float64() > t.sampleRate {
        return
    }
    
    // ã€åŸºæœ¬åˆ†é¡ã€‘
    statusClass := fmt.Sprintf("%dxx", statusCode/100)
    
    // ã€STEP 1ã€‘ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ æ›´æ–°
    t.histogram.WithLabelValues(method, endpoint, statusClass, userType).Observe(duration.Seconds())
    
    // ã€STEP 2ã€‘ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚µã‚¤ã‚ºåˆ†æ
    if requestSize > 0 {
        contentType := "application/json" // å®Ÿéš›ã®å®Ÿè£…ã§ã¯ Content-Type ãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰å–å¾—
        t.requestSizeHist.WithLabelValues(method, endpoint, contentType).Observe(float64(requestSize))
    }
    
    // ã€STEP 3ã€‘é…ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ç‰¹åˆ¥ãªè¿½è·¡
    t.trackSlowRequests(method, endpoint, duration)
    
    // ã€STEP 4ã€‘çµ±è¨ˆæƒ…å ±ã®æ›´æ–°
    t.updateStats(method, endpoint, statusCode, duration)
    
    // ã€STEP 5ã€‘ç•°å¸¸æ¤œçŸ¥
    t.detectAnomalies(method, endpoint, duration, statusCode)
}

// ã€é…ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆç›£è¦–ã€‘ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–ã®æ—©æœŸæ¤œå‡º
func (t *RequestLatencyTracker) trackSlowRequests(method, endpoint string, duration time.Duration) {
    if duration > t.slowThreshold {
        // ã€æ®µéšçš„ã‚¢ãƒ©ãƒ¼ãƒˆã€‘é…å»¶ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸåˆ†é¡
        var thresholdType string
        switch {
        case duration > t.slowThreshold*5: // 5å€ä»¥ä¸Š
            thresholdType = "severe"
            log.Printf("ğŸš¨ SEVERE slow request: %s %s took %v (threshold: %v)", 
                method, endpoint, duration, t.slowThreshold)
        case duration > t.slowThreshold*2: // 2å€ä»¥ä¸Š
            thresholdType = "critical"
            log.Printf("âš ï¸  CRITICAL slow request: %s %s took %v (threshold: %v)", 
                method, endpoint, duration, t.slowThreshold)
        default:
            thresholdType = "warning"
            log.Printf("â° WARNING slow request: %s %s took %v (threshold: %v)", 
                method, endpoint, duration, t.slowThreshold)
        }
        
        t.slowRequestCounter.WithLabelValues(method, endpoint, thresholdType).Inc()
    }
}

// ã€çµ±è¨ˆæƒ…å ±æ›´æ–°ã€‘ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æã®ãŸã‚ã®å†…éƒ¨çŠ¶æ…‹ç®¡ç†
func (t *RequestLatencyTracker) updateStats(method, endpoint string, statusCode int, duration time.Duration) {
    t.mu.Lock()
    defer t.mu.Unlock()
    
    // ã€å…¨ä½“çµ±è¨ˆã€‘
    t.stats.TotalRequests++
    if duration > t.slowThreshold {
        t.stats.SlowRequests++
    }
    
    // ã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆçµ±è¨ˆã€‘
    endpointKey := fmt.Sprintf("%s %s", method, endpoint)
    if t.stats.EndpointStats[endpointKey] == nil {
        t.stats.EndpointStats[endpointKey] = &EndpointStats{
            MinLatency: duration,
            MaxLatency: duration,
        }
    }
    
    epStats := t.stats.EndpointStats[endpointKey]
    epStats.RequestCount++
    epStats.TotalLatency += duration
    epStats.AverageLatency = epStats.TotalLatency / time.Duration(epStats.RequestCount)
    epStats.LastAccess = time.Now()
    
    // ã€æœ€å°ãƒ»æœ€å¤§ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ›´æ–°ã€‘
    if duration < epStats.MinLatency {
        epStats.MinLatency = duration
    }
    if duration > epStats.MaxLatency {
        epStats.MaxLatency = duration
    }
    
    // ã€ã‚¨ãƒ©ãƒ¼çµ±è¨ˆã€‘
    if statusCode >= 400 {
        epStats.ErrorCount++
    }
    
    t.stats.LastUpdate = time.Now()
}

// ã€ç•°å¸¸æ¤œçŸ¥ã€‘çµ±è¨ˆçš„æ‰‹æ³•ã«ã‚ˆã‚‹ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
func (t *RequestLatencyTracker) detectAnomalies(method, endpoint string, duration time.Duration, statusCode int) {
    t.mu.RLock()
    defer t.mu.RUnlock()
    
    endpointKey := fmt.Sprintf("%s %s", method, endpoint)
    epStats, exists := t.stats.EndpointStats[endpointKey]
    if !exists || epStats.RequestCount < 10 {
        return // çµ±è¨ˆçš„åˆ†æã«ã¯æœ€ä½10ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå¿…è¦
    }
    
    // ã€ç•°å¸¸æ¤œçŸ¥æ¡ä»¶ã€‘
    avgLatency := epStats.AverageLatency
    
    // ã€æ¡ä»¶1ã€‘å¹³å‡ã®5å€ä»¥ä¸Šã®é…å»¶
    if duration > avgLatency*5 {
        log.Printf("ğŸ” ANOMALY: %s %s latency %.3fs is 5x average (%.3fs)", 
            method, endpoint, duration.Seconds(), avgLatency.Seconds())
    }
    
    // ã€æ¡ä»¶2ã€‘ã‚¨ãƒ©ãƒ¼ç‡ã®æ€¥æ¿€ãªä¸Šæ˜‡
    errorRate := float64(epStats.ErrorCount) / float64(epStats.RequestCount)
    if errorRate > 0.1 && statusCode >= 500 {
        log.Printf("ğŸ” ANOMALY: %s %s error rate %.1f%% with 5xx status", 
            method, endpoint, errorRate*100)
    }
    
    // ã€æ¡ä»¶3ã€‘çªç™ºçš„ãªé«˜è² è·
    if epStats.RequestCount > 100 {
        recentRequests := epStats.RequestCount / 10 // ç›´è¿‘10%ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        if recentRequests > 50 {
            log.Printf("ğŸ” ANOMALY: %s %s high request rate detected", method, endpoint)
        }
    }
}

// ã€çµ±è¨ˆæƒ…å ±å–å¾—ã€‘ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ã®ãƒ‡ãƒ¼ã‚¿æä¾›
func (t *RequestLatencyTracker) GetStats() LatencyStats {
    t.mu.RLock()
    defer t.mu.RUnlock()
    
    // ã€ãƒ‡ã‚£ãƒ¼ãƒ—ã‚³ãƒ”ãƒ¼ã€‘ä¸¦è¡Œå®‰å…¨æ€§ã‚’ä¿è¨¼
    stats := LatencyStats{
        TotalRequests:  t.stats.TotalRequests,
        SlowRequests:   t.stats.SlowRequests,
        AverageLatency: t.stats.AverageLatency,
        P95Latency:     t.stats.P95Latency,
        P99Latency:     t.stats.P99Latency,
        LastUpdate:     t.stats.LastUpdate,
        EndpointStats:  make(map[string]*EndpointStats),
    }
    
    // ã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆçµ±è¨ˆã®ã‚³ãƒ”ãƒ¼ã€‘
    for key, epStats := range t.stats.EndpointStats {
        stats.EndpointStats[key] = &EndpointStats{
            RequestCount:   epStats.RequestCount,
            ErrorCount:     epStats.ErrorCount,
            AverageLatency: epStats.AverageLatency,
            MaxLatency:     epStats.MaxLatency,
            MinLatency:     epStats.MinLatency,
            TotalLatency:   epStats.TotalLatency,
            LastAccess:     epStats.LastAccess,
        }
    }
    
    return stats
}

// ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡èª¿æ•´ã€‘è² è·ã«å¿œã˜ãŸå‹•çš„èª¿æ•´
func (t *RequestLatencyTracker) SetSampleRate(rate float64) {
    if rate < 0 || rate > 1.0 {
        log.Printf("âŒ Invalid sample rate: %f (must be 0.0-1.0)", rate)
        return
    }
    
    t.mu.Lock()
    defer t.mu.Unlock()
    
    t.sampleRate = rate
    log.Printf("ğŸ”„ Sample rate updated to %.1f%%", rate*100)
}

// ã€çµ±è¨ˆãƒªã‚»ãƒƒãƒˆã€‘å®šæœŸçš„ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
func (t *RequestLatencyTracker) ResetStats() {
    t.mu.Lock()
    defer t.mu.Unlock()
    
    t.stats = &LatencyStats{
        EndpointStats: make(map[string]*EndpointStats),
    }
    
    log.Printf("ğŸ”„ Latency statistics reset")
}
```

#### 2. è‡ªå‹•çš„ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†

```go
// ã€é«˜åº¦ãªãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã€‘åŒ…æ‹¬çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
type HistogramMiddleware struct {
    latencyTracker     *RequestLatencyTracker
    sizeTracker        *prometheus.HistogramVec
    concurrencyGauge   *prometheus.GaugeVec
    throughputCounter  *prometheus.CounterVec
    errorCounter       *prometheus.CounterVec
    
    // ã€é«˜åº¦ãªç›£è¦–æ©Ÿèƒ½ã€‘
    responseTimeBySize *prometheus.HistogramVec
    userAgentTracker   *prometheus.CounterVec
    geolocationTracker *prometheus.CounterVec
    
    // ã€å®Ÿè¡Œæ™‚è¨­å®šã€‘
    config             *MiddlewareConfig
    rateLimiter        *RateLimiter
    alertManager       *AlertManager
}

// ã€ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢è¨­å®šã€‘æŸ”è»Ÿãªå‹•ä½œåˆ¶å¾¡
type MiddlewareConfig struct {
    SampleRate         float64       `json:"sample_rate"`         // ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡
    SlowThreshold      time.Duration `json:"slow_threshold"`      // é…ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®é–¾å€¤
    LargeRequestSize   int64         `json:"large_request_size"`  // å¤§ããªãƒªã‚¯ã‚¨ã‚¹ãƒˆã®é–¾å€¤
    EnableGeoTracking  bool          `json:"enable_geo_tracking"`  // åœ°ç†çš„ä½ç½®è¿½è·¡
    EnableUserAgent    bool          `json:"enable_user_agent"`    // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¿½è·¡
    MaxConcurrency     int           `json:"max_concurrency"`      // æœ€å¤§åŒæ™‚å®Ÿè¡Œæ•°
    AlertThresholds    AlertThresholds `json:"alert_thresholds"`   // ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤
}

// ã€ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤è¨­å®šã€‘
type AlertThresholds struct {
    ErrorRate        float64 `json:"error_rate"`          // ã‚¨ãƒ©ãƒ¼ç‡ (0.0-1.0)
    P95Latency       float64 `json:"p95_latency"`         // P95ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (seconds)
    P99Latency       float64 `json:"p99_latency"`         // P99ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (seconds)
    Throughput       float64 `json:"throughput"`          // ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ (req/sec)
    ConcurrencyLimit int     `json:"concurrency_limit"`   // åŒæ™‚å®Ÿè¡Œæ•°åˆ¶é™
}

func NewHistogramMiddleware(config *MiddlewareConfig) *HistogramMiddleware {
    if config == nil {
        config = &MiddlewareConfig{
            SampleRate:       1.0,
            SlowThreshold:    500 * time.Millisecond,
            LargeRequestSize: 1024 * 1024, // 1MB
            EnableGeoTracking: false,
            EnableUserAgent:   true,
            MaxConcurrency:    1000,
        }
    }
    
    return &HistogramMiddleware{
        latencyTracker: NewRequestLatencyTracker(config.SlowThreshold),
        
        sizeTracker: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name: "http_request_size_bytes",
                Help: "Size of HTTP requests in bytes",
                // ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚µã‚¤ã‚ºç‰¹åŒ–ãƒã‚±ãƒƒãƒˆã€‘
                Buckets: []float64{
                    64,     // 64B: å°ã•ãªGET request
                    256,    // 256B: ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»˜ãGET
                    1024,   // 1KB: å°ã•ãªJSON payload
                    4096,   // 4KB: ä¸­ç¨‹åº¦ã®JSON payload
                    16384,  // 16KB: å¤§ããªJSON payload
                    65536,  // 64KB: éå¸¸ã«å¤§ããªJSON payload
                    262144, // 256KB: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                    1048576, // 1MB: å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                    4194304, // 4MB: éå¸¸ã«å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«
                },
            },
            []string{"method", "endpoint", "content_type"},
        ),
        
        concurrencyGauge: prometheus.NewGaugeVec(
            prometheus.GaugeOpts{
                Name: "http_requests_in_flight",
                Help: "Number of HTTP requests currently being processed",
            },
            []string{"endpoint", "method"},
        ),
        
        throughputCounter: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "http_requests_per_second",
                Help: "HTTP requests per second",
            },
            []string{"method", "endpoint"},
        ),
        
        errorCounter: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "http_request_errors_total",
                Help: "Total number of HTTP request errors",
            },
            []string{"method", "endpoint", "error_type"},
        ),
        
        // ã€é«˜åº¦ãªåˆ†æç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€‘
        responseTimeBySize: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name: "http_response_time_by_size_seconds",
                Help: "HTTP response time grouped by request size",
                Buckets: prometheus.DefBuckets,
            },
            []string{"size_category"}, // small, medium, large, xlarge
        ),
        
        userAgentTracker: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "http_requests_by_user_agent",
                Help: "HTTP requests grouped by user agent type",
            },
            []string{"user_agent_type"}, // browser, mobile, bot, api
        ),
        
        geolocationTracker: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "http_requests_by_location",
                Help: "HTTP requests grouped by geographic location",
            },
            []string{"country", "region"},
        ),
        
        config: config,
    }
}

// ã€åŒ…æ‹¬çš„ãƒªã‚¯ã‚¨ã‚¹ãƒˆç›£è¦–ã€‘å¤šæ¬¡å…ƒãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
func (m *HistogramMiddleware) Middleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()
        endpoint := r.URL.Path
        method := r.Method
        
        // ã€STEP 1ã€‘ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°åˆ¤å®š
        if rand.Float64() > m.config.SampleRate {
            next.ServeHTTP(w, r)
            return
        }
        
        // ã€STEP 2ã€‘åŒæ™‚å®Ÿè¡Œæ•°åˆ¶é™ãƒã‚§ãƒƒã‚¯
        currentConcurrency := m.getCurrentConcurrency(endpoint, method)
        if currentConcurrency >= m.config.MaxConcurrency {
            http.Error(w, "Too Many Requests", http.StatusTooManyRequests)
            m.errorCounter.WithLabelValues(method, endpoint, "concurrency_limit").Inc()
            return
        }
        
        // ã€STEP 3ã€‘åŒæ™‚å®Ÿè¡Œæ•°è¿½è·¡
        m.concurrencyGauge.WithLabelValues(endpoint, method).Inc()
        defer m.concurrencyGauge.WithLabelValues(endpoint, method).Dec()
        
        // ã€STEP 4ã€‘ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚µã‚¤ã‚ºåˆ†æ
        requestSize := r.ContentLength
        if requestSize > 0 {
            contentType := r.Header.Get("Content-Type")
            if contentType == "" {
                contentType = "unknown"
            }
            m.sizeTracker.WithLabelValues(method, endpoint, contentType).Observe(float64(requestSize))
        }
        
        // ã€STEP 5ã€‘ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æ
        if m.config.EnableUserAgent {
            userAgentType := m.classifyUserAgent(r.Header.Get("User-Agent"))
            m.userAgentTracker.WithLabelValues(userAgentType).Inc()
        }
        
        // ã€STEP 6ã€‘åœ°ç†çš„ä½ç½®åˆ†æ
        if m.config.EnableGeoTracking {
            country, region := m.getGeolocation(r)
            if country != "" {
                m.geolocationTracker.WithLabelValues(country, region).Inc()
            }
        }
        
        // ã€STEP 7ã€‘ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ©ã‚¤ã‚¿ãƒ¼æ‹¡å¼µ
        ww := &enhancedResponseWriter{
            ResponseWriter: w,
            statusCode:     http.StatusOK,
            bytesWritten:   0,
        }
        
        // ã€STEP 8ã€‘ã‚¨ãƒ©ãƒ¼å‡¦ç†ä»˜ããƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œ
        defer func() {
            if err := recover(); err != nil {
                log.Printf("ğŸ’¥ Panic in request %s %s: %v", method, endpoint, err)
                m.errorCounter.WithLabelValues(method, endpoint, "panic").Inc()
                http.Error(w, "Internal Server Error", http.StatusInternalServerError)
            }
        }()
        
        // ã€STEP 9ã€‘å®Ÿéš›ã®å‡¦ç†å®Ÿè¡Œ
        next.ServeHTTP(ww, r)
        
        // ã€STEP 10ã€‘åŒ…æ‹¬çš„ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
        duration := time.Since(start)
        m.recordComprehensiveMetrics(method, endpoint, ww.statusCode, duration, requestSize, ww.bytesWritten, r)
    })
}

// ã€åŒ…æ‹¬çš„ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ã€‘å…¨æ¬¡å…ƒã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
func (m *HistogramMiddleware) recordComprehensiveMetrics(method, endpoint string, statusCode int, duration time.Duration, requestSize int64, responseSize int64, r *http.Request) {
    // ã€åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€‘
    userType := m.determineUserType(r)
    m.latencyTracker.TrackRequest(method, endpoint, statusCode, duration, requestSize, userType)
    
    // ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨˜éŒ²ã€‘
    m.throughputCounter.WithLabelValues(method, endpoint).Inc()
    
    // ã€ã‚¨ãƒ©ãƒ¼åˆ†æã€‘
    if statusCode >= 400 {
        errorType := m.classifyError(statusCode)
        m.errorCounter.WithLabelValues(method, endpoint, errorType).Inc()
    }
    
    // ã€ã‚µã‚¤ã‚ºåˆ¥ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“åˆ†æã€‘
    sizeCategory := m.categorizeSizeCategory(requestSize)
    m.responseTimeBySize.WithLabelValues(sizeCategory).Observe(duration.Seconds())
    
    // ã€è©³ç´°ãƒ­ã‚°ã€‘é‡è¦ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹
    if duration > m.config.SlowThreshold {
        log.Printf("â° Slow request: %s %s took %v (size: %d bytes, response: %d bytes)", 
            method, endpoint, duration, requestSize, responseSize)
    }
    
    if requestSize > m.config.LargeRequestSize {
        log.Printf("ğŸ“¦ Large request: %s %s size %d bytes took %v", 
            method, endpoint, requestSize, duration)
    }
}

// ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†é¡ã€‘ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç¨®åˆ¥ã®åˆ¤å®š
func (m *HistogramMiddleware) classifyUserAgent(userAgent string) string {
    userAgent = strings.ToLower(userAgent)
    
    switch {
    case strings.Contains(userAgent, "bot") || strings.Contains(userAgent, "crawler") || strings.Contains(userAgent, "spider"):
        return "bot"
    case strings.Contains(userAgent, "mobile") || strings.Contains(userAgent, "iphone") || strings.Contains(userAgent, "android"):
        return "mobile"
    case strings.Contains(userAgent, "curl") || strings.Contains(userAgent, "wget") || strings.Contains(userAgent, "postman"):
        return "api"
    case strings.Contains(userAgent, "chrome") || strings.Contains(userAgent, "firefox") || strings.Contains(userAgent, "safari"):
        return "browser"
    default:
        return "unknown"
    }
}

// ã€åœ°ç†çš„ä½ç½®å–å¾—ã€‘IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‹ã‚‰ã®ä½ç½®æƒ…å ±æ¨å®š
func (m *HistogramMiddleware) getGeolocation(r *http.Request) (country, region string) {
    // ã€å®Ÿè£…ä¾‹ã€‘å®Ÿéš›ã®å®Ÿè£…ã§ã¯ GeoIP ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨
    clientIP := m.getClientIP(r)
    
    // ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼å®Ÿè£…
    // å®Ÿéš›ã®å®Ÿè£…ã§ã¯ MaxMind GeoIP2 ã‚„é¡ä¼¼ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨
    if strings.HasPrefix(clientIP, "192.168.") || strings.HasPrefix(clientIP, "10.") {
        return "private", "internal"
    }
    
    // ç°¡æ˜“çš„ãªåˆ¤å®šä¾‹
    return "unknown", "unknown"
}

// ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¨®åˆ¥åˆ¤å®šã€‘èªè¨¼æƒ…å ±ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®š
func (m *HistogramMiddleware) determineUserType(r *http.Request) string {
    // ã€å®Ÿè£…ä¾‹ã€‘å®Ÿéš›ã®å®Ÿè£…ã§ã¯èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã‚„ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä½¿ç”¨
    authHeader := r.Header.Get("Authorization")
    if authHeader == "" {
        return "guest"
    }
    
    // JWT ãƒˆãƒ¼ã‚¯ãƒ³ã®è§£æã‚„ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã®ç¢ºèª
    // ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼å®Ÿè£…
    if strings.Contains(authHeader, "premium") {
        return "premium"
    }
    
    return "standard"
}

// ã€ã‚¨ãƒ©ãƒ¼åˆ†é¡ã€‘HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã®è©³ç´°åˆ†é¡
func (m *HistogramMiddleware) classifyError(statusCode int) string {
    switch {
    case statusCode >= 400 && statusCode < 500:
        switch statusCode {
        case 401:
            return "unauthorized"
        case 403:
            return "forbidden"
        case 404:
            return "not_found"
        case 429:
            return "rate_limit"
        default:
            return "client_error"
        }
    case statusCode >= 500:
        switch statusCode {
        case 500:
            return "internal_error"
        case 502:
            return "bad_gateway"
        case 503:
            return "service_unavailable"
        case 504:
            return "gateway_timeout"
        default:
            return "server_error"
        }
    default:
        return "unknown"
    }
}

// ã€ã‚µã‚¤ã‚ºã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã€‘ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚µã‚¤ã‚ºã®åˆ†é¡
func (m *HistogramMiddleware) categorizeSizeCategory(size int64) string {
    switch {
    case size < 1024:
        return "small"   // < 1KB
    case size < 65536:
        return "medium"  // 1KB - 64KB
    case size < 1048576:
        return "large"   // 64KB - 1MB
    default:
        return "xlarge"  // > 1MB
    }
}

// ã€ç¾åœ¨ã®åŒæ™‚å®Ÿè¡Œæ•°å–å¾—ã€‘è² è·åˆ¶å¾¡ç”¨
func (m *HistogramMiddleware) getCurrentConcurrency(endpoint, method string) int {
    // ã€å®Ÿè£…ä¾‹ã€‘å®Ÿéš›ã®å®Ÿè£…ã§ã¯ Prometheus metrics ã‹ã‚‰å–å¾—
    // ã“ã“ã§ã¯ç°¡æ˜“çš„ãªå®Ÿè£…
    return 0
}

// ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆIPå–å¾—ã€‘ãƒ—ãƒ­ã‚­ã‚·ç’°å¢ƒå¯¾å¿œ
func (m *HistogramMiddleware) getClientIP(r *http.Request) string {
    // X-Forwarded-For, X-Real-IP, RemoteAddr ã®é †ã§ç¢ºèª
    if xff := r.Header.Get("X-Forwarded-For"); xff != "" {
        return strings.Split(xff, ",")[0]
    }
    if xri := r.Header.Get("X-Real-IP"); xri != "" {
        return xri
    }
    return strings.Split(r.RemoteAddr, ":")[0]
}

// ã€æ‹¡å¼µãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ©ã‚¤ã‚¿ãƒ¼ã€‘è©³ç´°ãªå¿œç­”æƒ…å ±è¿½è·¡
type enhancedResponseWriter struct {
    http.ResponseWriter
    statusCode   int
    bytesWritten int64
}

func (rw *enhancedResponseWriter) WriteHeader(code int) {
    rw.statusCode = code
    rw.ResponseWriter.WriteHeader(code)
}

func (rw *enhancedResponseWriter) Write(b []byte) (int, error) {
    n, err := rw.ResponseWriter.Write(b)
    rw.bytesWritten += int64(n)
    return n, err
}
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ

#### 1. ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·åˆ†æå™¨

```go
type LatencyAnalyzer struct {
    tracker *RequestLatencyTracker
}

func (a *LatencyAnalyzer) AnalyzePerformance() PerformanceReport {
    // ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’å–å¾—
    metricFamilies, err := prometheus.DefaultGatherer.Gather()
    if err != nil {
        return PerformanceReport{}
    }
    
    report := PerformanceReport{
        Timestamp: time.Now(),
        Endpoints: make([]EndpointPerformance, 0),
    }
    
    for _, mf := range metricFamilies {
        if mf.GetName() == "http_request_duration_seconds" {
            report.Endpoints = a.analyzeHistogramMetrics(mf)
        }
    }
    
    return report
}

func (a *LatencyAnalyzer) analyzeHistogramMetrics(mf *dto.MetricFamily) []EndpointPerformance {
    endpointStats := make(map[string]*EndpointPerformance)
    
    for _, metric := range mf.GetMetric() {
        labels := make(map[string]string)
        for _, label := range metric.GetLabel() {
            labels[label.GetName()] = label.GetValue()
        }
        
        endpoint := labels["endpoint"]
        if endpoint == "" {
            continue
        }
        
        if _, exists := endpointStats[endpoint]; !exists {
            endpointStats[endpoint] = &EndpointPerformance{
                Endpoint: endpoint,
                Buckets:  make([]BucketData, 0),
            }
        }
        
        hist := metric.GetHistogram()
        endpointStats[endpoint].Count = hist.GetSampleCount()
        endpointStats[endpoint].Sum = hist.GetSampleSum()
        
        if endpointStats[endpoint].Count > 0 {
            endpointStats[endpoint].Average = endpointStats[endpoint].Sum / float64(endpointStats[endpoint].Count)
        }
        
        // ãƒã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
        for _, bucket := range hist.GetBucket() {
            endpointStats[endpoint].Buckets = append(endpointStats[endpoint].Buckets, BucketData{
                UpperBound: bucket.GetUpperBound(),
                Count:      bucket.GetCumulativeCount(),
            })
        }
        
        // ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®—
        endpointStats[endpoint].P50 = a.calculatePercentile(endpointStats[endpoint].Buckets, 0.5, endpointStats[endpoint].Count)
        endpointStats[endpoint].P95 = a.calculatePercentile(endpointStats[endpoint].Buckets, 0.95, endpointStats[endpoint].Count)
        endpointStats[endpoint].P99 = a.calculatePercentile(endpointStats[endpoint].Buckets, 0.99, endpointStats[endpoint].Count)
    }
    
    // ãƒãƒƒãƒ—ã‚’ã‚¹ãƒ©ã‚¤ã‚¹ã«å¤‰æ›
    result := make([]EndpointPerformance, 0, len(endpointStats))
    for _, ep := range endpointStats {
        result = append(result, *ep)
    }
    
    return result
}

func (a *LatencyAnalyzer) calculatePercentile(buckets []BucketData, percentile float64, totalCount uint64) float64 {
    if len(buckets) == 0 || totalCount == 0 {
        return 0
    }
    
    targetCount := float64(totalCount) * percentile
    var prevBound float64 = 0
    var prevCount uint64 = 0
    
    for _, bucket := range buckets {
        if float64(bucket.Count) >= targetCount {
            // ç·šå½¢è£œé–“ã§ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«å€¤ã‚’è¨ˆç®—
            if bucket.Count == prevCount {
                return prevBound
            }
            
            ratio := (targetCount - float64(prevCount)) / float64(bucket.Count-prevCount)
            return prevBound + ratio*(bucket.UpperBound-prevBound)
        }
        
        prevBound = bucket.UpperBound
        prevCount = bucket.Count
    }
    
    return buckets[len(buckets)-1].UpperBound
}

type PerformanceReport struct {
    Timestamp time.Time             `json:"timestamp"`
    Endpoints []EndpointPerformance `json:"endpoints"`
}

type EndpointPerformance struct {
    Endpoint string       `json:"endpoint"`
    Count    uint64       `json:"count"`
    Sum      float64      `json:"sum"`
    Average  float64      `json:"average"`
    P50      float64      `json:"p50"`
    P95      float64      `json:"p95"`
    P99      float64      `json:"p99"`
    Buckets  []BucketData `json:"buckets"`
}

type BucketData struct {
    UpperBound float64 `json:"upper_bound"`
    Count      uint64  `json:"count"`
}
```

#### 2. ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ 

```go
type AlertingSystem struct {
    tracker    *RequestLatencyTracker
    thresholds map[string]LatencyThreshold
    alertCh    chan Alert
}

type LatencyThreshold struct {
    P95Threshold float64 `json:"p95_threshold"`
    P99Threshold float64 `json:"p99_threshold"`
    ErrorRate    float64 `json:"error_rate"`
}

type Alert struct {
    Type         string    `json:"type"`
    Endpoint     string    `json:"endpoint"`
    Message      string    `json:"message"`
    Severity     string    `json:"severity"`
    Timestamp    time.Time `json:"timestamp"`
    CurrentValue float64   `json:"current_value"`
    Threshold    float64   `json:"threshold"`
}

func NewAlertingSystem(tracker *RequestLatencyTracker) *AlertingSystem {
    return &AlertingSystem{
        tracker:    tracker,
        thresholds: make(map[string]LatencyThreshold),
        alertCh:    make(chan Alert, 100),
    }
}

func (as *AlertingSystem) SetThreshold(endpoint string, threshold LatencyThreshold) {
    as.thresholds[endpoint] = threshold
}

func (as *AlertingSystem) StartMonitoring(ctx context.Context) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            as.checkThresholds()
        }
    }
}

func (as *AlertingSystem) checkThresholds() {
    analyzer := &LatencyAnalyzer{tracker: as.tracker}
    report := analyzer.AnalyzePerformance()
    
    for _, ep := range report.Endpoints {
        if threshold, exists := as.thresholds[ep.Endpoint]; exists {
            // P95ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒã‚§ãƒƒã‚¯
            if ep.P95 > threshold.P95Threshold {
                alert := Alert{
                    Type:         "latency_p95",
                    Endpoint:     ep.Endpoint,
                    Message:      "P95 latency exceeds threshold",
                    Severity:     "warning",
                    Timestamp:    time.Now(),
                    CurrentValue: ep.P95,
                    Threshold:    threshold.P95Threshold,
                }
                
                select {
                case as.alertCh <- alert:
                    log.Printf("Alert: P95 latency for %s is %.3fs (threshold: %.3fs)", 
                        ep.Endpoint, ep.P95, threshold.P95Threshold)
                default:
                    log.Printf("Alert channel full, dropping alert")
                }
            }
            
            // P99ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒã‚§ãƒƒã‚¯
            if ep.P99 > threshold.P99Threshold {
                alert := Alert{
                    Type:         "latency_p99",
                    Endpoint:     ep.Endpoint,
                    Message:      "P99 latency exceeds threshold",
                    Severity:     "critical",
                    Timestamp:    time.Now(),
                    CurrentValue: ep.P99,
                    Threshold:    threshold.P99Threshold,
                }
                
                select {
                case as.alertCh <- alert:
                    log.Printf("CRITICAL: P99 latency for %s is %.3fs (threshold: %.3fs)", 
                        ep.Endpoint, ep.P99, threshold.P99Threshold)
                default:
                    log.Printf("Alert channel full, dropping critical alert")
                }
            }
        }
    }
}

func (as *AlertingSystem) GetAlerts() <-chan Alert {
    return as.alertCh
}
```

### Grafanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å¯¾å¿œ

#### 1. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨­è¨ˆ

```go
type GrafanaMetrics struct {
    // ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    RequestDuration *prometheus.HistogramVec
    
    // ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚«ã‚¦ãƒ³ã‚¿ãƒ¼  
    RequestsTotal *prometheus.CounterVec
    
    // ã‚¨ãƒ©ãƒ¼ç‡ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    ErrorsTotal *prometheus.CounterVec
    
    // è¿½åŠ ã®åˆ†æç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    SlowRequests    *prometheus.CounterVec  // é–¾å€¤ã‚’è¶…ãˆã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    RequestSize     *prometheus.HistogramVec // ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚µã‚¤ã‚ºåˆ†å¸ƒ
    ResponseSize    *prometheus.HistogramVec // ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚µã‚¤ã‚ºåˆ†å¸ƒ
}

func NewGrafanaMetrics() *GrafanaMetrics {
    return &GrafanaMetrics{
        RequestDuration: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name: "http_request_duration_seconds",
                Help: "HTTP request duration in seconds",
                Buckets: []float64{0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0},
            },
            []string{"method", "endpoint", "status_class"},
        ),
        RequestsTotal: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "http_requests_total",
                Help: "Total number of HTTP requests",
            },
            []string{"method", "endpoint", "status"},
        ),
        ErrorsTotal: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "http_errors_total",
                Help: "Total number of HTTP errors",
            },
            []string{"method", "endpoint", "status"},
        ),
        SlowRequests: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "http_slow_requests_total",
                Help: "Total number of slow HTTP requests",
            },
            []string{"method", "endpoint", "threshold"},
        ),
        RequestSize: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name: "http_request_size_bytes",
                Help: "HTTP request size in bytes",
                Buckets: prometheus.ExponentialBuckets(64, 4, 8),
            },
            []string{"method", "endpoint"},
        ),
        ResponseSize: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name: "http_response_size_bytes", 
                Help: "HTTP response size in bytes",
                Buckets: prometheus.ExponentialBuckets(64, 4, 8),
            },
            []string{"method", "endpoint", "status_class"},
        ),
    }
}
```

#### 2. PromQL ã‚¯ã‚¨ãƒªä¾‹

```promql
# 95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼ˆ5åˆ†é–“ï¼‰
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåˆ¥ã®95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
histogram_quantile(0.95, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint)
)

# SLI: 100msä»¥å†…ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‰²åˆ
sum(rate(http_request_duration_seconds_bucket{le="0.1"}[5m])) 
/ 
sum(rate(http_request_duration_seconds_count[5m]))

# ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆï¼ˆRPSï¼‰
sum(rate(http_requests_total[5m]))

# ã‚¨ãƒ©ãƒ¼ç‡
sum(rate(http_errors_total[5m])) 
/ 
sum(rate(http_requests_total[5m]))

# å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“
rate(http_request_duration_seconds_sum[5m]) 
/ 
rate(http_request_duration_seconds_count[5m])
```

## ğŸ“ èª²é¡Œ (The Problem)

ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æŒã¤Prometheusãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š

### 1. ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒˆãƒ©ãƒƒã‚«ãƒ¼

```go
type RequestLatencyTracker struct {
    histogram *prometheus.HistogramVec
}
```

### 2. å¿…è¦ãªæ©Ÿèƒ½

- **å¤šæ¬¡å…ƒãƒ¡ãƒˆãƒªã‚¯ã‚¹**: method, endpoint, status ã«ã‚ˆã‚‹åˆ†é¡
- **é©åˆ‡ãªãƒã‚±ãƒƒãƒˆè¨­è¨ˆ**: Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«é©ã—ãŸãƒã‚±ãƒƒãƒˆå¢ƒç•Œ
- **è‡ªå‹•åé›†ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢**: HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã®è‡ªå‹•ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ**: ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®—ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
- **ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ **: é–¾å€¤ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½

### 3. ãƒ¬ãƒãƒ¼ãƒˆæ©Ÿèƒ½

- ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåˆ¥ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
- P50/P95/P99ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã®è¨ˆç®—
- å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®ç®—å‡º
- ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆåˆ†æ

### 4. ç›£è¦–æ©Ÿèƒ½

- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆ
- é–¾å€¤è¶…éã®æ¤œå‡º
- ã‚¢ãƒ©ãƒ¼ãƒˆå±¥æ­´ã®ç®¡ç†

## âœ… æœŸå¾…ã•ã‚Œã‚‹æŒ™å‹• (Expected Behavior)

å®Ÿè£…ãŒæ­£ã—ãå®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ†ã‚¹ãƒˆçµæœãŒå¾—ã‚‰ã‚Œã¾ã™ï¼š

```bash
$ go test -v
=== RUN   TestHistogram_BasicObservation
    main_test.go:45: Histogram observation recorded correctly
--- PASS: TestHistogram_BasicObservation (0.01s)

=== RUN   TestHistogram_MultipleObservations
    main_test.go:65: Multiple observations recorded correctly
    main_test.go:68: Bucket distribution is accurate
--- PASS: TestHistogram_MultipleObservations (0.01s)

=== RUN   TestPercentileCalculation
    main_test.go:85: P50: 0.250s, P95: 0.950s, P99: 0.990s
--- PASS: TestPercentileCalculation (0.02s)

=== RUN   TestAlertingSystem
    main_test.go:105: Alert triggered for P95 threshold violation
--- PASS: TestAlertingSystem (0.05s)

PASS
ok      day58-prometheus-histogram   0.156s
```

### ãƒ¡ãƒˆãƒªã‚¯ã‚¹å‡ºåŠ›ä¾‹

```
# HELP http_request_duration_seconds Time spent on HTTP requests
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",status_class="2xx",le="0.001"} 45
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",status_class="2xx",le="0.005"} 250
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",status_class="2xx",le="0.01"} 500
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",status_class="2xx",le="0.025"} 800
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",status_class="2xx",le="0.05"} 950
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",status_class="2xx",le="0.1"} 990
http_request_duration_seconds_bucket{method="GET",endpoint="/api/users",status_class="2xx",le="+Inf"} 1000
http_request_duration_seconds_sum{method="GET",endpoint="/api/users",status_class="2xx"} 15.5
http_request_duration_seconds_count{method="GET",endpoint="/api/users",status_class="2xx"} 1000
```

## ğŸ’¡ ãƒ’ãƒ³ãƒˆ (Hints)

å®Ÿè£…ã«è©°ã¾ã£ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®ãƒ’ãƒ³ãƒˆã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š

### åŸºæœ¬çš„ãªãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å®Ÿè£…

```go
func NewRequestLatencyTracker() *RequestLatencyTracker {
    return &RequestLatencyTracker{
        histogram: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name: "http_request_duration_seconds",
                Help: "Time spent on HTTP requests",
                Buckets: []float64{
                    0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0,
                },
            },
            []string{"method", "endpoint", "status_class"},
        ),
    }
}
```

### ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®—

```go
func calculatePercentile(buckets []BucketData, percentile float64, totalCount uint64) float64 {
    if len(buckets) == 0 || totalCount == 0 {
        return 0
    }
    
    targetCount := float64(totalCount) * percentile
    var prevBound float64 = 0
    var prevCount uint64 = 0
    
    for _, bucket := range buckets {
        if float64(bucket.Count) >= targetCount {
            if bucket.Count == prevCount {
                return prevBound
            }
            
            ratio := (targetCount - float64(prevCount)) / float64(bucket.Count-prevCount)
            return prevBound + ratio*(bucket.UpperBound-prevBound)
        }
        
        prevBound = bucket.UpperBound
        prevCount = bucket.Count
    }
    
    return buckets[len(buckets)-1].UpperBound
}
```

### ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢å®Ÿè£…

```go
func (t *RequestLatencyTracker) Middleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()
        ww := &responseWriter{ResponseWriter: w, statusCode: http.StatusOK}
        
        next.ServeHTTP(ww, r)
        
        duration := time.Since(start)
        statusClass := fmt.Sprintf("%dxx", ww.statusCode/100)
        
        t.histogram.WithLabelValues(r.Method, r.URL.Path, statusClass).Observe(duration.Seconds())
    })
}
```

## ğŸš€ ç™ºå±•èª²é¡Œ (Advanced Challenges)

åŸºæœ¬å®Ÿè£…ãŒå®Œäº†ã—ãŸã‚‰ã€ä»¥ä¸‹ã®ç™ºå±•çš„ãªæ©Ÿèƒ½ã«ã‚‚ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ã¦ã¿ã¦ãã ã•ã„ï¼š

1. **å‹•çš„ãƒã‚±ãƒƒãƒˆèª¿æ•´**: è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ããƒã‚±ãƒƒãƒˆå¢ƒç•Œã®æœ€é©åŒ–
2. **è¤‡æ•°æ™‚é–“è»¸åˆ†æ**: çŸ­æœŸ/ä¸­æœŸ/é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã®æ¯”è¼ƒ
3. **ç•°å¸¸æ¤œçŸ¥**: çµ±è¨ˆçš„æ‰‹æ³•ã«ã‚ˆã‚‹ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
4. **å®¹é‡è¨ˆç”»**: æˆé•·äºˆæ¸¬ã¨ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°
5. **ã‚³ã‚¹ãƒˆåˆ†æ**: ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ã‚³ã‚¹ãƒˆã®è©³ç´°åˆ†æ

Prometheusãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®å®Ÿè£…ã‚’é€šã˜ã¦ã€é«˜åº¦ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰æ‰‹æ³•ã‚’ç¿’å¾—ã—ã¾ã—ã‚‡ã†ï¼