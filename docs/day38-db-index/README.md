# Day 38: DBã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–ã¨ã‚¯ã‚¨ãƒªåˆ†æ

## ğŸ¯ æœ¬æ—¥ã®ç›®æ¨™

ã“ã®ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã‚’é€šã—ã¦ã€ä»¥ä¸‹ã®ã‚¹ã‚­ãƒ«ã‚’èº«ã«ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼š

- **EXPLAINã‚’ä½¿ã£ãŸã‚¯ã‚¨ãƒªå®Ÿè¡Œè¨ˆç”»ã®è©³ç´°åˆ†æãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹**
- **ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥ã®ç«‹æ¡ˆã¨åŠ¹æœæ¸¬å®šã‚’å®Ÿè·µã§ãã‚‹ã‚ˆã†ã«ãªã‚‹**
- **ã‚¯ã‚¨ãƒªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®šã¨æ”¹å–„ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹**
- **ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã§ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é‹ç”¨ç®¡ç†ã‚’ãƒã‚¹ã‚¿ãƒ¼ã™ã‚‹**

## ğŸ“– è§£èª¬

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã¯ä½•ã‹ï¼Ÿ

```go
// ã€DBã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–ã®é‡è¦æ€§ã€‘å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç”Ÿæ­»ã‚’åˆ†ã‘ã‚‹æŠ€è¡“
// âŒ å•é¡Œä¾‹ï¼šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­è¨ˆãƒŸã‚¹ã«ã‚ˆã‚‹æœ¬ç•ªã‚·ã‚¹ãƒ†ãƒ å®Œå…¨åœæ­¢ã¨æ¥­å‹™éº»ç—º
func catastrophicIndexMismanagement() {
    // ğŸš¨ ç½å®³ä¾‹ï¼šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸å‚™ã«ã‚ˆã‚‹å£Šæ»…çš„ã‚·ã‚¹ãƒ†ãƒ éšœå®³ã¨ãƒ“ã‚¸ãƒã‚¹åœæ­¢
    
    // âŒ æœ€æ‚ªã®ãƒ†ãƒ¼ãƒ–ãƒ«è¨­è¨ˆï¼š1å„„ä»¶ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã§ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åœ°ç„
    /*
    CREATE TABLE users (
        id SERIAL PRIMARY KEY,           -- å”¯ä¸€ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        email VARCHAR(255),              -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ï¼
        username VARCHAR(100),           -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ï¼
        phone VARCHAR(20),               -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ï¼
        created_at TIMESTAMP,            -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ï¼
        last_login TIMESTAMP,            -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ï¼
        profile_data JSONB,              -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ï¼
        tags TEXT[]                      -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ï¼
    );
    
    -- 100,000,000è¡Œã®ãƒ‡ãƒ¼ã‚¿ãŒæ—¢ã«å­˜åœ¨
    */
    
    // âŒ ç½å®³çš„ã‚¯ã‚¨ãƒª1ï¼šãƒ¡ãƒ¼ãƒ«æ¤œç´¢ã§å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ£ãƒ³
    func LoginByEmailDisaster(db *sql.DB, email string) (*User, error) {
        query := `
            SELECT id, email, username, profile_data 
            FROM users 
            WHERE email = $1  -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ï¼
        `
        
        // ã€ç½å®³çš„å®Ÿè¡Œè¨ˆç”»ã€‘
        // Seq Scan on users (cost=0.00..2500000.00 rows=1 width=256)
        //   Filter: (email = 'user@example.com')
        //   Rows Removed by Filter: 99999999
        //   Execution Time: 67834.521 ms (67ç§’ï¼)
        
        var user User
        err := db.QueryRow(query, email).Scan(&user.ID, &user.Email, &user.Username, &user.ProfileData)
        // çµæœï¼š1å›ã®ãƒ­ã‚°ã‚¤ãƒ³è©¦è¡Œã§67ç§’ã€å…¨ã‚·ã‚¹ãƒ†ãƒ å¿œç­”ä¸èƒ½
        return &user, err
    }
    
    // âŒ ç½å®³çš„ã‚¯ã‚¨ãƒª2ï¼šç¯„å›²æ¤œç´¢ã§å®Œå…¨æ­»äº¡
    func GetRecentActiveUsersDisaster(db *sql.DB) ([]*User, error) {
        query := `
            SELECT id, email, username, last_login
            FROM users 
            WHERE last_login >= NOW() - INTERVAL '7 days'  -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ï¼
            ORDER BY last_login DESC                        -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ï¼
            LIMIT 1000
        `
        
        // ã€ç½å®³çš„å®Ÿè¡Œè¨ˆç”»ã€‘
        // Sort (cost=3500000.00..3750000.00 rows=1000000 width=128)
        //   Sort Key: last_login DESC
        //   ->  Seq Scan on users (cost=0.00..2500000.00 rows=1000000 width=128)
        //         Filter: (last_login >= (now() - '7 days'::interval))
        //         Rows Removed by Filter: 99000000
        //   Execution Time: 123456.789 ms (123ç§’ï¼)
        
        rows, err := db.Query(query)
        if err != nil {
            return nil, err
        }
        defer rows.Close()
        
        var users []*User
        for rows.Next() {
            var user User
            err := rows.Scan(&user.ID, &user.Email, &user.Username, &user.LastLogin)
            if err != nil {
                continue
            }
            users = append(users, &user)
        }
        
        // çµæœï¼šç®¡ç†ç”»é¢ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡¨ç¤ºã«2åˆ†3ç§’ã€é‹ç”¨ãƒãƒ¼ãƒ æ¥­å‹™åœæ­¢
        return users, nil
    }
    
    // âŒ ç½å®³çš„ã‚¯ã‚¨ãƒª3ï¼šè¤‡åˆæ¡ä»¶ã§ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨å´©å£Š
    func SearchUsersDisaster(db *sql.DB, username string, startDate, endDate time.Time) ([]*User, error) {
        query := `
            SELECT u.id, u.email, u.username, u.created_at,
                   COUNT(o.id) as order_count
            FROM users u
            LEFT JOIN orders o ON u.id = o.user_id  -- orders.user_idã«ã‚‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ï¼
            WHERE u.username ILIKE $1               -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ï¼
            AND u.created_at BETWEEN $2 AND $3     -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ï¼
            GROUP BY u.id, u.email, u.username, u.created_at
            ORDER BY order_count DESC               -- è¨ˆç®—çµæœã®ã‚½ãƒ¼ãƒˆ
            LIMIT 100
        `
        
        // ã€ç½å®³çš„å®Ÿè¡Œè¨ˆç”»ã€‘
        // Sort (cost=15000000.00..15500000.00 rows=10000000 width=256)
        //   Sort Key: (count(o.id)) DESC
        //   ->  HashAggregate (cost=12000000.00..13000000.00 rows=10000000 width=256)
        //         Group Key: u.id, u.email, u.username, u.created_at
        //         ->  Hash Left Join (cost=5000000.00..10000000.00 rows=50000000 width=128)
        //               Hash Cond: (u.id = o.user_id)
        //               ->  Seq Scan on users u (cost=0.00..2500000.00 rows=1000000 width=64)
        //                     Filter: ((username ~~* $1) AND (created_at >= $2) AND (created_at <= $3))
        //                     Rows Removed by Filter: 99000000
        //               ->  Hash (cost=1500000.00..1500000.00 rows=50000000 width=8)
        //                     ->  Seq Scan on orders o (cost=0.00..1500000.00 rows=50000000 width=8)
        //   Execution Time: 456789.123 ms (456ç§’ = 7åˆ†36ç§’ï¼)
        
        rows, err := db.Query(query, username+"%", startDate, endDate)
        if err != nil {
            return nil, err
        }
        defer rows.Close()
        
        var users []*User
        for rows.Next() {
            var user User
            var orderCount int
            err := rows.Scan(&user.ID, &user.Email, &user.Username, &user.CreatedAt, &orderCount)
            if err != nil {
                continue
            }
            user.OrderCount = orderCount
            users = append(users, &user)
        }
        
        // çµæœï¼šç®¡ç†è€…ã®é¡§å®¢æ¤œç´¢ã«7åˆ†36ç§’ã€é¡§å®¢ã‚µãƒãƒ¼ãƒˆæ¥­å‹™å®Œå…¨åœæ­¢
        return users, nil
    }
    
    // ã€æœ¬ç•ªç’°å¢ƒã§ã®å®Ÿéš›ã®ç½å®³ã€‘
    // 1. ECã‚µã‚¤ãƒˆï¼šå•†å“æ¤œç´¢ã«5åˆ†â†’å£²ä¸Š80%æ¸›å°‘ã€é¡§å®¢é›¢è„±
    // 2. éŠ€è¡Œã‚·ã‚¹ãƒ†ãƒ ï¼šå£åº§æ®‹é«˜ç…§ä¼šã«3åˆ†â†’ATMå…¨å°åœæ­¢ã€é¡§å®¢è‹¦æƒ…æ®ºåˆ°
    // 3. åŒ»ç™‚ã‚·ã‚¹ãƒ†ãƒ ï¼šæ‚£è€…æ¤œç´¢ã«8åˆ†â†’è¨ºç™‚äºˆç´„ã‚·ã‚¹ãƒ†ãƒ éº»ç—ºã€ç—…é™¢æ¥­å‹™åœæ­¢
    // 4. ç‰©æµã‚·ã‚¹ãƒ†ãƒ ï¼šé…é€çŠ¶æ³ç¢ºèªã«4åˆ†â†’é…é€è¿½è·¡ä¸èƒ½ã€é¡§å®¢å¯¾å¿œç ´ç¶»
    
    // ã€é€£é–çš„è¢«å®³ã€‘
    // - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«æ¯æ¸‡
    // - ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒãƒ¼å¿œç­”ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    // - ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯å¤±æ•—
    // - å…¨ã‚·ã‚¹ãƒ†ãƒ ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢åˆ¤å®š
    // - ç·Šæ€¥äº‹æ…‹å®£è¨€ã€å…¨ç¤¾å¯¾ç­–æœ¬éƒ¨è¨­ç½®
    
    fmt.Println("âŒ Index disaster caused 7+ minute queries and complete business shutdown!")
    // çµæœï¼š1ã‚¯ã‚¨ãƒª456ç§’ã€å…¨ã‚·ã‚¹ãƒ†ãƒ åœæ­¢ã€æå¤±æ•°å„„å††
}

// âœ… æ­£è§£ï¼šã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç´šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
type EnterpriseIndexOptimizationSystem struct {
    // ã€åŸºæœ¬ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†ã€‘
    indexAnalyzer    *IndexAnalyzer           // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è§£æã‚¨ãƒ³ã‚¸ãƒ³
    queryOptimizer   *QueryOptimizer          // ã‚¯ã‚¨ãƒªæœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³
    explainParser    *ExplainParser           // EXPLAINçµæœãƒ‘ãƒ¼ã‚µãƒ¼
    
    // ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥ã€‘
    indexStrategy    *IndexStrategy           // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥ã‚¨ãƒ³ã‚¸ãƒ³
    coveringAnalyzer *CoveringIndexAnalyzer   // ã‚«ãƒãƒªãƒ³ã‚°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è§£æ
    compositeBuilder *CompositeIndexBuilder   // è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
    
    // ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã€‘
    performanceMonitor *PerformanceMonitor    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
    slowQueryDetector  *SlowQueryDetector     // ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªæ¤œå‡º
    indexUsageTracker  *IndexUsageTracker     // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨çŠ¶æ³è¿½è·¡
    
    // ã€è‡ªå‹•æœ€é©åŒ–ã€‘
    autoOptimizer     *AutoOptimizer          // è‡ªå‹•æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³
    recommendationEngine *RecommendationEngine // æ¨å¥¨ã‚¨ãƒ³ã‚¸ãƒ³
    impactAnalyzer    *ImpactAnalyzer         // å½±éŸ¿åº¦åˆ†æ
    
    // ã€ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã€‘
    maintenanceScheduler *MaintenanceScheduler // ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
    fragmentationAnalyzer *FragmentationAnalyzer // æ–­ç‰‡åŒ–è§£æ
    
    // ã€ãƒãƒ«ãƒç’°å¢ƒå¯¾å¿œã€‘
    environmentManager *EnvironmentManager     // ç’°å¢ƒç®¡ç†
    migrationPlanner   *MigrationPlanner       // ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨ˆç”»
    
    config           *IndexConfig             // è¨­å®šç®¡ç†
    mu               sync.RWMutex             // ä¸¦è¡Œã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡
}

// ã€é‡è¦é–¢æ•°ã€‘åŒ…æ‹¬çš„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
func NewEnterpriseIndexOptimizationSystem(config *IndexConfig) *EnterpriseIndexOptimizationSystem {
    return &EnterpriseIndexOptimizationSystem{
        config:                config,
        indexAnalyzer:         NewIndexAnalyzer(),
        queryOptimizer:        NewQueryOptimizer(),
        explainParser:         NewExplainParser(),
        indexStrategy:         NewIndexStrategy(),
        coveringAnalyzer:      NewCoveringIndexAnalyzer(),
        compositeBuilder:      NewCompositeIndexBuilder(),
        performanceMonitor:    NewPerformanceMonitor(),
        slowQueryDetector:     NewSlowQueryDetector(),
        indexUsageTracker:     NewIndexUsageTracker(),
        autoOptimizer:         NewAutoOptimizer(),
        recommendationEngine:  NewRecommendationEngine(),
        impactAnalyzer:        NewImpactAnalyzer(),
        maintenanceScheduler:  NewMaintenanceScheduler(),
        fragmentationAnalyzer: NewFragmentationAnalyzer(),
        environmentManager:    NewEnvironmentManager(),
        migrationPlanner:      NewMigrationPlanner(),
    }
}

// ã€å®Ÿç”¨ä¾‹ã€‘æœ€é©åŒ–ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 
func (eios *EnterpriseIndexOptimizationSystem) CreateOptimalIndexes(
    ctx context.Context,
    db *sql.DB,
) error {
    
    // ã€STEP 1ã€‘æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çŠ¶æ³åˆ†æ
    currentIndexes, err := eios.indexAnalyzer.AnalyzeCurrentIndexes(ctx, db)
    if err != nil {
        return fmt.Errorf("failed to analyze current indexes: %w", err)
    }
    
    // ã€STEP 2ã€‘ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    queryPatterns, err := eios.slowQueryDetector.AnalyzeQueryPatterns(ctx, db)
    if err != nil {
        return fmt.Errorf("failed to analyze query patterns: %w", err)
    }
    
    // ã€STEP 3ã€‘æœ€é©ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¨å¥¨
    recommendations := eios.recommendationEngine.GenerateIndexRecommendations(
        currentIndexes, queryPatterns)
    
    // ã€STEP 4ã€‘å½±éŸ¿åº¦åˆ†æã¨å®‰å…¨æ€§ç¢ºèª
    for _, recommendation := range recommendations {
        impact, err := eios.impactAnalyzer.AnalyzeImpact(ctx, db, recommendation)
        if err != nil {
            continue
        }
        
        if impact.RiskLevel > AcceptableRiskLevel {
            continue // é«˜ãƒªã‚¹ã‚¯ã¯ ã‚¹ã‚­ãƒƒãƒ—
        }
        
        // ã€STEP 5ã€‘æ®µéšçš„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        err = eios.createIndexSafely(ctx, db, recommendation)
        if err != nil {
            return fmt.Errorf("failed to create index %s: %w", recommendation.IndexName, err)
        }
    }
    
    return nil
}

// ã€æ ¸å¿ƒãƒ¡ã‚½ãƒƒãƒ‰ã€‘å®‰å…¨ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
func (eios *EnterpriseIndexOptimizationSystem) createIndexSafely(
    ctx context.Context,
    db *sql.DB,
    recommendation *IndexRecommendation,
) error {
    
    // ã€å®‰å…¨å¯¾ç­–1ã€‘CONCURRENTLY ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä½¿ç”¨
    createSQL := fmt.Sprintf(
        "CREATE INDEX CONCURRENTLY %s ON %s (%s)",
        recommendation.IndexName,
        recommendation.TableName,
        strings.Join(recommendation.Columns, ", "),
    )
    
    // ã€å®‰å…¨å¯¾ç­–2ã€‘ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
    ctxWithTimeout, cancel := context.WithTimeout(ctx, 30*time.Minute)
    defer cancel()
    
    // ã€å®‰å…¨å¯¾ç­–3ã€‘é€²æ—ç›£è¦–
    go eios.monitorIndexCreation(ctx, db, recommendation.IndexName)
    
    // ã€å®‰å…¨å¯¾ç­–4ã€‘ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Ÿè¡Œ
    _, err := db.ExecContext(ctxWithTimeout, createSQL)
    if err != nil {
        return fmt.Errorf("index creation failed: %w", err)
    }
    
    // ã€å®‰å…¨å¯¾ç­–5ã€‘ä½œæˆå¾Œæ¤œè¨¼
    isValid, err := eios.validateIndexCreation(ctx, db, recommendation.IndexName)
    if err != nil || !isValid {
        // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤
        dropSQL := fmt.Sprintf("DROP INDEX CONCURRENTLY %s", recommendation.IndexName)
        db.ExecContext(ctx, dropSQL)
        return fmt.Errorf("index validation failed, rolled back")
    }
    
    return nil
}

// ã€å®Ÿç”¨ä¾‹ã€‘æœ€é©åŒ–å¾Œã®ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
func OptimizedUserLogin(db *sql.DB, email string) (*User, error) {
    // äº‹å‰ä½œæˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: CREATE INDEX idx_users_email ON users(email);
    
    query := `
        SELECT id, email, username, profile_data 
        FROM users 
        WHERE email = $1  -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ’ãƒƒãƒˆï¼
    `
    
    // ã€æœ€é©åŒ–å¾Œå®Ÿè¡Œè¨ˆç”»ã€‘
    // Index Scan using idx_users_email on users (cost=0.43..8.45 rows=1 width=256)
    //   Index Cond: (email = 'user@example.com')
    //   Execution Time: 0.123 ms (0.123ãƒŸãƒªç§’ï¼)
    
    var user User
    err := db.QueryRow(query, email).Scan(&user.ID, &user.Email, &user.Username, &user.ProfileData)
    
    // ã€çµæœã€‘
    // - å¾“æ¥: 67ç§’ã®ãƒ•ãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ£ãƒ³
    // - æœ€é©åŒ–å¾Œ: 0.123ãƒŸãƒªç§’ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¤œç´¢
    // - æ”¹å–„ç‡: 544,715å€ã®é«˜é€ŸåŒ–
    
    return &user, err
}
```

ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç´ æ—©ããƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã®**ãƒ‡ãƒ¼ã‚¿æ§‹é€ **ã§ã™ã€‚è¾æ›¸ã®è¦‹å‡ºã—ã®ã‚ˆã†ã«ã€ãƒ‡ãƒ¼ã‚¿ã®ä½ç½®ã‚’åŠ¹ç‡çš„ã«ç‰¹å®šã§ãã¾ã™ã€‚

#### ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ã§ã®ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ã®å•é¡Œ

```go
// 1å„„ä»¶ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰emailã§æ¤œç´¢ã™ã‚‹å ´åˆ
// CREATE TABLE users (id SERIAL PRIMARY KEY, email VARCHAR(255), name VARCHAR(255), created_at TIMESTAMP);

func FindUserByEmailWithoutIndex(db *sql.DB, email string) (*User, error) {
    query := `
        SELECT id, email, name, created_at 
        FROM users 
        WHERE email = $1
    `
    // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒãªã„å ´åˆï¼š
    // - ãƒ†ãƒ¼ãƒ–ãƒ«å…¨ä½“ã‚’ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆSequential Scanï¼‰
    // - 1å„„ä»¶å…¨ã¦ã‚’ãƒã‚§ãƒƒã‚¯ = æ•°åç§’ã‹ã‹ã‚‹
    // - CPUã¨I/Oãƒªã‚½ãƒ¼ã‚¹ã‚’å¤§é‡æ¶ˆè²»
    
    var user User
    err := db.QueryRow(query, email).Scan(&user.ID, &user.Email, &user.Name, &user.CreatedAt)
    return &user, err
}
```

**å•é¡Œç‚¹ã®è©³ç´°åˆ†æï¼š**
- **æ™‚é–“è¨ˆç®—é‡**: O(n) - ãƒ‡ãƒ¼ã‚¿é‡ã«æ¯”ä¾‹ã—ã¦æ¤œç´¢æ™‚é–“ãŒå¢—åŠ 
- **I/Oè² è·**: å…¨ãƒ‡ãƒ¼ã‚¿ãƒ–ãƒ­ãƒƒã‚¯ã®èª­ã¿è¾¼ã¿ãŒå¿…è¦
- **ãƒªã‚½ãƒ¼ã‚¹ç«¶åˆ**: ä»–ã®ã‚¯ã‚¨ãƒªã‚‚åŒæ™‚ã«é…å»¶
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: ãƒ‡ãƒ¼ã‚¿å¢—åŠ ã§æŒ‡æ•°çš„ã«æ€§èƒ½åŠ£åŒ–

#### ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã‚ˆã‚‹åŠ‡çš„ãªæ”¹å–„

```sql
-- emailã‚«ãƒ©ãƒ ã«B-treeã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
CREATE INDEX idx_users_email ON users(email);
```

```go
func FindUserByEmailWithIndex(db *sql.DB, email string) (*User, error) {
    query := `
        SELECT id, email, name, created_at 
        FROM users 
        WHERE email = $1
    `
    // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒã‚ã‚‹å ´åˆï¼š
    // - Index Scanä½¿ç”¨
    // - O(log n)ã®æ™‚é–“è¨ˆç®—é‡ = æ•°ãƒŸãƒªç§’ã§å®Œäº†
    // - å¿…è¦æœ€å°é™ã®ãƒ‡ãƒ¼ã‚¿ãƒ–ãƒ­ãƒƒã‚¯ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹
    
    var user User
    err := db.QueryRow(query, email).Scan(&user.ID, &user.Email, &user.Name, &user.CreatedAt)
    return &user, err
}
```

**æ”¹å–„åŠ¹æœï¼š**
- **æ¤œç´¢æ™‚é–“**: æ•°åç§’ â†’ æ•°ãƒŸãƒªç§’ï¼ˆ10,000å€é«˜é€ŸåŒ–ï¼‰
- **I/Oè² è·**: 99.9%å‰Šæ¸›
- **åŒæ™‚å®Ÿè¡Œæ€§**: å¤§å¹…å‘ä¸Š
- **ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡**: CPUä½¿ç”¨ç‡æ¿€æ¸›

### ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç¨®é¡

#### 1. B-tree ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆæœ€ã‚‚ä¸€èˆ¬çš„ï¼‰
```sql
-- å˜ä¸€ã‚«ãƒ©ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_users_email ON users(email);

-- è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_orders_user_date ON orders(user_id, created_at);

-- éƒ¨åˆ†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_active_users ON users(email) WHERE active = true;
```

#### 2. ãƒãƒƒã‚·ãƒ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
```sql
-- ç­‰ä¾¡æ¤œç´¢ã«æœ€é©
CREATE INDEX idx_users_id_hash ON users USING HASH(id);
```

#### 3. GINã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆé…åˆ—ãƒ»JSONç”¨ï¼‰
```sql
-- é…åˆ—æ¤œç´¢ç”¨
CREATE INDEX idx_post_tags ON posts USING GIN(tags);

-- JSONBæ¤œç´¢ç”¨
CREATE INDEX idx_user_metadata ON users USING GIN(metadata);
```

### é«˜åº¦ãªEXPLAINåˆ†æã‚·ã‚¹ãƒ†ãƒ 

EXPLAINã‚’ä½¿ã£ãŸåŒ…æ‹¬çš„ãªã‚¯ã‚¨ãƒªåˆ†æã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ï¼š

```go
package main

import (
    "database/sql"
    "encoding/json"
    "fmt"
    "strings"
    "time"
    "math"
)

// QueryAnalyzer analyzes SQL queries using EXPLAIN
type QueryAnalyzer struct {
    db *sql.DB
    cache map[string]*CachedExplainResult
    mu    sync.RWMutex
}

func NewQueryAnalyzer(db *sql.DB) *QueryAnalyzer {
    return &QueryAnalyzer{
        db:    db,
        cache: make(map[string]*CachedExplainResult),
    }
}

// CachedExplainResult holds cached analysis results
type CachedExplainResult struct {
    Result    *DetailedExplainResult
    Timestamp time.Time
    TTL       time.Duration
}

// DetailedExplainResult holds comprehensive analysis
type DetailedExplainResult struct {
    Query                string                    `json:"query"`
    ExecutionPlan        *ExecutionPlan           `json:"execution_plan"`
    PerformanceMetrics   *PerformanceMetrics      `json:"performance_metrics"`
    IndexUsage           []IndexUsageInfo         `json:"index_usage"`
    Recommendations      []OptimizationSuggestion `json:"recommendations"`
    BottleneckAnalysis   *BottleneckAnalysis      `json:"bottleneck_analysis"`
    CostBreakdown        *CostBreakdown           `json:"cost_breakdown"`
}

type ExecutionPlan struct {
    NodeType           string             `json:"Node Type"`
    Relation           string             `json:"Relation Name,omitempty"`
    Alias              string             `json:"Alias,omitempty"`
    StartupCost        float64            `json:"Startup Cost"`
    TotalCost          float64            `json:"Total Cost"`
    PlanRows           int                `json:"Plan Rows"`
    PlanWidth          int                `json:"Plan Width"`
    ActualStartupTime  float64            `json:"Actual Startup Time,omitempty"`
    ActualTotalTime    float64            `json:"Actual Total Time,omitempty"`
    ActualRows         int                `json:"Actual Rows,omitempty"`
    IndexName          string             `json:"Index Name,omitempty"`
    IndexCondition     string             `json:"Index Cond,omitempty"`
    Filter             string             `json:"Filter,omitempty"`
    BuffersHit         int                `json:"Buffers Hit,omitempty"`
    BuffersRead        int                `json:"Buffers Read,omitempty"`
    ChildPlans         []*ExecutionPlan   `json:"Plans,omitempty"`
    JoinType           string             `json:"Join Type,omitempty"`
    HashCondition      string             `json:"Hash Cond,omitempty"`
    SortKey            []string           `json:"Sort Key,omitempty"`
    SortMethod         string             `json:"Sort Method,omitempty"`
    WorkMemUsed        int                `json:"Sort Space Used,omitempty"`
}

type PerformanceMetrics struct {
    ExecutionTime      time.Duration  `json:"execution_time"`
    PlanningTime       time.Duration  `json:"planning_time"`
    TotalCost          float64        `json:"total_cost"`
    RowsReturned       int            `json:"rows_returned"`
    RowsExamined       int            `json:"rows_examined"`
    SelectivityRatio   float64        `json:"selectivity_ratio"`
    BufferHitRatio     float64        `json:"buffer_hit_ratio"`
    IOTime             time.Duration  `json:"io_time"`
    CPUTime            time.Duration  `json:"cpu_time"`
}

type IndexUsageInfo struct {
    IndexName        string  `json:"index_name"`
    TableName        string  `json:"table_name"`
    Columns          []string `json:"columns"`
    UsageType        string   `json:"usage_type"` // "scan", "seek", "lookup"
    SelectivityGain  float64  `json:"selectivity_gain"`
    CostReduction    float64  `json:"cost_reduction"`
}

type OptimizationSuggestion struct {
    Type           string  `json:"type"` // "create_index", "drop_index", "modify_query"
    Priority       string  `json:"priority"` // "high", "medium", "low"
    Description    string  `json:"description"`
    SQLCommand     string  `json:"sql_command,omitempty"`
    ExpectedGain   float64 `json:"expected_gain"` // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ç‡ï¼ˆ%ï¼‰
    Reason         string  `json:"reason"`
    Impact         string  `json:"impact"`
}

type BottleneckAnalysis struct {
    PrimaryBottleneck   string             `json:"primary_bottleneck"`
    BottleneckDetails   map[string]float64 `json:"bottleneck_details"`
    TimeBreakdown       map[string]float64 `json:"time_breakdown"`
    ResourceUsage       map[string]float64 `json:"resource_usage"`
}

type CostBreakdown struct {
    SeqScanCost      float64 `json:"seq_scan_cost"`
    IndexScanCost    float64 `json:"index_scan_cost"`
    JoinCost         float64 `json:"join_cost"`
    SortCost         float64 `json:"sort_cost"`
    HashCost         float64 `json:"hash_cost"`
    FilterCost       float64 `json:"filter_cost"`
}

// ComprehensiveAnalyzeQuery performs detailed query analysis
func (qa *QueryAnalyzer) ComprehensiveAnalyzeQuery(query string, args ...interface{}) (*DetailedExplainResult, error) {
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
    cacheKey := qa.generateCacheKey(query, args...)
    if cached := qa.getCachedResult(cacheKey); cached != nil {
        return cached, nil
    }
    
    // EXPLAIN ANALYZEå®Ÿè¡Œ
    explainQuery := "EXPLAIN (ANALYZE true, BUFFERS true, FORMAT JSON, TIMING true, VERBOSE true) " + query
    
    var jsonResult string
    start := time.Now()
    err := qa.db.QueryRow(explainQuery, args...).Scan(&jsonResult)
    if err != nil {
        return nil, fmt.Errorf("failed to execute EXPLAIN: %w", err)
    }
    executionTime := time.Since(start)
    
    // JSONçµæœã‚’ãƒ‘ãƒ¼ã‚¹
    var rawResult []map[string]interface{}
    if err := json.Unmarshal([]byte(jsonResult), &rawResult); err != nil {
        return nil, fmt.Errorf("failed to parse EXPLAIN result: %w", err)
    }
    
    if len(rawResult) == 0 {
        return nil, fmt.Errorf("empty EXPLAIN result")
    }
    
    planData := rawResult[0]["Plan"].(map[string]interface{})
    
    // è©³ç´°åˆ†æã‚’å®Ÿè¡Œ
    result := &DetailedExplainResult{
        Query: query,
    }
    
    result.ExecutionPlan = qa.parseExecutionPlan(planData)
    result.PerformanceMetrics = qa.calculatePerformanceMetrics(planData, executionTime)
    result.IndexUsage = qa.analyzeIndexUsage(result.ExecutionPlan)
    result.Recommendations = qa.generateRecommendations(result)
    result.BottleneckAnalysis = qa.analyzeBottlenecks(result)
    result.CostBreakdown = qa.calculateCostBreakdown(result.ExecutionPlan)
    
    // çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    qa.cacheResult(cacheKey, result, 5*time.Minute)
    
    return result, nil
}

func (qa *QueryAnalyzer) parseExecutionPlan(planData map[string]interface{}) *ExecutionPlan {
    plan := &ExecutionPlan{}
    
    // åŸºæœ¬æƒ…å ±ã®æŠ½å‡º
    if nodeType, ok := planData["Node Type"].(string); ok {
        plan.NodeType = nodeType
    }
    if relation, ok := planData["Relation Name"].(string); ok {
        plan.Relation = relation
    }
    if alias, ok := planData["Alias"].(string); ok {
        plan.Alias = alias
    }
    
    // ã‚³ã‚¹ãƒˆæƒ…å ±
    if startupCost, ok := planData["Startup Cost"].(float64); ok {
        plan.StartupCost = startupCost
    }
    if totalCost, ok := planData["Total Cost"].(float64); ok {
        plan.TotalCost = totalCost
    }
    if planRows, ok := planData["Plan Rows"].(float64); ok {
        plan.PlanRows = int(planRows)
    }
    if planWidth, ok := planData["Plan Width"].(float64); ok {
        plan.PlanWidth = int(planWidth)
    }
    
    // å®Ÿè¡Œæ™‚çµ±è¨ˆ
    if actualStartupTime, ok := planData["Actual Startup Time"].(float64); ok {
        plan.ActualStartupTime = actualStartupTime
    }
    if actualTotalTime, ok := planData["Actual Total Time"].(float64); ok {
        plan.ActualTotalTime = actualTotalTime
    }
    if actualRows, ok := planData["Actual Rows"].(float64); ok {
        plan.ActualRows = int(actualRows)
    }
    
    // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±
    if indexName, ok := planData["Index Name"].(string); ok {
        plan.IndexName = indexName
    }
    if indexCond, ok := planData["Index Cond"].(string); ok {
        plan.IndexCondition = indexCond
    }
    if filter, ok := planData["Filter"].(string); ok {
        plan.Filter = filter
    }
    
    // ãƒãƒƒãƒ•ã‚¡æƒ…å ±
    if buffersHit, ok := planData["Buffers Hit"].(float64); ok {
        plan.BuffersHit = int(buffersHit)
    }
    if buffersRead, ok := planData["Buffers Read"].(float64); ok {
        plan.BuffersRead = int(buffersRead)
    }
    
    // JOINæƒ…å ±
    if joinType, ok := planData["Join Type"].(string); ok {
        plan.JoinType = joinType
    }
    if hashCond, ok := planData["Hash Cond"].(string); ok {
        plan.HashCondition = hashCond
    }
    
    // ã‚½ãƒ¼ãƒˆæƒ…å ±
    if sortKey, ok := planData["Sort Key"].([]interface{}); ok {
        plan.SortKey = make([]string, len(sortKey))
        for i, key := range sortKey {
            plan.SortKey[i] = key.(string)
        }
    }
    if sortMethod, ok := planData["Sort Method"].(string); ok {
        plan.SortMethod = sortMethod
    }
    if workMemUsed, ok := planData["Sort Space Used"].(float64); ok {
        plan.WorkMemUsed = int(workMemUsed)
    }
    
    // å­ãƒ—ãƒ©ãƒ³ã®å†å¸°çš„ãƒ‘ãƒ¼ã‚¹
    if plans, ok := planData["Plans"].([]interface{}); ok {
        plan.ChildPlans = make([]*ExecutionPlan, len(plans))
        for i, childPlan := range plans {
            plan.ChildPlans[i] = qa.parseExecutionPlan(childPlan.(map[string]interface{}))
        }
    }
    
    return plan
}

func (qa *QueryAnalyzer) calculatePerformanceMetrics(planData map[string]interface{}, executionTime time.Duration) *PerformanceMetrics {
    metrics := &PerformanceMetrics{
        ExecutionTime: executionTime,
    }
    
    // åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    if totalCost, ok := planData["Total Cost"].(float64); ok {
        metrics.TotalCost = totalCost
    }
    if actualRows, ok := planData["Actual Rows"].(float64); ok {
        metrics.RowsReturned = int(actualRows)
    }
    
    // ãƒãƒƒãƒ•ã‚¡ãƒ’ãƒƒãƒˆç‡è¨ˆç®—
    totalBuffers := 0
    hitBuffers := 0
    qa.calculateBufferStats(planData, &totalBuffers, &hitBuffers)
    
    if totalBuffers > 0 {
        metrics.BufferHitRatio = float64(hitBuffers) / float64(totalBuffers)
    }
    
    // é¸æŠæ€§è¨ˆç®—ï¼ˆæ¦‚ç®—ï¼‰
    if planRows, ok := planData["Plan Rows"].(float64); ok {
        if actualRows, ok := planData["Actual Rows"].(float64); ok {
            if planRows > 0 {
                metrics.SelectivityRatio = actualRows / planRows
            }
        }
    }
    
    return metrics
}

func (qa *QueryAnalyzer) calculateBufferStats(planData map[string]interface{}, totalBuffers, hitBuffers *int) {
    if hit, ok := planData["Buffers Hit"].(float64); ok {
        *hitBuffers += int(hit)
        *totalBuffers += int(hit)
    }
    if read, ok := planData["Buffers Read"].(float64); ok {
        *totalBuffers += int(read)
    }
    
    // å­ãƒ—ãƒ©ãƒ³ã®çµ±è¨ˆã‚‚è¨ˆç®—
    if plans, ok := planData["Plans"].([]interface{}); ok {
        for _, childPlan := range plans {
            qa.calculateBufferStats(childPlan.(map[string]interface{}), totalBuffers, hitBuffers)
        }
    }
}
```

### ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŠ¹æœã®æ¸¬å®š

```go
package main

import (
    "context"
    "database/sql"
    "time"
)

// IndexPerformanceTest tests index performance
type IndexPerformanceTest struct {
    db    *sql.DB
    table string
}

// BenchmarkQuery measures query performance
func (ipt *IndexPerformanceTest) BenchmarkQuery(ctx context.Context, query string, iterations int, args ...interface{}) (QueryBenchmark, error) {
    var totalDuration time.Duration
    var successCount int
    
    for i := 0; i < iterations; i++ {
        start := time.Now()
        
        rows, err := ipt.db.QueryContext(ctx, query, args...)
        if err != nil {
            continue
        }
        
        // Consume all rows to ensure full execution
        for rows.Next() {
            // Do nothing, just consume
        }
        rows.Close()
        
        totalDuration += time.Since(start)
        successCount++
    }
    
    return QueryBenchmark{
        Query:           query,
        Iterations:      iterations,
        SuccessCount:    successCount,
        TotalDuration:   totalDuration,
        AverageDuration: totalDuration / time.Duration(successCount),
    }, nil
}

type QueryBenchmark struct {
    Query           string
    Iterations      int
    SuccessCount    int
    TotalDuration   time.Duration
    AverageDuration time.Duration
}
```

### ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¨å¥¨ã‚·ã‚¹ãƒ†ãƒ 

```go
// IndexRecommendation suggests indexes based on query patterns
type IndexRecommendation struct {
    TableName   string
    Columns     []string
    IndexType   string
    Reason      string
    ExpectedGain float64
}

// IndexAdvisor analyzes queries and suggests indexes
type IndexAdvisor struct {
    db           *sql.DB
    analyzer     *QueryAnalyzer
    queries      []string
    recommendations []IndexRecommendation
}

func NewIndexAdvisor(db *sql.DB) *IndexAdvisor {
    return &IndexAdvisor{
        db:       db,
        analyzer: NewQueryAnalyzer(db),
        queries:  make([]string, 0),
        recommendations: make([]IndexRecommendation, 0),
    }
}

// AnalyzeQuery analyzes a query and suggests indexes
func (ia *IndexAdvisor) AnalyzeQuery(query string, args ...interface{}) error {
    results, err := ia.analyzer.ExplainQuery(query, args...)
    if err != nil {
        return err
    }
    
    // Analyze for sequential scans
    for _, result := range results {
        if result.NodeType == "Seq Scan" && result.ActualTotalTime > 10.0 {
            recommendation := IndexRecommendation{
                TableName:    result.Relation,
                Columns:      extractColumnsFromFilter(result.Filter),
                IndexType:    "btree",
                Reason:       "Sequential scan detected on large table",
                ExpectedGain: result.ActualTotalTime * 0.8, // Estimate 80% improvement
            }
            ia.recommendations = append(ia.recommendations, recommendation)
        }
    }
    
    return nil
}
```

### å®Ÿè·µçš„ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥

#### WHEREå¥ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
```go
// Bad: No index on email
// SELECT * FROM users WHERE email = 'user@example.com'

// Good: Index on email
// CREATE INDEX idx_users_email ON users(email);

func FindUserByEmail(db *sql.DB, email string) (*User, error) {
    query := `
        SELECT id, name, email, created_at 
        FROM users 
        WHERE email = $1
    `
    
    var user User
    err := db.QueryRow(query, email).Scan(
        &user.ID, &user.Name, &user.Email, &user.CreatedAt,
    )
    if err != nil {
        return nil, err
    }
    
    return &user, nil
}
```

#### è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ´»ç”¨
```go
// è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: (user_id, created_at)
// CREATE INDEX idx_orders_user_date ON orders(user_id, created_at);

func GetUserOrdersInDateRange(db *sql.DB, userID int, start, end time.Time) ([]Order, error) {
    query := `
        SELECT id, user_id, amount, created_at
        FROM orders 
        WHERE user_id = $1 
          AND created_at BETWEEN $2 AND $3
        ORDER BY created_at DESC
    `
    
    rows, err := db.Query(query, userID, start, end)
    if err != nil {
        return nil, err
    }
    defer rows.Close()
    
    var orders []Order
    for rows.Next() {
        var order Order
        err := rows.Scan(&order.ID, &order.UserID, &order.Amount, &order.CreatedAt)
        if err != nil {
            return nil, err
        }
        orders = append(orders, order)
    }
    
    return orders, nil
}
```

### ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

```go
// IndexMaintenance handles index maintenance tasks
type IndexMaintenance struct {
    db *sql.DB
}

// GetIndexUsageStats returns index usage statistics
func (im *IndexMaintenance) GetIndexUsageStats() ([]IndexUsage, error) {
    query := `
        SELECT 
            schemaname,
            tablename,
            indexname,
            idx_tup_read,
            idx_tup_fetch,
            idx_scan
        FROM pg_stat_user_indexes
        ORDER BY idx_scan ASC
    `
    
    rows, err := im.db.Query(query)
    if err != nil {
        return nil, err
    }
    defer rows.Close()
    
    var usage []IndexUsage
    for rows.Next() {
        var idx IndexUsage
        err := rows.Scan(
            &idx.SchemaName,
            &idx.TableName, 
            &idx.IndexName,
            &idx.TupRead,
            &idx.TupFetch,
            &idx.Scans,
        )
        if err != nil {
            return nil, err
        }
        usage = append(usage, idx)
    }
    
    return usage, nil
}

type IndexUsage struct {
    SchemaName string
    TableName  string
    IndexName  string
    TupRead    int64
    TupFetch   int64
    Scans      int64
}

// FindUnusedIndexes identifies potentially unused indexes
func (im *IndexMaintenance) FindUnusedIndexes() ([]string, error) {
    query := `
        SELECT indexname 
        FROM pg_stat_user_indexes 
        WHERE idx_scan = 0
          AND indexname != tablename || '_pkey'
    `
    
    rows, err := im.db.Query(query)
    if err != nil {
        return nil, err
    }
    defer rows.Close()
    
    var unused []string
    for rows.Next() {
        var indexName string
        if err := rows.Scan(&indexName); err != nil {
            return nil, err
        }
        unused = append(unused, indexName)
    }
    
    return unused, nil
}
```

ğŸ“ **èª²é¡Œ**

ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ†æã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š

1. **`QueryAnalyzer`**: EXPLAINçµæœã®åˆ†æ
2. **`IndexAdvisor`**: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¨å¥¨ã‚·ã‚¹ãƒ†ãƒ 
3. **`PerformanceTester`**: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŠ¹æœã®æ¸¬å®š
4. **`IndexMaintenance`**: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¿å®ˆç®¡ç†
5. **`QueryOptimizer`**: ã‚¯ã‚¨ãƒªæœ€é©åŒ–æ”¯æ´
6. **çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ãƒ¬ãƒãƒ¼ãƒˆ

âœ… **æœŸå¾…ã•ã‚Œã‚‹æŒ™å‹•**

å®Ÿè£…ãŒå®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªå‹•ä½œãŒæœŸå¾…ã•ã‚Œã¾ã™ï¼š

```bash
$ go test -v
=== RUN   TestQueryAnalyzer_ExplainQuery
--- PASS: TestQueryAnalyzer_ExplainQuery (0.02s)
=== RUN   TestIndexAdvisor_Recommendations
--- PASS: TestIndexAdvisor_Recommendations (0.05s)
=== RUN   TestPerformanceTester_IndexComparison
--- PASS: TestPerformanceTester_IndexComparison (0.10s)
=== RUN   TestIndexMaintenance_UsageStats
--- PASS: TestIndexMaintenance_UsageStats (0.03s)
=== RUN   TestQueryOptimizer_Integration
--- PASS: TestQueryOptimizer_Integration (0.15s)
PASS
ok      day38-db-index    0.350s
```

ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**

å®Ÿè£…ã«è©°ã¾ã£ãŸå ´åˆã¯ã€ä»¥ä¸‹ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š

1. **EXPLAIN ANALYZE**: å®Ÿéš›ã®å®Ÿè¡Œçµ±è¨ˆã‚’å–å¾—
2. **pg_stat_user_indexes**: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨çŠ¶æ³ã®ç›£è¦–
3. **JSONBå‡¦ç†**: PostgreSQLã®EXPLAINçµæœãƒ‘ãƒ¼ã‚¹
4. **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯**: ã‚¯ã‚¨ãƒªæ€§èƒ½ã®å®šé‡çš„æ¸¬å®š
5. **ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥**: é©åˆ‡ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­è¨ˆ

ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­è¨ˆã®ãƒã‚¤ãƒ³ãƒˆï¼š
- **é¸æŠæ€§ã®é«˜ã„ã‚«ãƒ©ãƒ **: ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ãŒå¤šã„ã‚«ãƒ©ãƒ ã‚’å„ªå…ˆ
- **WHEREå¥ã®é »åº¦**: ã‚ˆãä½¿ã‚ã‚Œã‚‹æ¤œç´¢æ¡ä»¶ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
- **è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®é †åº**: é¸æŠæ€§ã®é«˜ã„é †ã«é…ç½®
- **ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚³ã‚¹ãƒˆ**: æ›´æ–°é »åº¦ã¨ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®

## å®Ÿè¡Œæ–¹æ³•

```bash
go test -v
go test -race  # ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã®æ¤œå‡º
go test -bench=.  # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
```