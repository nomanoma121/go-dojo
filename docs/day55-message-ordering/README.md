# Day 55: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é †åºä¿è¨¼

## ğŸ¯ æœ¬æ—¥ã®ç›®æ¨™ (Today's Goal)

åˆ†æ•£ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é †åºä¿è¨¼ã‚’å®Ÿè£…ã—ã€ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³åˆ†å‰²ã€é †åºä»˜ãã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ã€ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼åˆ¶å¾¡ã‚’å«ã‚€åŒ…æ‹¬çš„ãªé †åºä¿è¨¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

## ğŸ“– è§£èª¬ (Explanation)

### ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é †åºä¿è¨¼ã®é‡è¦æ€§

åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é †åºãŒé‡è¦ãªãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã«å½±éŸ¿ã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ï¼š
- é‡‘èå–å¼•ã®å‡¦ç†é †åº
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®æ™‚ç³»åˆ—
- åœ¨åº«æ›´æ–°ã®é †åº
- ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®é †åº

```go
// ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é †åºä¿è¨¼ã®é‡è¦æ€§ã€‘åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã§ã®ä¸€è²«æ€§ç¶­æŒ
// âŒ å•é¡Œä¾‹ï¼šé †åºä¿è¨¼ãªã—ã«ã‚ˆã‚‹å£Šæ»…çš„ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆ
func catastrophicUnorderedProcessing() {
    // ğŸš¨ ç½å®³ä¾‹ï¼šéŠ€è¡Œå–å¼•ã‚·ã‚¹ãƒ†ãƒ ã§ã®é †åºç„¡è¦–å‡¦ç†
    
    accountID := "ACC-12345"
    initialBalance := 1000.0
    
    // ã€å•é¡Œã®ã‚·ãƒŠãƒªã‚ªã€‘é¡§å®¢ã®ä¸€é€£ã®å–å¼•ãŒä¸¦è¡Œå‡¦ç†ã•ã‚Œã‚‹
    transactions := []Transaction{
        {ID: "TXN-001", Type: "deposit",    Amount: 500.0,  Timestamp: time.Now().Add(-3*time.Minute)}, // +500
        {ID: "TXN-002", Type: "withdrawal", Amount: 800.0,  Timestamp: time.Now().Add(-2*time.Minute)}, // -800
        {ID: "TXN-003", Type: "deposit",    Amount: 300.0,  Timestamp: time.Now().Add(-1*time.Minute)}, // +300
        {ID: "TXN-004", Type: "withdrawal", Amount: 200.0,  Timestamp: time.Now()},                    // -200
    }
    
    // ã€æ­£ã—ã„å‡¦ç†é †åºã€‘æ™‚ç³»åˆ—é †ï¼š1000 â†’ 1500 â†’ 700 â†’ 1000 â†’ 800
    // æœ€çµ‚æ®‹é«˜ï¼š800ï¼ˆæ­£å¸¸ãªå–å¼•ã™ã¹ã¦ãŒå®Ÿè¡Œå¯èƒ½ï¼‰
    
    // ã€è‡´å‘½çš„å•é¡Œã€‘ä¸¦è¡Œå‡¦ç†ã§é †åºãŒãƒ©ãƒ³ãƒ€ãƒ ã«
    var wg sync.WaitGroup
    for _, txn := range transactions {
        wg.Add(1)
        
        // ã€ç½å®³ç™ºç”Ÿã€‘å„å–å¼•ãŒä¸¦è¡Œå®Ÿè¡Œã•ã‚Œã€é †åºãŒä¿è¨¼ã•ã‚Œãªã„
        go func(t Transaction) {
            defer wg.Done()
            
            // ã€ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã€‘åŒæ™‚å®Ÿè¡Œã§æ®‹é«˜è¨ˆç®—ãŒç ´ç¶»
            // å¯èƒ½ãªå®Ÿè¡Œé †åºãƒ‘ã‚¿ãƒ¼ãƒ³ï¼š
            // ãƒ‘ã‚¿ãƒ¼ãƒ³1: TXN-004, TXN-002, TXN-001, TXN-003
            // ãƒ‘ã‚¿ãƒ¼ãƒ³2: TXN-002, TXN-004, TXN-003, TXN-001
            // â†’ å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã§å…¨ãç•°ãªã‚‹æœ€çµ‚æ®‹é«˜
            
            processTransactionUnsafe(accountID, t)
            
            // ã€å®Ÿéš›ã®è¢«å®³ä¾‹ã€‘ï¼š
            // - æ®‹é«˜ä¸æ•´åˆï¼šé¡§å®¢Aã®1000å††ãŒãƒã‚¤ãƒŠã‚¹2000å††ã«
            // - äºŒé‡æ”¯æ‰•ã„ï¼šåŒã˜å•†å“ä»£é‡‘ã‚’è¤‡æ•°å›æ±ºæ¸ˆ
            // - åœ¨åº«éå‰°æ¸›ç®—ï¼šåœ¨åº«100å€‹ãŒ-50å€‹ã«ãªã‚‹
            // - ç›£æŸ»ä¸å¯èƒ½ï¼šå–å¼•å±¥æ­´ã®æ™‚ç³»åˆ—ãŒç ´ç¶»
            
        }(txn)
    }
    
    wg.Wait()
    
    // ã€çµæœã€‘ï¼š
    // - é¡§å®¢ã®æ­£å½“ãªå–å¼•ãŒæ‹’å¦ã•ã‚Œã‚‹ï¼ˆé¡§å®¢æº€è¶³åº¦ä½ä¸‹ï¼‰
    // - ã‚·ã‚¹ãƒ†ãƒ ã®æ•´åˆæ€§ãŒç ´ç¶»ï¼ˆç›£æŸ»ã§ç™ºè¦šã€æ³•çš„è²¬ä»»ï¼‰
    // - ä¿®å¾©ä½œæ¥­ã§è«å¤§ãªã‚³ã‚¹ãƒˆï¼ˆå…¨å–å¼•ã®æ‰‹å‹•èª¿æŸ»ãƒ»ä¿®æ­£ï¼‰
    // - ä¿¡é ¼å¤±å¢œï¼ˆé‡‘èãƒ©ã‚¤ã‚»ãƒ³ã‚¹å‰¥å¥ªã®å¯èƒ½æ€§ï¼‰
    
    log.Printf("Final balance: %.2f (INCONSISTENT!)", getCurrentBalance(accountID))
    // å®Ÿè¡Œã®ãŸã³ã«ç•°ãªã‚‹å€¤ãŒå‡ºåŠ›ã•ã‚Œã‚‹
}

// âœ… æ­£è§£ï¼šã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç´šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é †åºä¿è¨¼ã‚·ã‚¹ãƒ†ãƒ 
type EnterpriseOrderedMessageSystem struct {
    // ã€åŸºæœ¬é †åºä¿è¨¼ã€‘
    partitionManager    *PartitionManager       // ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ç®¡ç†
    sequencer          *MessageSequencer       // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é †åºä»˜ã‘
    orderValidator     *OrderValidator         // é †åºæ¤œè¨¼
    conflictResolver   *ConflictResolver       // ç«¶åˆè§£æ±º
    
    // ã€é«˜åº¦é †åºåˆ¶å¾¡ã€‘
    logicalClock       *VectorClock           // ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¯ãƒ­ãƒƒã‚¯
    timestampOracle    *TimestampOracle       // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç”Ÿæˆ
    causalityTracker   *CausalityTracker      // å› æœé–¢ä¿‚è¿½è·¡
    dependencyGraph    *DependencyGraph       // ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•
    
    // ã€ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³æˆ¦ç•¥ã€‘
    shardingStrategy   ShardingStrategy       // ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥
    rebalancer         *PartitionRebalancer   // ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³å†é…åˆ†
    consistentHashing  *ConsistentHashRing    // ä¸€è²«æ€§ãƒãƒƒã‚·ãƒ¥
    affinityManager    *AffinityManager       // ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³è¦ªå’Œæ€§
    
    // ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã€‘
    batchProcessor     *BatchOrderProcessor   // ãƒãƒƒãƒé †åºå‡¦ç†
    pipelineManager    *PipelineManager       // ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç®¡ç†
    bufferManager      *OrderedBufferManager  // é †åºä»˜ããƒãƒƒãƒ•ã‚¡
    backpressure       *BackpressureController // ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼åˆ¶å¾¡
    
    // ã€éšœå®³å‡¦ç†ãƒ»å¾©æ—§ã€‘
    recoveryManager    *OrderRecoveryManager  // é †åºå¾©æ—§
    checkpointer       *OrderCheckpointer     // é †åºãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
    replicationManager *OrderReplication      // é †åºè¤‡è£½
    auditLogger        *OrderAuditLogger      // é †åºç›£æŸ»ãƒ­ã‚°
}

// ã€åŒ…æ‹¬çš„é †åºä¿è¨¼å‡¦ç†ã€‘ä¼æ¥­ãƒ¬ãƒ™ãƒ«ã®é †åºåˆ¶å¾¡
func (oms *EnterpriseOrderedMessageSystem) ProcessOrderedMessage(ctx context.Context, message *OrderedMessage) error {
    startTime := time.Now()
    processingID := generateProcessingID()
    
    // ã€STEP 1ã€‘ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é †åºæ¤œè¨¼
    orderInfo := &OrderInfo{
        MessageID:     message.ID,
        PartitionKey:  message.PartitionKey,
        SequenceNum:   message.SequenceNumber,
        Timestamp:     message.Timestamp,
        ProcessingID:  processingID,
        Dependencies:  message.Dependencies,
    }
    
    if !oms.orderValidator.ValidateOrder(orderInfo) {
        return oms.handleOrderViolation(message, orderInfo)
    }
    
    // ã€STEP 2ã€‘ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³é¸æŠã¨è¦ªå’Œæ€§ç¢ºä¿
    partition := oms.partitionManager.SelectPartition(message.PartitionKey)
    if partition.IsRebalancing() {
        // ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³å†é…åˆ†ä¸­ã¯ä¸€æ™‚å¾…æ©Ÿ
        if err := oms.waitForRebalanceCompletion(ctx, partition); err != nil {
            return fmt.Errorf("partition rebalancing timeout: %w", err)
        }
    }
    
    // ã€STEP 3ã€‘å› æœé–¢ä¿‚ã¨ä¾å­˜é–¢ä¿‚ã®ç¢ºèª
    if len(message.Dependencies) > 0 {
        if err := oms.causalityTracker.WaitForDependencies(ctx, message.Dependencies); err != nil {
            return fmt.Errorf("dependency wait failed: %w", err)
        }
    }
    
    // ã€STEP 4ã€‘é †åºä»˜ããƒãƒƒãƒ•ã‚¡ã¸ã®æ ¼ç´
    bufferSlot := oms.bufferManager.AcquireSlot(partition.ID, message.SequenceNumber)
    defer bufferSlot.Release()
    
    // ã€ä¸¦è¡Œæ€§åˆ¶å¾¡ã€‘åŒä¸€ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³å†…ã§ã®é †åºä¿è¨¼
    partitionLock := oms.getPartitionOrderLock(partition.ID)
    partitionLock.Lock()
    defer partitionLock.Unlock()
    
    // ã€STEP 5ã€‘é †åºãƒã‚§ãƒƒã‚¯ã¨å¾…æ©Ÿ
    expectedSequence := oms.sequencer.GetExpectedSequence(partition.ID)
    if message.SequenceNumber != expectedSequence {
        // ã€é †åºå¾…æ©Ÿã€‘æœŸå¾…ã•ã‚Œã‚‹é †åºç•ªå·ã¾ã§å¾…æ©Ÿ
        log.Printf("â³ Message %s waiting for sequence %d (current: %d)", 
            message.ID, expectedSequence, message.SequenceNumber)
        
        if err := oms.waitForPrecedingMessages(ctx, partition.ID, expectedSequence, message.SequenceNumber); err != nil {
            return fmt.Errorf("sequence wait failed: %w", err)
        }
    }
    
    // ã€STEP 6ã€‘ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè¡Œ
    processingResult, err := oms.executeBusinessLogic(ctx, message, partition)
    if err != nil {
        // å¤±æ•—æ™‚ã®é †åºçŠ¶æ…‹å¾©æ—§
        oms.recoveryManager.HandleProcessingFailure(partition.ID, message.SequenceNumber, err)
        return fmt.Errorf("business logic failed: %w", err)
    }
    
    // ã€STEP 7ã€‘é †åºçŠ¶æ…‹æ›´æ–°
    oms.sequencer.AdvanceSequence(partition.ID, message.SequenceNumber)
    
    // ã€STEP 8ã€‘å¾Œç¶šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é€šçŸ¥
    oms.notifyWaitingMessages(partition.ID, message.SequenceNumber+1)
    
    // ã€STEP 9ã€‘ç›£æŸ»ãƒ­ã‚°è¨˜éŒ²
    auditEntry := &OrderAuditEntry{
        MessageID:         message.ID,
        PartitionID:       partition.ID,
        SequenceNumber:    message.SequenceNumber,
        ProcessingTime:    time.Since(startTime),
        ProcessingResult:  processingResult,
        PredecessorID:     oms.getPredecessorMessageID(partition.ID, message.SequenceNumber-1),
        SuccessorID:       "", // å¾Œã§è¨­å®š
    }
    
    oms.auditLogger.LogOrderedProcessing(auditEntry)
    
    log.Printf("âœ… Message %s processed in order (seq: %d, partition: %s)", 
        message.ID, message.SequenceNumber, partition.ID)
    
    return nil
}

// ã€é †åºé•åå‡¦ç†ã€‘é †åºã‚¨ãƒ©ãƒ¼æ™‚ã®è©³ç´°å¯¾å¿œ
func (oms *EnterpriseOrderedMessageSystem) handleOrderViolation(message *OrderedMessage, orderInfo *OrderInfo) error {
    violation := &OrderViolation{
        MessageID:       message.ID,
        ExpectedSeq:     orderInfo.ExpectedSequence,
        ActualSeq:       message.SequenceNumber,
        PartitionID:     orderInfo.PartitionID,
        ViolationType:   oms.classifyViolation(orderInfo),
        Timestamp:       time.Now(),
        Severity:        oms.assessViolationSeverity(message, orderInfo),
    }
    
    // ã€é•åã‚¿ã‚¤ãƒ—åˆ¥å‡¦ç†ã€‘
    switch violation.ViolationType {
    case ViolationTypeSequenceGap:
        // ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç•ªå·ã®æ¬ è½ã€‘å‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒæœªåˆ°ç€
        return oms.handleSequenceGap(message, violation)
        
    case ViolationTypeDuplicateSequence:
        // ã€é‡è¤‡ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã€‘åŒã˜ç•ªå·ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¤‡æ•°
        return oms.handleDuplicateSequence(message, violation)
        
    case ViolationTypeOutOfOrder:
        // ã€é †åºé€†è»¢ã€‘å¾Œç¶šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå…ˆã«åˆ°ç€
        return oms.handleOutOfOrder(message, violation)
        
    case ViolationTypePartitionMismatch:
        // ã€ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ä¸æ•´åˆã€‘äºˆæœŸã—ãªã„ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³
        return oms.handlePartitionMismatch(message, violation)
        
    case ViolationTypeTimestampAnomaly:
        // ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç•°å¸¸ã€‘æ™‚è¨ˆã®ç‹‚ã„ã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é…å»¶
        return oms.handleTimestampAnomaly(message, violation)
        
    default:
        // ã€æœªçŸ¥ã®é•åã€‘æ–°ã—ã„ã‚¿ã‚¤ãƒ—ã®é †åºé•å
        return oms.handleUnknownViolation(message, violation)
    }
}

// ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ¬ è½å‡¦ç†ã€‘ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ¬ è½æ™‚ã®å¯¾å¿œ
func (oms *EnterpriseOrderedMessageSystem) handleSequenceGap(message *OrderedMessage, violation *OrderViolation) error {
    log.Printf("ğŸš¨ Sequence gap detected: expected %d, got %d for partition %s", 
        violation.ExpectedSeq, violation.ActualSeq, violation.PartitionID)
    
    // ã€æ¬ è½æ¤œå‡ºã€‘ã©ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒæ¬ è½ã—ã¦ã„ã‚‹ã‹ã‚’ç‰¹å®š
    missingSequences := make([]int64, 0)
    for seq := violation.ExpectedSeq; seq < violation.ActualSeq; seq++ {
        missingSequences = append(missingSequences, seq)
    }
    
    // ã€é‡è¦åº¦è©•ä¾¡ã€‘
    impact := oms.assessGapImpact(violation.PartitionID, missingSequences)
    
    if impact.Severity >= ImpactSeverityCritical {
        // ã€ç·Šæ€¥å¯¾å¿œã€‘ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ¬ è½
        alert := &CriticalOrderAlert{
            Type:           AlertTypeSequenceGap,
            PartitionID:    violation.PartitionID,
            MissingSequences: missingSequences,
            BusinessImpact: impact,
            RequiredActions: []string{
                "Immediate investigation of message loss",
                "Check producer system health",
                "Verify network infrastructure",
                "Consider system rollback if data corruption suspected",
            },
        }
        
        oms.sendCriticalAlert(alert)
        
        // ã€ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ä¿è­·ã€‘ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«æ™‚ã¯å‡¦ç†åœæ­¢
        if oms.config.StrictOrderingMode {
            return fmt.Errorf("critical sequence gap detected, halting processing to prevent data corruption")
        }
    }
    
    // ã€æ¬ è½å›å¾©æˆ¦ç•¥ã€‘
    recoveryStrategy := oms.selectRecoveryStrategy(violation.PartitionID, missingSequences, impact)
    
    switch recoveryStrategy {
    case RecoveryStrategyWaitAndRetry:
        // ã€å¾…æ©Ÿãƒ»å†è©¦è¡Œã€‘çŸ­æ™‚é–“å¾…æ©Ÿã—ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸åˆ°ç€ã‚’æœŸå¾…
        return oms.waitForMissingMessages(violation.PartitionID, missingSequences, 30*time.Second)
        
    case RecoveryStrategySkipAndContinue:
        // ã€ã‚¹ã‚­ãƒƒãƒ—ãƒ»ç¶™ç¶šã€‘éã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯æ¬ è½ã‚’è¨±å®¹
        oms.logSkippedMessages(violation.PartitionID, missingSequences)
        return oms.advanceSequenceWithGap(violation.PartitionID, violation.ActualSeq)
        
    case RecoveryStrategyRequestRedelivery:
        // ã€å†é…ä¿¡è¦æ±‚ã€‘ãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼ã«æ¬ è½ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å†é€è¦æ±‚
        return oms.requestMessageRedelivery(violation.PartitionID, missingSequences)
        
    case RecoveryStrategyFailsafeMode:
        // ã€ã‚»ãƒ¼ãƒ•ãƒ¢ãƒ¼ãƒ‰ã€‘ã‚·ã‚¹ãƒ†ãƒ ä¿è­·ã®ãŸã‚å‡¦ç†ã‚’ä¸€æ™‚åœæ­¢
        return oms.enterFailsafeMode(violation.PartitionID, "sequence gap detected")
        
    default:
        return fmt.Errorf("unknown recovery strategy: %v", recoveryStrategy)
    }
}
```

### é †åºä¿è¨¼ã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³

#### 1. ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³åˆ†å‰²ã«ã‚ˆã‚‹é †åºä¿è¨¼

```go
type PartitionedQueue struct {
    partitions    map[int]*OrderedPartition
    partitioner   Partitioner
    mu           sync.RWMutex
}

type OrderedPartition struct {
    id           int
    messages     []*OrderedMessage
    consumers    []*OrderedConsumer
    mu          sync.RWMutex
    sequenceNo  int64
}

type OrderedMessage struct {
    ID          string                 `json:"id"`
    PartitionKey string                `json:"partition_key"`
    SequenceNo  int64                 `json:"sequence_no"`
    Data        []byte                `json:"data"`
    Timestamp   time.Time             `json:"timestamp"`
    Metadata    map[string]interface{} `json:"metadata"`
}

func (pq *PartitionedQueue) Send(message *OrderedMessage) error {
    partitionID := pq.partitioner.GetPartition(message.PartitionKey)
    
    pq.mu.RLock()
    partition, exists := pq.partitions[partitionID]
    pq.mu.RUnlock()
    
    if !exists {
        return fmt.Errorf("partition %d not found", partitionID)
    }
    
    return partition.AddMessage(message)
}
```

#### 2. é †åºä»˜ãã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼

```go
type OrderedConsumer struct {
    id                string
    partition        *OrderedPartition
    lastProcessedSeq int64
    processingQueue  chan *OrderedMessage
    handler          MessageHandler
    backpressure     *BackpressureController
}

func (oc *OrderedConsumer) Start(ctx context.Context) error {
    go oc.processMessages(ctx)
    go oc.consumeFromPartition(ctx)
    return nil
}

func (oc *OrderedConsumer) processMessages(ctx context.Context) {
    for {
        select {
        case message := <-oc.processingQueue:
            if message.SequenceNo != oc.lastProcessedSeq+1 {
                // é †åºãŒæ­£ã—ããªã„å ´åˆã¯å¾…æ©Ÿ
                oc.waitForCorrectSequence(ctx, message)
                continue
            }
            
            if err := oc.handler(ctx, message); err != nil {
                oc.handleProcessingError(message, err)
                continue
            }
            
            oc.lastProcessedSeq = message.SequenceNo
            oc.backpressure.MessageProcessed()
            
        case <-ctx.Done():
            return
        }
    }
}
```

#### 3. ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼åˆ¶å¾¡

```go
type BackpressureController struct {
    maxQueueSize     int
    currentQueueSize int64
    processingRate   *RateCalculator
    mu              sync.RWMutex
    throttle        chan struct{}
}

func (bp *BackpressureController) ShouldThrottle() bool {
    bp.mu.RLock()
    defer bp.mu.RUnlock()
    
    if bp.currentQueueSize >= int64(bp.maxQueueSize) {
        return true
    }
    
    // å‡¦ç†é€Ÿåº¦ã«åŸºã¥ãå‹•çš„åˆ¶å¾¡
    currentRate := bp.processingRate.GetCurrentRate()
    targetRate := bp.processingRate.GetTargetRate()
    
    return currentRate < targetRate*0.8
}

func (bp *BackpressureController) WaitIfNeeded(ctx context.Context) error {
    if !bp.ShouldThrottle() {
        return nil
    }
    
    select {
    case <-bp.throttle:
        return nil
    case <-ctx.Done():
        return ctx.Err()
    }
}
```

#### 4. é †åºä¿è¨¼ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

```go
type OrderingCoordinator struct {
    partitions       map[int]*PartitionState
    globalSequence   int64
    orderingWindow   time.Duration
    pendingMessages  *PriorityQueue
    mu              sync.RWMutex
}

type PartitionState struct {
    LastSequence     int64
    ExpectedSequence int64
    BufferedMessages map[int64]*OrderedMessage
    MaxBufferSize    int
}

func (oc *OrderingCoordinator) ProcessMessage(message *OrderedMessage) error {
    partitionID := message.PartitionKey
    
    oc.mu.Lock()
    defer oc.mu.Unlock()
    
    state, exists := oc.partitions[partitionID]
    if !exists {
        state = &PartitionState{
            BufferedMessages: make(map[int64]*OrderedMessage),
            MaxBufferSize:   1000,
        }
        oc.partitions[partitionID] = state
    }
    
    if message.SequenceNo == state.ExpectedSequence {
        // æœŸå¾…ã•ã‚Œã‚‹ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç•ªå·
        return oc.processInOrder(state, message)
    } else if message.SequenceNo > state.ExpectedSequence {
        // æœªæ¥ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ - ãƒãƒƒãƒ•ã‚¡ã«ä¿å­˜
        return oc.bufferMessage(state, message)
    } else {
        // é‡è¤‡ã¾ãŸã¯å¤ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        return fmt.Errorf("duplicate or old message: seq=%d, expected=%d", 
            message.SequenceNo, state.ExpectedSequence)
    }
}

func (oc *OrderingCoordinator) processInOrder(state *PartitionState, message *OrderedMessage) error {
    // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†
    if err := oc.handleMessage(message); err != nil {
        return err
    }
    
    state.ExpectedSequence = message.SequenceNo + 1
    state.LastSequence = message.SequenceNo
    
    // ãƒãƒƒãƒ•ã‚¡ã•ã‚ŒãŸæ¬¡ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒã‚§ãƒƒã‚¯
    for {
        nextMessage, exists := state.BufferedMessages[state.ExpectedSequence]
        if !exists {
            break
        }
        
        delete(state.BufferedMessages, state.ExpectedSequence)
        
        if err := oc.handleMessage(nextMessage); err != nil {
            return err
        }
        
        state.ExpectedSequence++
        state.LastSequence = nextMessage.SequenceNo
    }
    
    return nil
}
```

### é«˜åº¦ãªé †åºä¿è¨¼æ©Ÿèƒ½

#### 1. ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ™ãƒ¼ã‚¹é †åºä¿è¨¼

```go
type TimestampOrderingQueue struct {
    messages        *TimestampPriorityQueue
    watermark       time.Time
    maxDelay        time.Duration
    orderingWindow  time.Duration
    deliveryQueue   chan *OrderedMessage
}

func (toq *TimestampOrderingQueue) AddMessage(message *OrderedMessage) error {
    toq.messages.Push(message)
    
    // ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ã‚¯ã‚’æ›´æ–°
    now := time.Now()
    if toq.watermark.IsZero() || now.Sub(toq.watermark) > toq.orderingWindow {
        toq.watermark = now.Add(-toq.maxDelay)
        toq.deliverReadyMessages()
    }
    
    return nil
}

func (toq *TimestampOrderingQueue) deliverReadyMessages() {
    for !toq.messages.IsEmpty() {
        message := toq.messages.Peek()
        if message.Timestamp.After(toq.watermark) {
            break
        }
        
        toq.messages.Pop()
        toq.deliveryQueue <- message
    }
}
```

#### 2. åˆ†æ•£é †åºä¿è¨¼

```go
type DistributedOrderingCoordinator struct {
    nodeID          string
    vectorClock     *VectorClock
    lamportClock    int64
    nodeClocks      map[string]int64
    orderingBuffer  *DistributedOrderingBuffer
    consensus       ConsensusService
}

type VectorClock map[string]int64

func (doc *DistributedOrderingCoordinator) SendMessage(message *OrderedMessage) error {
    // ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¯ãƒ­ãƒƒã‚¯ã‚’æ›´æ–°
    doc.vectorClock[doc.nodeID]++
    message.VectorClock = doc.copyVectorClock()
    
    // ãƒ©ãƒ³ãƒãƒ¼ãƒˆã‚¯ãƒ­ãƒƒã‚¯ã‚’æ›´æ–°
    atomic.AddInt64(&doc.lamportClock, 1)
    message.LamportTimestamp = atomic.LoadInt64(&doc.lamportClock)
    
    return doc.broadcastMessage(message)
}

func (doc *DistributedOrderingCoordinator) ReceiveMessage(message *OrderedMessage) error {
    // ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¯ãƒ­ãƒƒã‚¯ã‚’æ›´æ–°
    doc.updateVectorClock(message.VectorClock)
    
    // ãƒ©ãƒ³ãƒãƒ¼ãƒˆã‚¯ãƒ­ãƒƒã‚¯ã‚’æ›´æ–°
    currentLamport := atomic.LoadInt64(&doc.lamportClock)
    newLamport := max(currentLamport, message.LamportTimestamp) + 1
    atomic.StoreInt64(&doc.lamportClock, newLamport)
    
    // å› æœé †åºã«åŸºã¥ã„ã¦é…ä¿¡
    return doc.orderingBuffer.AddMessage(message)
}
```

## ğŸ“ èª²é¡Œ (The Problem)

ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æŒã¤åŒ…æ‹¬çš„ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é †åºä¿è¨¼ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š

### 1. ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³åˆ†å‰²
- ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚­ãƒ¼ãƒ™ãƒ¼ã‚¹ã®åˆ†å‰²
- å‹•çš„ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³è¿½åŠ /å‰Šé™¤
- è² è·åˆ†æ•£

### 2. é †åºä¿è¨¼ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
- ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç•ªå·ãƒ™ãƒ¼ã‚¹
- ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ™ãƒ¼ã‚¹
- ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¯ãƒ­ãƒƒã‚¯ãƒ™ãƒ¼ã‚¹

### 3. ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼åˆ¶å¾¡
- å‹•çš„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆèª¿æ•´
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡åˆ¶å¾¡
- é…å»¶åˆ¶å¾¡

### 4. ç›£è¦–æ©Ÿèƒ½
- é †åºé•åæ¤œå‡º
- é…å»¶ãƒ¡ãƒˆãƒªã‚¯ã‚¹
- ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆç›£è¦–

### 5. å¾©æ—§æ©Ÿèƒ½
- é †åºã‚¨ãƒ©ãƒ¼ä¿®å¾©
- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†é€
- çŠ¶æ…‹å¾©å…ƒ

## âœ… æœŸå¾…ã•ã‚Œã‚‹æŒ™å‹• (Expected Behavior)

å®Ÿè£…ãŒæ­£ã—ãå®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ†ã‚¹ãƒˆçµæœãŒå¾—ã‚‰ã‚Œã¾ã™ï¼š

```bash
$ go test -v
=== RUN   TestOrderedQueue_BasicOrdering
    main_test.go:45: Message ordering preserved correctly
--- PASS: TestOrderedQueue_BasicOrdering (0.01s)

=== RUN   TestOrderedQueue_PartitionHandling
    main_test.go:65: Partition-based ordering working
--- PASS: TestOrderedQueue_PartitionHandling (0.02s)

=== RUN   TestOrderedQueue_BackpressureControl
    main_test.go:85: Backpressure control functioning
--- PASS: TestOrderedQueue_BackpressureControl (0.03s)

PASS
ok      day55-message-ordering   0.156s
```

## ğŸ’¡ ãƒ’ãƒ³ãƒˆ (Hints)

å®Ÿè£…ã«è©°ã¾ã£ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®ãƒ’ãƒ³ãƒˆã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š

### ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³åˆ†å‰²

```go
type HashPartitioner struct {
    partitionCount int
}

func (hp *HashPartitioner) GetPartition(key string) int {
    hash := fnv.New32a()
    hash.Write([]byte(key))
    return int(hash.Sum32()) % hp.partitionCount
}
```

### é †åºä¿è¨¼ãƒãƒƒãƒ•ã‚¡

```go
type OrderingBuffer struct {
    buffer          map[int64]*OrderedMessage
    expectedSeq     int64
    maxBufferSize   int
    deliveryChannel chan *OrderedMessage
}

func (ob *OrderingBuffer) AddMessage(message *OrderedMessage) error {
    if message.SequenceNo == ob.expectedSeq {
        return ob.deliverInOrder(message)
    }
    
    if len(ob.buffer) >= ob.maxBufferSize {
        return errors.New("buffer overflow")
    }
    
    ob.buffer[message.SequenceNo] = message
    return nil
}
```

## ğŸš€ ç™ºå±•èª²é¡Œ (Advanced Challenges)

åŸºæœ¬å®Ÿè£…ãŒå®Œäº†ã—ãŸã‚‰ã€ä»¥ä¸‹ã®ç™ºå±•çš„ãªæ©Ÿèƒ½ã«ã‚‚ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ã¦ã¿ã¦ãã ã•ã„ï¼š

1. **åˆ†æ•£é †åºä¿è¨¼**: è¤‡æ•°ãƒãƒ¼ãƒ‰é–“ã§ã®å…¨é †åºä¿è¨¼
2. **æ©Ÿæ¢°å­¦ç¿’äºˆæ¸¬**: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸åˆ°ç€ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­¦ç¿’
3. **å‹•çš„ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³**: è² è·ã«å¿œã˜ãŸè‡ªå‹•åˆ†å‰²ãƒ»çµåˆ
4. **CRDTçµ±åˆ**: Conflict-free Replicated Data Types
5. **ã‚¼ãƒ­ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ç§»è¡Œ**: é †åºä¿è¨¼ã‚’ç¶­æŒã—ãŸè¨­å®šæ›´æ–°

ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é †åºä¿è¨¼ã®å®Ÿè£…ã‚’é€šã˜ã¦ã€åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹ä¸€è²«æ€§åˆ¶å¾¡ã®é‡è¦ãªæ¦‚å¿µã‚’ç¿’å¾—ã—ã¾ã—ã‚‡ã†ï¼